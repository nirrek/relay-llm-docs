<relay-docs relay-version="10.1.2">

---
id: community-learning-resources
title: Community Learning Resources
original_id: community-learning-resources
---
## Relay example projects

These projects serve as an example of how to use Relay in real world applications. Some of them are even with educational videos.

-   [github.com/relayjs/relay-examples](https://github.com/relayjs/relay-examples)
-   [github.com/adeira/relay-example](https://github.com/adeira/relay-example)
-   [github.com/juffalow/react-relay-example](https://github.com/juffalow/react-relay-example)

## Learn basics

Here, you will find articles written by Relay community. They are touching basic topic which are necessary for your daily work.

-   [What is a fragment? Basic explanation of what is a fragment and what it is used for](https://medium.com/@sibelius/relay-modern-what-is-a-fragment-c70f164c2469) (by @sibelius)
-   [Relay anti-patterns. What you should avoid doing when using Relay concepts](https://medium.com/entria/relay-apollo-anti-pattern-d9f4dea47738) (by Entria)
-   [Insights of how Relay Modern has improved a lot since Relay Classic](https://medium.com/entria/relay-is-just-getting-better-54112ffc1a9e) (by Entria)
-   [How to use @argumentsDefinitions to define local variables to your fragments](https://medium.com/entria/relay-modern-argumentdefinitions-d53769dbb95d) (by Entria)
-   [How to paginate using a Refetch Container. You can use a refetch container to paginate as well, just use renderVariables correctly](https://medium.com/entria/relay-modern-pagination-using-refetch-container-editing-a07c6b33ae4e) (by Entria)

## About Relay Store

-   [How Relay Modern stores your data](https://medium.com/@sibelius/relay-modern-the-relay-store-8984cd148798) (by @sibelius)
-   [Deep Dive of Updater Relay Store function. How to update your store properly after a mutation or subscription](https://medium.com/entria/wrangling-the-client-store-with-the-relay-modern-updater-function-5c32149a71ac) (by Entria)
-   [Optimistic Update: how to update your UI before server responds](https://medium.com/entria/relay-modern-optimistic-update-a09ba22d83c9) (by Entria)
-   [Local State Management, part 1 - how to create a controlled input using Relay](https://babangsund.com/relay_local_state_management/) (by @babangsund)
-   [Local State Management, part 2 - how to manage global state and localStorage persistence on the client, using Relay](https://babangsund.com/relay_local_state_management_2/) (by @babangsund)
-   [Local State Management, part 3 - using LocalQueryRenderer and local state to manage nested fragments](https://babangsund.com/relay_local_state_management_3/) (by @babangsund)

## Network Layer

-   [Relay Network Deep Dive - how to incrementally improve your network layer to manage complex data fetching requirements](https://medium.com/entria/relay-modern-network-deep-dive-ec187629dfd3) (by Entria)

## Relay Configuration

-   [Relay Modern with TypeScript - how to configure Relay Modern to make it with TypeScript](https://medium.com/@sibelius/relay-modern-migration-to-typescript-c26ab0ee749c) (by @sibelius)

## Miscellaneous

-   [Relay Modern Learning Blog Posts Thread on Twitter](https://twitter.com/sseraphini/status/1078595758801203202)
-   [Collection of random thoughts and discoveries around Relay](https://mrtnzlml.com/docs/relay)


---
id: graphql-server-specification
title: GraphQL Server Specification
original_id: graphql-server-specification
---

import useBaseUrl from '@docusaurus/useBaseUrl';

The goal of this document is to specify the assumptions that Relay makes about a GraphQL server and demonstrate them through an example GraphQL schema.

Table of Contents:

-   [Preface](#preface)
-   [Schema](#schema)
-   [Object Identification](#object-identification)
-   [Connections](#connections)
-   [Mutations](#mutations)
-   [Further Reading](#further-reading)

## Preface

The three core assumptions that Relay makes about a GraphQL server are that it provides:

1.  A mechanism for refetching an object.
2.  A description of how to page through connections.
3.  Structure around mutations to make them predictable.

This example demonstrates all three of these assumptions. This example is not comprehensive, but it is designed to quickly introduce these core assumptions, to provide some context before diving into the more detailed specification of the library.

The premise of the example is that we want to use GraphQL to query for information about ships and factions in the original Star Wars trilogy.

It is assumed that the reader is already familiar with [GraphQL](http://graphql.org/); if not, the README for [GraphQL.js](https://github.com/graphql/graphql-js) is a good place to start.

It is also assumed that the reader is already familiar with [Star Wars](https://en.wikipedia.org/wiki/Star_Wars); if not, the 1977 version of Star Wars is a good place to start, though the 1997 Special Edition will serve for the purposes of this document.

## Schema

The schema described below will be used to demonstrate the functionality that a GraphQL server used by Relay should implement. The two core types are a faction and a ship in the Star Wars universe, where a faction has many ships associated with it. The schema below is the output of the GraphQL.js [`printSchema`](https://github.com/graphql/graphql-js/blob/main/src/utilities/printSchema.js).

```

interface Node {
  id: ID!
}

type Faction implements Node {
  id: ID!
  name: String
  ships: ShipConnection
}

type Ship implements Node {
  id: ID!
  name: String
}

type ShipConnection {
  edges: [ShipEdge]
  pageInfo: PageInfo!
}

type ShipEdge {
  cursor: String!
  node: Ship
}

type PageInfo {
  hasNextPage: Boolean!
  hasPreviousPage: Boolean!
  startCursor: String
  endCursor: String
}

type Query {
  rebels: Faction
  empire: Faction
  node(id: ID!): Node
}

input IntroduceShipInput {
  factionId: String!
  shipNamed: String!
}

type IntroduceShipPayload {
  faction: Faction
  ship: Ship
}

type Mutation {
  introduceShip(input: IntroduceShipInput!): IntroduceShipPayload
}
```

## Object Identification

Both `Faction` and `Ship` have identifiers that we can use to refetch them. We expose this capability to Relay through the `Node` interface and the `node` field on the root query type.

The `Node` interface contains a single field, `id`, which is an `ID!`. The `node` root field takes a single argument, an `ID!`, and returns a `Node`. These two work in concert to allow refetching; if we pass the `id` returned in that field to the `node` field, we get the object back.

Let's see this in action, and query for the ID of the rebels:

```

query RebelsQuery {
  rebels {
    id
    name
  }
}
```

returns

```json

{
  "rebels": {
    "id": "RmFjdGlvbjox",
    "name": "Alliance to Restore the Republic"
  }
}
```

So now we know the ID of the Rebels in our system. We can now refetch them:

```

query RebelsRefetchQuery {
  node(id: "RmFjdGlvbjox") {
    id
    ... on Faction {
      name
    }
  }
}
```

returns

```json

{
  "node": {
    "id": "RmFjdGlvbjox",
    "name": "Alliance to Restore the Republic"
  }
}
```

If we do the same thing with the Empire, we'll find that it returns a different ID, and we can refetch it as well:

```

query EmpireQuery {
  empire {
    id
    name
  }
}
```

yields

```json

{
  "empire": {
    "id": "RmFjdGlvbjoy",
    "name": "Galactic Empire"
  }
}
```

and

```

query EmpireRefetchQuery {
  node(id: "RmFjdGlvbjoy") {
    id
    ... on Faction {
      name
    }
  }
}
```

yields

```json

{
  "node": {
    "id": "RmFjdGlvbjoy",
    "name": "Galactic Empire"
  }
}
```

The `Node` interface and `node` field assume globally unique IDs for this refetching. A system without globally unique IDs can usually synthesize them by combining the type with the type-specific ID, which is what was done in this example.

The IDs we got back were base64 strings. IDs are designed to be opaque (the only thing that should be passed to the `id` argument on `node` is the unaltered result of querying `id` on some object in the system), and base64ing a string is a useful convention in GraphQL to remind viewers that the string is an opaque identifier.

Complete details on how the server should behave are available in the [GraphQL Object Identification](https://graphql.org/learn/global-object-identification/) best practices guide in the GraphQL site.

## Connections

A faction has many ships in the Star Wars universe. Relay contains functionality to make manipulating one-to-many relationships easy, using a standardized way of expressing these one-to-many relationships. This standard connection model offers ways of slicing and paginating through the connection.

Let's take the rebels, and ask for their first ship:

```

query RebelsShipsQuery {
  rebels {
    name,
    ships(first: 1) {
      edges {
        node {
          name
        }
      }
    }
  }
}
```

yields

```json

{
  "rebels": {
    "name": "Alliance to Restore the Republic",
    "ships": {
      "edges": [
        {
          "node": {
            "name": "X-Wing"
          }
        }
      ]
    }
  }
}
```

That used the `first` argument to `ships` to slice the result set down to the first one. But what if we wanted to paginate through it? On each edge, a cursor will be exposed that we can use to paginate. Let's ask for the first two this time, and get the cursor as well:

```

query MoreRebelShipsQuery {
  rebels {
    name,
    ships(first: 2) {
      edges {
        cursor
        node {
          name
        }
      }
    }
  }
}
```

and we get back

```json

{
  "rebels": {
    "name": "Alliance to Restore the Republic",
    "ships": {
      "edges": [
        {
          "cursor": "YXJyYXljb25uZWN0aW9uOjA=",
          "node": {
            "name": "X-Wing"
          }
        },
        {
          "cursor": "YXJyYXljb25uZWN0aW9uOjE=",
          "node": {
            "name": "Y-Wing"
          }
        }
      ]
    }
  }
}
```

Notice that the cursor is a base64 string. That's the pattern from earlier: the server is reminding us that this is an opaque string. We can pass this string back to the server as the `after` argument to the `ships` field, which will let us ask for the next three ships after the last one in the previous result:

```

query EndOfRebelShipsQuery {
  rebels {
    name,
    ships(first: 3 after: "YXJyYXljb25uZWN0aW9uOjE=") {
      edges {
        cursor,
        node {
          name
        }
      }
    }
  }
}
```

gives us

```json


{
  "rebels": {
    "name": "Alliance to Restore the Republic",
    "ships": {
      "edges": [
        {
          "cursor": "YXJyYXljb25uZWN0aW9uOjI=",
          "node": {
            "name": "A-Wing"
          }
        },
        {
          "cursor": "YXJyYXljb25uZWN0aW9uOjM=",
          "node": {
            "name": "Millenium Falcon"
          }
        },
        {
          "cursor": "YXJyYXljb25uZWN0aW9uOjQ=",
          "node": {
            "name": "Home One"
          }
        }
      ]
    }
  }
}
```

Sweet! Let's keep going and get the next four!

```

query RebelsQuery {
  rebels {
    name,
    ships(first: 4 after: "YXJyYXljb25uZWN0aW9uOjQ=") {
      edges {
        cursor,
        node {
          name
        }
      }
    }
  }
}
```

yields

```json

{
  "rebels": {
    "name": "Alliance to Restore the Republic",
    "ships": {
      "edges": []
    }
  }
}
```

Hm. There were no more ships; guess there were only five in the system for the rebels. It would have been nice to know that we'd reached the end of the connection, without having to do another round trip in order to verify that. The connection model exposes this capability with a type called `PageInfo`. So let's issue the two queries that got us ships again, but this time ask for `hasNextPage`:

```

query EndOfRebelShipsQuery {
  rebels {
    name,
    originalShips: ships(first: 2) {
      edges {
        node {
          name
        }
      }
      pageInfo {
        hasNextPage
      }
    }
    moreShips: ships(first: 3 after: "YXJyYXljb25uZWN0aW9uOjE=") {
      edges {
        node {
          name
        }
      }
      pageInfo {
        hasNextPage
      }
    }
  }
}
```

and we get back

```json

{
  "rebels": {
    "name": "Alliance to Restore the Republic",
    "originalShips": {
      "edges": [
        {
          "node": {
            "name": "X-Wing"
          }
        },
        {
          "node": {
            "name": "Y-Wing"
          }
        }
      ],
      "pageInfo": {
        "hasNextPage": true
      }
    },
    "moreShips": {
      "edges": [
        {
          "node": {
            "name": "A-Wing"
          }
        },
        {
          "node": {
            "name": "Millenium Falcon"
          }
        },
        {
          "node": {
            "name": "Home One"
          }
        }
      ],
      "pageInfo": {
        "hasNextPage": false
      }
    }
  }
}
```

So on the first query for ships, GraphQL told us there was a next page, but on the next one, it told us we'd reached the end of the connection.

Relay uses all of this functionality to build out abstractions around connections, to make these easy to work with efficiently without having to manually manage cursors on the client.

<p>Complete details on how the server should behave are available in the <a href={useBaseUrl('graphql/connections.htm')}>GraphQL Cursor Connections</a> spec.</p>

## Mutations

Relay uses a common pattern for mutations, where there are root fields on the mutation type with a single argument, `input`, and where the input and output both contain a client mutation identifier used to reconcile requests and responses.

By convention, mutations are named as verbs, their inputs are the name with "Input" appended at the end, and they return an object that is the name with "Payload" appended.

So for our `introduceShip` mutation, we create two types: `IntroduceShipInput` and `IntroduceShipPayload`:

```

input IntroduceShipInput {
  factionId: ID!
  shipName: String!
}

type IntroduceShipPayload {
  faction: Faction
  ship: Ship
}
```

With this input and payload, we can issue the following mutation:

```

mutation AddBWingQuery($input: IntroduceShipInput!) {
  introduceShip(input: $input) {
    ship {
      id
      name
    }
    faction {
      name
    }
  }
}
```

with these params:

```json

{
  "input": {
    "shipName": "B-Wing",
    "factionId": "1"
  }
}
```

and we'll get this result:

```json

{
  "introduceShip": {
    "ship": {
      "id": "U2hpcDo5",
      "name": "B-Wing"
    },
    "faction": {
      "name": "Alliance to Restore the Republic"
    }
  }
}
```

## Further Reading

<p>This concludes the overview of the GraphQL Server Specifications. For the detailed requirements of a Relay-compliant GraphQL server, a more formal description of the <a href={useBaseUrl('graphql/connections.htm')}>Relay cursor connection</a> model, the <a href="https://graphql.org/learn/global-object-identification/">GraphQL global object identification</a> model are all available.</p>

To see code implementing the specification, the [GraphQL.js Relay library](https://github.com/graphql/graphql-relay-js) provides helper functions for creating nodes, connections, and mutations; that repository's [`__tests__`](https://github.com/graphql/graphql-relay-js/tree/main/src/__tests__) folder contains an implementation of the above example as integration tests for the repository.


---
id: installation-and-setup
title: Installation and Setup
original_id: installation-and-setup
---
## Installation

Install React and Relay using `yarn` or `npm`:

```sh

yarn add react react-dom react-relay

```

## Set up Relay with a single config file

The below configuration of `babel-plugin-relay` and `relay-compiler` can be applied using a single configuration file by
using the `relay-config` package. Besides unifying all Relay configuration in a single place, other tooling can leverage
this to provide zero-config setup (e.g. [vscode-apollo-relay](https://github.com/relay-tools/vscode-apollo-relay)).

Install the package:

```sh

yarn add --dev relay-config

```

And create the configuration file:

```javascript
// relay.config.js
module.exports = {
  // ...
  // Configuration options accepted by the `relay-compiler` command-line tool and `babel-plugin-relay`.
  src: "./src",
  schema: "./data/schema.graphql",
  exclude: ["**/node_modules/**", "**/__mocks__/**", "**/__generated__/**"],
}
```

## Set up babel-plugin-relay

Relay Modern requires a Babel plugin to convert GraphQL to runtime artifacts:

```sh

yarn add --dev babel-plugin-relay graphql

```

Add `"relay"` to the list of plugins your `.babelrc` file:

```javascript
{
  "plugins": [
    "relay"
  ]
}
```

Please note that the `"relay"` plugin should run before other plugins or
presets to ensure the `graphql` template literals are correctly transformed. See
Babel's [documentation on this topic](https://babeljs.io/docs/plugins/#pluginpreset-ordering).

Alternatively, instead of using `babel-plugin-relay`, you can use Relay with [babel-plugin-macros](https://github.com/kentcdodds/babel-plugin-macros). After installing `babel-plugin-macros` and adding it to your Babel config:

```javascript
const graphql = require('babel-plugin-relay/macro');
```

If you need to configure `babel-plugin-relay` further (e.g. to enable `compat` mode), you can do so by [specifying the options in a number of ways](https://github.com/kentcdodds/babel-plugin-macros/blob/main/other/docs/user.md#config-experimental).

For example:

```javascript
// babel-plugin-macros.config.js
module.exports = {
  // ...
  // Other macros config
  relay: {
    compat: true,
  },
}
```

## Set up relay-compiler

Relay's ahead-of-time compilation requires the [Relay Compiler](Modern-GraphQLInRelay.md#relay-compiler), which you can install via `yarn` or `npm`:

```sh

yarn add --dev relay-compiler

```

This installs the bin script `relay-compiler` in your node_modules folder. It's recommended to run this from a `yarn`/`npm` script by adding a script to your `package.json` file:

```javascript
"scripts": {
  "relay": "relay-compiler --src ./src --schema ./schema.graphql"
}
```

or if you are using jsx:

```javascript
"scripts": {
  "relay": "relay-compiler --src ./src --schema ./schema.graphql --extensions js jsx"
}
```

Then, after making edits to your application files, just run the `relay` script to generate new compiled artifacts:

```sh

yarn run relay

```

Alternatively, you can pass the `--watch` option to watch for file changes in your source code and automatically re-generate the compiled artifacts (**Note:** Requires [watchman](https://facebook.github.io/watchman) to be installed):

```sh

yarn run relay --watch

```

For more details, check out our [Relay Compiler docs](Modern-GraphQLInRelay.md#relay-compiler).

## JavaScript environment requirements

The Relay Modern packages distributed on NPM use the widely-supported ES5
version of JavaScript to support as many browser environments as possible.

However, Relay Modern expects modern JavaScript global types (`Map`, `Set`,
`Promise`, `Object.assign`) to be defined. If you support older browsers and
devices which may not yet provide these natively, consider including a global
polyfill in your bundled application, such as [core-js][] or
[@babel/polyfill](https://babeljs.io/docs/usage/polyfill/).

A polyfilled environment for Relay using [core-js][] to support older browsers
might look like:

```javascript
require('core-js/es6/map');
require('core-js/es6/set');
require('core-js/es6/promise');
require('core-js/es6/object');

require('./myRelayApplication');
```

[core-js]: https://github.com/zloirock/core-js


---
id: introduction-to-relay
title: Introduction to Relay
original_id: introduction-to-relay
slug: /
---
Relay is a JavaScript framework for building data-driven React applications powered by GraphQL, designed from the ground up to be easy to use, extensible and, most of all, performant. Relay accomplishes this with static queries and ahead-of-time code generation.

[React](https://facebook.github.io/react/) allows views to be defined as components where every component is responsible for rendering a part of the UI. Composing other components is how to build complex UIs. Each React component doesn't need to know the inner workings of the composed components.

Relay couples React with GraphQL and develops the idea of encapsulation further. It allows components to specify what data they need and the Relay framework provides the data. This makes the data needs of inner components opaque and allows composition of those needs. Thinking about what data an app needs becomes localized to the component making it easier to reason about what fields are needed or no longer needed.


---
id: prerequisites
title: Prerequisites
original_id: prerequisites
---
## React

Relay is a framework for data management with the primary supported binding for React applications, so we assume that you are already familiar with [React](https://reactjs.org/).

## GraphQL

We also assume basic understanding of [GraphQL](http://graphql.org/learn/). In order to start using Relay, you will also need:

### A GraphQL Schema

A description of your data model with an associated set of resolve methods that know how to fetch any data your application could ever need.

GraphQL is designed to support a wide range of data access patterns. In order to understand the structure of an application's data, Relay requires that you follow certain conventions when defining your schema. These are documented in the [GraphQL Server Specification](GraphQL-ServerSpecification.md).

-   **[graphql-js](https://github.com/graphql/graphql-js)** on [npm](https://www.npmjs.com/package/graphql)

    General-purpose tools for building a GraphQL schema using JavaScript

-   **[graphql-relay-js](https://github.com/graphql/graphql-relay-js)** on [npm](https://www.npmjs.com/package/graphql-relay)

    JavaScript helpers for defining connections between data, and mutations, in a way that smoothly integrates with Relay.

### A GraphQL Server

Any server can be taught to load a schema and speak GraphQL. Our [examples](https://github.com/relayjs/relay-examples) use Express.

-   **[express-graphql](https://github.com/graphql/express-graphql)** on [npm](https://www.npmjs.com/package/express-graphql)


---
id: quick-start-guide
title: Quick Start Guide
original_id: quick-start-guide
---
In this guide we are going to give a brief overview of how Relay works and how to use it, using as reference an example todo list app. For more thorough documentation, check out our Guides and API sections.

Table of Contents:

-   [Setup](#setup)
-   [Relay Environment](#relay-environment)
-   [Rendering GraphQL Queries](#rendering-graphql-queries)
-   [Using Query Variables](#using-query-variables)
-   [Using Fragments](#using-fragments)
-   [Composing Fragments](#composing-fragments)
-   [Rendering Fragments](#rendering-fragments)
-   [Mutating Data](#mutating-data)
-   [Next Steps](#next-steps)

## Setup

Before starting, make sure to check out our [Prerequisites](Introduction-Prerequisites.md) and [Installation and Setup](Introduction-InstallationAndSetup.md) guides. As mentioned in the prerequisites, we need to make sure that we've set up a GraphQL server and schema.

Fortunately, we are going to be using this [example todo list app](https://github.com/relayjs/relay-examples/tree/main/todo), which already has a [server](https://github.com/relayjs/relay-examples/blob/main/todo/server.js) and [schema](https://github.com/relayjs/relay-examples/blob/main/todo/data/schema.graphql) available for us to use:

```graphql
# From schema.graphql
# https://github.com/relayjs/relay-examples/blob/main/todo/data/schema.graphql

type Query {
  viewer: User

  # Fetches an object given its ID
  node(
    # The ID of an object
    id: ID!
  ): Node
}
```

Additionally, we will be using [Flow](https://flow.org/) inside our JavaScript code examples. Flow is optional to set up in your project, but we will include it in our examples for completeness.

## Relay Environment

Before we can start rendering pixels on the screen, we need to configure Relay via a [Relay Environment](Modern-RelayEnvironment.md). The environment bundles together the configuration, cache storage, and network-handling that Relay needs in order to operate.

For the purposes of our example, we are simply going to configure our environment to communicate with our existing GraphQL server:

```javascript
import {
  Environment,
  Network,
  RecordSource,
  Store,
} from 'relay-runtime';

function fetchQuery(
  operation,
  variables,
) {
  return fetch('/graphql', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      query: operation.text,
      variables,
    }),
  }).then(response => {
    return response.json();
  });
}

const environment = new Environment({
  network: Network.create(fetchQuery),
  store: new Store(new RecordSource()),
});

export default environment;
```

A Relay Environment requires at least a [Store](Modern-RelayStore.md) and a [Network Layer](Modern-NetworkLayer.md). The above code uses the default implementation for `Store`, and creates a [Network Layer](Modern-NetworkLayer.md) using a simple `fetchQuery` function to fetch a GraphQL query from our server.

Usually we'd want a single environment in our app, so you could export this environment as a singleton instance from a module to make it accessible across your app.

## Rendering GraphQL Queries

Now that we've configured our Relay Environment, we can start fetching queries and rendering data on the screen. The entry point to render data from a GraphQL query is the [`QueryRenderer`](Modern-QueryRenderer.md) component provided by `react-relay`.

To start, let's assume we just want to render the user id on the screen. From our [schema](https://github.com/relayjs/relay-examples/blob/main/todo/data/schema.graphql#L66), we know that we can get the current `User` via the `viewer` field, so let's write a sample query to fetch the current user id:

```graphql
query UserQuery {
  viewer {
    id
  }
}
```

Now, let's see what it would take to create a component that fetches and renders the above query:

```javascript
// App.js
import React from 'react';
import {graphql, QueryRenderer} from 'react-relay';

const environment = // defined or imported above...

export default class App extends React.Component {
  render() {
    return (
      <QueryRenderer
        environment={environment}
        query={graphql`
          query UserQuery {
            viewer {
              id
            }
          }
        `}
        variables={{}}
        render={({error, props}) => {
          if (error) {
            return <div>Error!</div>;
          }
          if (!props) {
            return <div>Loading...</div>;
          }
          return <div>User ID: {props.viewer.id}</div>;
        }}
      />
    );
  }
}
```

Our app is rendering a `QueryRenderer` in the above code, like any other React Component, but let's see what's going on in the props that we are passing to it:

-   We're passing the `environment` we defined earlier.
-   We're using the [`graphql`](Modern-GraphQLInRelay.md) function to define our GraphQL query. `graphql` is a template tag that is never executed at runtime, but rather used by the [Relay Compiler](Modern-GraphQLInRelay.md#relay-compiler) to generate the runtime artifacts that Relay requires to operate. We don't need to worry about this right now; for more details check out our [GraphQL in Relay](Modern-GraphQLInRelay.md) docs.
-   We're passing an empty set of `variables`. We'll look into how to use variables in the next section.
-   We're passing a `render` function; as you can tell from the code, Relay gives us some information about whether an error occurred, or if we're still fetching the query. If everything succeeds, the data we requested will be available inside `props`, with the same shape as the one specified in the query.

In order to run this app, we need to first compile our query using the Relay Compiler. Assuming the setup from [Installation and Setup](Introduction-InstallationAndSetup.md), we can just run `yarn relay`.

For more details on `QueryRenderer`, check out the [docs](Modern-QueryRenderer.md).

## Using Query Variables

Let's assume for a moment that in our app we want to be able to view data for different users, so we're going to somehow need to query users by id. From our [schema](https://github.com/relayjs/relay-examples/blob/main/todo/data/schema.graphql#L69), we know we can query nodes given an id, so let's write a parameterized query to get a user by id:

```graphql
query UserQuery($userID: ID!) {
  node(id: $userID) {
    id
  }
}
```

Now, let's see how we would fetch the above query using a `QueryRenderer`:

```javascript
// UserTodoList.js
// @flow
import React from 'react';
import {graphql, QueryRenderer} from 'react-relay';

const environment = // defined or imported above...

type Props = {
  userID: string,
};

export default class UserTodoList extends React.Component<Props> {
  render() {
    const {userID} = this.props;

    return (
      <QueryRenderer
        environment={environment}
        query={graphql`
          query UserQuery($userID: ID!) {
            node(id: $userID) {
              id
            }
          }
        `}
        variables={{userID}}
        render={({error, props}) => {
          if (error) {
            return <div>Error!</div>;
          }
          if (!props) {
            return <div>Loading...</div>;
          }
          return <div>User ID: {props.node.id}</div>;
        }}
      />
    );
  }
}
```

The above code is doing something very similar to our [previous example](#rendering-graphql-queries). However, we are now passing a `$userID` variable to the GraphQL query via the `variables` prop. This has a couple of important implications:

-   Given that `userID` is also a prop that our component takes, it could receive a new `userID` from its parent component at any moment. When this happens, new `variables` will be passed down to our `QueryRenderer`, which will automatically cause it to re-fetch the query with the new value for `$userID`.
-   The `$userID` variable will now be available anywhere inside that query. This will become important to keep in mind when using fragments.

Now that we've updated the query, don't forget to run `yarn relay`.

## Using Fragments

Now that we know how to define and fetch queries, let's actually start building a todo list.

First, let's start at the bottom. Suppose that we want to render a component that simply displays a given todo item's text and completed state:

```javascript
// Todo.js
import React from 'react';

type Props = {
  todo: {
    complete: boolean,
    text: string,
  },
};

export default class Todo extends React.Component<Props> {
  render() {
    const {complete, text} = this.props.todo;

    return (
      <li>
        <div>
          <input
            checked={complete}
            type="checkbox"
          />
          <label>
            {text}
          </label>
        </div>
      </li>
    );
  }
}
```

From our [schema](https://github.com/relayjs/relay-examples/blob/main/todo/data/schema.graphql#L112), we know that we can query this data on the `Todo` type. However, we don't want to have to send a separate query for each todo item; that would defeat the purpose of using GraphQL over a traditional REST API. We could manually query for these fields directly in our `QueryRenderer` query, but that would hurt re-usability: what if we want to query the same set of fields as part of a different query? Additionally, we wouldn't know which component needs the data we're querying, which is a problem Relay directly tries to address.

Instead, we can define a reusable [Fragment](http://graphql.org/learn/queries/#fragments), which allows us to define a set of fields on a type and reuse them within our queries wherever we need to:

```graphql
fragment TodoItemFragment on Todo {
  complete
  text
}
```

Our component can then use this fragment to declare its data dependency on the `Todo` GraphQL type:

```javascript
// Todo.js

// OPTIONAL: Flow type generated after running `yarn relay`, defining an Object type with shape of the fragment:
import type {Todo_todo} from './__generated__/Todo_todo.graphql';

import React from 'react';
import {graphql, createFragmentContainer} from 'react-relay'

type Props = {
  todo: Todo_todo
}

class Todo extends React.Component<Props> {
  render() {
    const {complete, text} = this.props.todo;

    return (
      <li>
        <div>
          <input
            checked={complete}
            type="checkbox"
          />
          <label>
            {text}
          </label>
        </div>
      </li>
    );
  }
}

export default createFragmentContainer(
  Todo,
  // Each key specified in this object will correspond to a prop available to the component
  {
    todo: graphql`
      # As a convention, we name the fragment as '<ComponentFileName>_<propName>'
      fragment Todo_todo on Todo {
        complete
        text
      }
    `
  },
)

```

The above code highlights one of Relay's most important principles which is colocation of components with their data dependencies. This is beneficial for a few reasons:

-   It becomes obvious at a glance what data is required to render a given component, without having to search which query in our app is fetching the required data.
-   As a corollary, the component is de-coupled from the query that renders it. We can change the data dependencies for the component without having to update the queries that render them or worrying about breaking other components.

Check out our [Thinking in Relay](PrinciplesAndArchitecture-ThinkingInRelay.md) guide for more details behind Relay's principles.

Before proceeding, don't forget to run the Relay Compiler with `yarn relay`.

## Composing Fragments

Given that [Fragment Containers](Modern-FragmentContainer.md) are just React components, we can compose them as such. We can even re-use fragment containers within other fragment containers. As an example, let's see how we would define a `TodoList` component that just renders a list of todo items, and whether all have been completed or not:

```javascript
// TodoList.js

// OPTIONAL: Flow type generated after running `yarn relay`, defining an Object type with shape of the fragment:
import type {TodoList_userTodoData} from './__generated__/TodoList_userTodoData.graphql';

import React from 'react';
import {graphql, createFragmentContainer} from 'react-relay';

type Props = {
  userTodoData: TodoList_userTodoData,
}

class TodoList extends React.Component<Props> {
  render() {
    const {userTodoData: {totalCount, completedCount, todos}} = this.props;

    return (
      <section>
        <input
          checked={totalCount === completedCount}
          type="checkbox"
        />
        <ul>
          {todos.edges.map(edge =>
            <Todo
              key={edge.node.id}
              // We pass the data required by Todo here
              todo={edge.node}
            />
          )}
        </ul>
      </section>
    );
  }
}

export default createFragmentContainer(
  TodoList,
  {
    userTodoData: graphql`
      # As a convention, we name the fragment as '<ComponentFileName>_<PropName>'
      fragment TodoList_userTodoData on User {
        todos(
          first: 2147483647  # max GraphQLInt, to fetch all todos
        ) {
          edges {
            node {
              id,
              # We use the fragment defined by the child Todo component here
              ...Todo_todo,
            },
          },
        },
        id,
        totalCount,
        completedCount,
      }
    `,
  },
);
```

As with the first fragment container we defined, `TodoList` declares its data dependencies via a fragment. However, this component additionally re-uses the fragment previously defined by the `Todo` component, and passes the appropriate data when rendering the child `Todo` components (a.k.a. fragment containers).

One final thing to note when composing fragment containers is that the parent will not have access to the data defined by the child container. Relay only allows components to access data they specifically ask for in GraphQL fragments â€” nothing more. This is called [Data Masking](PrinciplesAndArchitecture-ThinkingInRelay.md#data-masking), and it's intentional to prevent components from depending on data they didn't declare as a dependency.

## Rendering Fragments

Now that we have some components (a.k.a fragment containers) that declare their data dependencies, we need to hook them up to a `QueryRenderer` so that the data is actually fetched and rendered. Remember,
fragment containers do not directly fetch data. Instead, containers declare a specification of the data needed to render, and Relay guarantees that this data is available before rendering.

A `QueryRenderer` rendering these fragment containers could look like the following:

```javascript
// ViewerTodoList.js
import React from 'react';
import {graphql, QueryRenderer} from 'react-relay';
import TodoList from './TodoList'

const environment = // defined or imported above...

export default class ViewerTodoList extends React.Component {
  render() {
    return (
      <QueryRenderer
        environment={environment}
        query={graphql`
          query ViewerQuery {
            viewer {
              id
              # Re-use the fragment here
              ...TodoList_userTodoData
            }
          }
        `}
        variables={{}}
        render={({error, props}) => {
          if (error) {
            return <div>Error!</div>;
          }
          if (!props) {
            return <div>Loading...</div>;
          }
          return (
            <div>
              <div>Todo list for User {props.viewer.id}:</div>
              <TodoList userTodoData={props.viewer} />
            </div>
          );
        }}
      />
    );
  }
}
```

Check out our docs for [Fragment Containers](Modern-FragmentContainer.md) for more details, and our guides on [Refetch](Modern-RefetchContainer.md) and [Pagination](Modern-PaginationContainer.md) for more advanced usage of containers.

## Mutating Data

Now that we know how to query for and render data, let's move on to changing our data. We know that to change any data in our server, we need to use GraphQL [Mutations](http://graphql.org/learn/queries/#mutations).

From our [schema](https://github.com/relayjs/relay-examples/blob/main/todo/data/schema.graphql#L35), we know that we have some mutations available to us, so let's start by writing a mutation to change the `complete` status of a given todo item (i.e. mark or unmark it as done):

```graphql
mutation ChangeTodoStatusMutation($input: ChangeTodoStatusInput!) {
  changeTodoStatus(input: $input) {
    todo {
      id
      complete
    }
  }
}
```

This mutation allows us to query back some data as a [result of the mutation](https://github.com/relayjs/relay-examples/blob/main/todo/data/schema.graphql#L18), so we're going to query for the updated `complete` status on the todo item.

In order to execute this mutation in Relay, we're going to write a new mutation using Relay's `commitMutation` api:

```javascript
// ChangeTodoStatusMutation.js
import {graphql, commitMutation} from 'react-relay';

// We start by defining our mutation from above using `graphql`
const mutation = graphql`
  mutation ChangeTodoStatusMutation($input: ChangeTodoStatusInput!) {
    changeTodoStatus(input: $input) {
      todo {
        id
        complete
      }
    }
  }
`;

function commit(
  environment,
  complete,
  todo,
) {
  // Now we just call commitMutation with the appropriate parameters
  return commitMutation(
    environment,
    {
      mutation,
      variables: {
        input: {complete, id: todo.id},
      },
    }
  );
}

export default {commit};
```

Whenever we call `ChangeTodoStatusMutation.commit(...)`, Relay will send the mutation to the server and, in our case, upon receiving a response it will automatically update the local data store with the latest data from the server. This also means that upon receiving the response, Relay will ensure that any components (i.e. containers) that depend on the updated data are re-rendered.

In order to actually use this mutation in our component, we could update our `Todo` component in the following way:

```javascript
// Todo.js

// ...

class Todo extends React.Component<Props> {
  // Add a new event handler that fires off the mutation
  _handleOnCheckboxChange = (e) => {
    const complete = e.target.checked;
    ChangeTodoStatusMutation.commit(
      this.props.relay.environment,
      complete,
      this.props.todo,
    );
  };

  render() {
    // ...
  }
}

// ...

```

### Optimistic Updates

In our example above, the `complete` status in our component won't be updated and re-rendered until we get a response back from the server, which won't make for a great user experience.

In order to make the experience better, we can configure our mutation to do an optimistic update. An optimistic update means immediately updating our local data with what we expect it to be if we get a successful response from the server, i.e. updating the data immediately assuming that the mutation request will succeed. If the request doesn't succeed, we can roll-back our update.

In Relay, there's a couple of options we can pass to `commitMutation` to enable optimistic updates. Let's see what that would look like in our `ChangeTodoStatusMutation`:

```javascript
// ChangeTodoStatusMutation.js

// ...

function getOptimisticResponse(complete, todo) {
  return {
    changeTodoStatus: {
      todo: {
        complete: complete,
        id: todo.id,
      },
    },
  };
}

function commit(
  environment,
  complete,
  todo
) {
  // Now we just call commitMutation with the appropriate parameters
  return commitMutation(
    environment,
    {
      mutation,
      variables: {
        input: {complete, id: todo.id},
      },
      optimisticResponse: getOptimisticResponse(complete, todo),
    }
  );
}

export default {commit};
```

In the simplest case above, we just need to pass an `optimisticResponse` option, which should refer to an object having the same shape as the mutation response payload. When we pass this option, Relay will know to immediately update our local data with the optimistic response, and then update it with the actual server response or roll it back if an error occurs.

Please note that the actual query and response payload may not have the exact same shape as the selection in your code, because sometimes Relay will add extra fields for you during the compilation step, and you need to add these fields to your optimistic response. For example:

-   Relay will add an `id` field if it exists on the type for caching purpose.

-   Relay will add a `__typename` field if the type is an union or an interface.

You can inspect the network request or response to see the exact shape.

### Updating local data from mutation responses

By default, Relay will know to update the fields on the records referenced by the mutation payload, (i.e. the `todo` in our example). However, this is only the simplest case. In some cases updating the local data isn't as simple as just updating the fields in a record.

For instance, we might be updating a collection of items, or we might be deleting a record entirely. For these more advanced scenarios Relay allows us to pass a set of options for us to control how we update the local data from a server response, including a set of [`configs`](Modern-Mutations.md#configs) and an [`updater`](Modern-Mutations.md#using-updater-and-optimisticupdater) function for full control over the update.

For more details and advanced use cases on mutations and updates, check out our [Mutations](Modern-Mutations.md) docs.

## Next Steps

This guide just scratches the surface of Relay's API. For more detailed docs and guides, check out our API Reference and Guides sections.


---
id: api-cheatsheet
title: API Cheatsheet
original_id: api-cheatsheet
---
A reference for translating between the Relay Classic and Relay Modern APIs.

### To add a new root for relay components

Classic: `<RelayRootContainer>`

Modern: `<QueryRenderer>`

### To add a new relay container

Classic: `Relay.createContainer`

Modern: `createFragmentContainer`

### To add a new relay container that has changing data requirements

Classic: `Relay.createContainer`

Modern `createRefetchContainer`

### To add a new paginating relay container

Classic: `Relay.createContainer`

Modern: `createPaginationContainer`

### To update a variable for my component

Classic: `this.props.relay.setVariable({foo: bar}...)`

Modern: `this.props.relay.refetch({foo: bar}...` in a Refetch Container

### To paginate through a connection

Classic: `this.props.relay.setVariable({count: prevCount + pageSize}...)`

Modern `this.props.relay.loadMore(pageSize...)` in a Pagination Container

### To force fetch a component

Classic: `this.props.relay.forceFetch()`

Modern: `this.props.relay.refetchConnection(...)` in a Pagination Container

or: `this.props.relay.refetch({}, {}, callback, {force: true})` in a Refetch Container

### To commit a mutation

Classic: `this.props.relay.commitUpdate(mutation...)`

Modern: `commitMutation(this.props.relay.environment, {mutation...})`


---
id: compatibility-cheatsheet
title: Compatibility Cheatsheet
original_id: compatibility-cheatsheet
---
What works with what? Relay Compat (`'react-relay/compat'`) is the most flexible.
Compat components and mutations can be used by everything. Compat components can also have any kind of children.

However components using the Relay Modern API (`'react-relay'`) and the Relay Classic API (`'react-relay/classic'`) cannot be used with each other.

### Can RelayRootContainer use:

| Classic Component | Compat Component | Modern Component | Classic Mutation | Compat Mutation | Modern Mutation |
| ----------------- | ---------------- | ---------------- | ---------------- | --------------- | --------------- |
| Yes               | Yes              | No               | Yes              | Yes             | No              |

### Can QueryRenderer using Classic Environment (`Store` in `react-relay/classic`) use:

| Classic Component | Compat Component | Modern Component | Classic Mutation | Compat Mutation | Modern Mutation |
| ----------------- | ---------------- | ---------------- | ---------------- | --------------- | --------------- |
| Yes               | Yes              | No               | Yes              | Yes             | No              |

### Can QueryRenderer using Modern Environment use:

| Classic Component | Compat Component | Modern Component | Classic Mutation | Compat Mutation | Modern Mutation |
| ----------------- | ---------------- | ---------------- | ---------------- | --------------- | --------------- |
| No                | Yes              | Yes              | No               | Yes             | Yes             |

### Can React Modern Component use:

| Classic Component | Compat Component | Modern Component | Classic Mutation | Compat Mutation | Modern Mutation |
| ----------------- | ---------------- | ---------------- | ---------------- | --------------- | --------------- |
| No                | Yes              | Yes              | No               | Yes             | Yes             |

### Can React Compat Component use:

| Classic Component | Compat Component | Modern Component | Classic Mutation | Compat Mutation | Modern Mutation |
| ----------------- | ---------------- | ---------------- | ---------------- | --------------- | --------------- |
| Yes               | Yes              | Yes              | Yes\*            | Yes             | Yes             |

\* Modern API doesn't support mutation fragments. You might have to inline the mutation fragments from your legacy mutation in the fragment of the component.

### Can React Classic Component use:

| Classic Component | Compat Component | Modern Component | Classic Mutation | Compat Mutation | Modern Mutation |
| ----------------- | ---------------- | ---------------- | ---------------- | --------------- | --------------- |
| Yes               | Yes              | No               | Yes              | Yes             | No              |


---
id: conversion-playbook
title: Conversion Playbook
original_id: conversion-playbook
---
Incrementally modernize your Relay Classic app in these steps:

## Step 0: Install and configure your environment

Follow the steps outlined in the [Migration Setup](./Modern-MigrationSetup.md) guide.

## Step 1: Incrementally convert to Relay Compat

Start converting your components and mutations to use the Relay Modern APIs from the `'react-relay/compat'` module (`createFragmentContainer`, `createRefetchContainer`, `createPaginationContainer`, `commitMutation`). It will be easier to go from the leaf components up. The [conversion scripts](https://github.com/relayjs/relay-codemod) should make this step less tedious.

If a fragment uses variables that are determined at runtime, [see below](#note-determining-variable-values-at-runtime).

## Step 2: Introduce `<QueryRenderer>`

Once all the components and mutations have been converted to use the Relay Modern APIs, convert to using `QueryRenderer` instead of using `Relay.Renderer` or `Relay.RootContainer`. You may supply `Store` from `'react-relay/classic'` as the `environment` for most cases.

## Step 3: Introduce Relay Modern runtime

Once a few or all of your views are using `QueryRenderer`, `Store` from `'react-relay/classic'` could be replaced with a `RelayModernEnvironment`. Keep in mind that `RelayModernEnvironment` and `Store` do not share any data. You might want to hold off on this step until views that have significant data overlap can be switched over at the same time. This step is what unlocks the perf wins for your app. Apps using the `RelayModernEnvironment` get to send persisted query IDs instead of the full query strings to the server, as well as much more optimized data normalizing and processing.

## Step 4: Clean up by replacing Relay Compat with Relay Modern.

Switch the `'react-relay/compat'` references in your app to `'react-relay'`. This is more of a clean-up step that prevents your app from pulling in unnecessary `'react-relay/classic'` code.

## Note: Determining variable values at runtime

There is currently only one supported way to set the initial value of a variable dynamically: using global variables defined on the query that includes the fragment (or via `variables` on the `QueryRenderer`).

For example, if `currentDate` is set in `QueryRenderer` `variables`, then $currentDate may be referenced in any fragment included in the `QueryRenderer` `query`.

If you're using `createRefetchContainer` then your `refetch` method may also update these variables to render with new values.


---
id: conversion-scripts
title: Conversion Scripts
original_id: conversion-scripts
---
We built a few scripts to help you with the conversion process. Check them out at [github.com/relayjs/relay-codemod](https://github.com/relayjs/relay-codemod).


---
id: converting-mutations
title: Converting Mutations
original_id: converting-mutations
---
We made some changes to how mutations work in the new version of Relay in order to makes them more straight forward to use and more customizable. Mutations are currently not covered by an automatic conversion and require a manual upgrade. However, limited number of changes is needed to make your existing mutations work with both the old and new environment.

## Simplifying FatQueries to Standard GraphQL Queries

FatQueries in Relay Classic mutations was a concept that was confusing for a number of people. It required Relay to keep track of a significant amount of metadata regarding each record and automatically figure out the query to send to the server for the mutation. The logic to deduce the queries to send to the server was both complicated to maintain and slow to run. On top of that, we often had questions about why a particular field is included or skipped. We decided to allow people to have more control by allowing them write out exactly what data they want to update as the result of a mutation. Both individual fields and fragments can be included in these queries. Similar to container fragments, this is subjected to masking. That means only fields listed out directly will be accessible in the callbacks and the updater functions. The data fetched by in referenced fragments will still be updated in the store.

Example of existing fat query:

```javascript
  RelayClassic.QL`
    fragment on MarkReadNotificationResponsePayload @relay(pattern: true) {
      notification
    }
  `;
```

Example of converted mutation query:

```javascript
graphql`
  mutation MarkReadNotificationMutation(
    $input: MarkReadNotificationData!
  ) {
    markReadNotification(data: $input) {
      notification {
        seenState # include fields to be updated
        ... MyNotificationComponent_notification # reuse fragments from components to be updated
      }
    }
  }
`;
```

## Migrating Configs

### FIELDS_CHANGE

This is no longer needed in Compatibility Mode for neither environments. Relay will normalized the data using the mutation query and id to update the store automatically. You can remove it completely.

### REQUIRED_CHILDREN

This is no longer needed in Compatibility Mode for neither environments. Simply include any fields that you need as part of the mutation query without specifying the config.

### RANGE_ADD

`RANGE_ADD` needs one additional property in the config named `connectionInfo` to work with the new environment. Learn more about `connectionInfo` [Mutation/RANGE_ADD](./Modern-Mutations.md#range-add)

### RANGE_DELETE

`RANGE_DELETE` needs one additional property in the config named `connectionKeys` to work with the new environment. Learn more about `connectionKeys` [Mutation/RANGE_DELETE](./Modern-Mutations.md#range-delete)

### NODE_DELETE

`NODE_DELETE` config will work as-is with the new environment. No change is needed.

## Converting a Simple Mutation

Take this example of a simple mutation in Relay Classic:

```javascript
class LikeStoryMutation extends RelayClassic.Mutation {
  getMutation() {
    return RelayClassic.QL`mutation {likeStory}`;
  }

  getVariables() {
    return {storyID: this.props.story.id};
  }

  getFatQuery() {
    return RelayClassic.QL`
      fragment on LikeStoryPayload @relay(pattern: true) {
        story {
          likers,
          likeSentence,
          viewerDoesLike,
        },
      }
    `;
  }

  getConfigs() {
    return [{
      type: 'FIELDS_CHANGE',
      fieldIDs: {
        story: this.props.story.id,
      },
    }];
  }

  static fragments = {
    story: () => Relay.QL`
      fragment on Story {
        id
      }
    `,
  };
}
```

### Converting `getMutation()` and `getFatQuery()`

We combine these two into a regular GraphQL mutation, which list out specific fields that needs to be updated.

```javascript
const mutation = graphql`
  mutation LikeStoryMutation($input: LikeStoryData!) {
    story(data: $input) {
      likers {
        count
      }
      likeSentence
      viewerDoesLike
    }
  }
`;
```

### Converting `getConfigs()`

As specified above, `FIELDS_CHANGE` configs can be omitted.

### Converting `getVariables()`

To convert `getVariables()`, we take the return value from the original function and wrap it in an object that contains a property that matches the variable name for the mutation. In this case, the mutation has a `input` variable that is of type `LikeStoryData`.

```javascript
const variables = {
  input: {
    storyID: args.storyID
  }
}
```

### Final Result

As you can see, our resulting mutation is a lot simpler and more like regular GraphQL than the Relay Classic version we started out with.

```javascript
const mutation = graphql`
  mutation LikeStoryMutation($input: LikeStoryData!) {
    story {
      likers {
        count
      },
      likeSentence,
      viewerDoesLike
    }
  }
`;

// environment should be passed in from your component as this.props.relay.environment
function commit(environment: CompatEnvironment, args) {
  const variables = {
    input: {
      storyID: args.storyID
    }
  };

  return commitMutation(environment, {
    mutation,
    variables,
  });
}
```

See [Mutation](Modern-Mutations.md) for additional options on `commitMutation` for more complex mutations.


---
id: relay-debugging
title: Debugging
original_id: relay-debugging
---
If you're new to Relay, we provide some basic debugging strategies that should serve to help you clarify key concepts as you build your app. Alternatively, Relay provides a couple of tools to inspect the store and its records.

## Strategies

**Given:** You've properly setup your schema on the backend and React on the frontend. You've read through the documents but can't seem to identify what's wrong with your code. You've even done a number of searches but can't find the answer you're looking for.

**A few questions to ask yourself:**

-   _Is my [compilation](Introduction-InstallationAndSetup.md#set-up-relay-compiler) up-to-date?_
-   _Is my query valid?_ You can test this on your GraphiQL endpoint.

**If so:**

1.  Put your entire query at the top-level (your `QueryRenderer`) and comment out all fragment containers. Pass the data through your component hierarchy down to the components that were using fragments.
2.  If your app isn't rendering properly, use `console.log(props);` for every component to see the props you are actually passing.
3.  Once your app is rendering, uncomment the deepest fragment container and add that fragment back to your top-level query. Everything should still render. If not, use `console.log(props);` again.
4.  Continue uncommenting fragments and confirming that your app renders until your top-level query is as desired.
5.  If this still fails, come back to your code later and try debugging with a fresh mind. Additionally, you can [post an issue](https://github.com/facebook/relay/issues/new) and someone should get back to you hopefully within a few days.

## Tools

Relay DevTools is tool designed to help developers inspect their Relay state and understand how store changes overtime. Relay DevTools ships in two ways:

-   [Chrome Extension][extension] creates a Relay tab in the developer tools interface for debugging apps in Chrome

![Store Explorer](/img/docs/store-explorer-updated.png)
![Mutations View](/img/docs/mutations-view-updated.png)

[extension]: https://chrome.google.com/webstore/detail/relay-developer-tools/ncedobpgnmkhcmnnkcimnobpfepidadl

[app]: https://www.npmjs.com/package/relay-devtools


---
id: fragment-container
title: Fragment Container
original_id: fragment-container
---
A Fragment Container is a [higher-order component](https://reactjs.org/docs/higher-order-components.html) that allows components to specify their data requirements. A container does not directly fetch data, but instead declares a _specification_ of the data needed for rendering, and then Relay will guarantee that this data is available _before_ rendering occurs.

Table of Contents:

-   [`createFragmentContainer`](#createfragmentcontainer)
-   [Example](#example)
-   [Container Composition](#container-composition)
-   [Rendering Containers](#rendering-containers)

## `createFragmentContainer`

`createFragmentContainer` has the following signature:

```javascript
createFragmentContainer(
  component: ReactComponentClass,
  fragmentSpec: {[string]: GraphQLTaggedNode},
): ReactComponentClass;
```

### Arguments

-   `component`: The React Component _class_ of the component requiring the fragment data.
-   `fragmentSpec`: Specifies the data requirements for the Component via a GraphQL fragment. The required data will be available on the component as props that match the shape of the provided fragment. `fragmentSpec` should be an object whose keys are prop names and values are `graphql` tagged fragments. Each key specified in this object will correspond to a prop available to the resulting Component.
    -   **Note:** `relay-compiler` enforces fragments to be named as `<FileName>_<propName>`.

### Available Props

The Component resulting from `createFragmentContainer` will receive the following `props`:

```

type Props = {
  relay: {
    environment: Environment,
  },
  // Additional props as specified by the fragmentSpec
}
```

-   `relay`:
    -   `environment`: The current [Relay Environment](Modern-RelayEnvironment.md)

## Example

To start, let's build the plain React version of a hypothetical `<TodoItem />` component that displays the text and completion status of a `Todo`.

### React Component

Here's a basic implementation of `<TodoItem />` that ignores styling in order to highlight the functionality:

```javascript
// TodoItem.js
class TodoItem extends React.Component {
  render() {
    // Expects the `item` prop to have the following shape:
    // {
    //   item: {
    //     text,
    //     isComplete
    //   }
    // }
    const item = this.props.item;
    return (
      <View>
        <Checkbox checked={item.isComplete} />
        <Text>{item.text}</Text>
      </View>
    );
  }
}
```

### Data Dependencies With GraphQL

In Relay, data dependencies are described using [GraphQL](https://github.com/facebook/graphql). For `<TodoItem />`, the dependency can be expressed as follows. Note that this exactly matches the shape that the component expected for the `item` prop.

```javascript
graphql`
  # This fragment only applies to objects of type 'Todo'.
  fragment TodoItem_item on Todo {
    text
    isComplete
  }
`

```

### Defining Containers

Given the plain React component and a GraphQL fragment, we can now define a Fragment Container to specify this component's data requirements. Let's look at the code first and then see what's happening:

```javascript
// TodoItem.js
import {createFragmentContainer, graphql} from 'react-relay';

class TodoItem extends React.Component // as above

// Export a *new* React component that wraps the original `<TodoItem>`.
export default createFragmentContainer(TodoItem, {
  // For each of the props that depend on server data, we define a corresponding
  // key in this object. Here, the component expects server data to populate the
  // `item` prop, so we'll specify the fragment from above at the `item` key.
  item: graphql`
    fragment TodoItem_item on Todo {
      text
      isComplete
    }
  `,
});
```

## Container Composition

React and Relay support creating arbitrarily complex applications through _composition_. Larger components can be created by composing smaller components, helping us to create modular, robust applications.

Let's explore how this works via a `<TodoList />` component that composes the `<TodoItem />` we defined above.

### Composing Views

View composition is _exactly_ what you're used to â€” Relay containers are just standard React components. Here's the `<TodoList />` component:

```javascript
class TodoList extends React.Component {
  render() {
    // Expects a `list` with a string `title`, as well as the information
    // for the `<TodoItem>`s (we'll get that next).
    const list = this.props.list;
    return (
      <View>
        <Text>{list.title}</Text>
        {list.todoItems.map(item => <TodoItem
          // It works just like a React component, because it is one!
          item={item}
        />)}
      </View>
    );
  }
}
```

### Composing Fragments

Fragment composition works similarly â€” a parent container's fragment composes the fragment for each of its children. In this case, `<TodoList />` needs to fetch information about the `Todo`s that are required by `<TodoItem />`.

```javascript
class TodoList extends React.Component // as above

export default createFragmentContainer(TodoList, {
  // This `list` fragment corresponds to the prop named `list` that is
  // expected to be populated with server data by the `<TodoList>` component.
  list: graphql`
    fragment TodoList_list on TodoList {
      # Specify any fields required by '<TodoList>' itself.
      title
      # Include a reference to the fragment from the child component.
      todoItems {
        ...TodoItem_item
      }
    }
  `,
});
```

Note that when composing fragments, the type of the composed fragment must match the field on the parent in which it is embedded. For example, it wouldn't make sense to embed a fragment of type `Story` into a parent's field of type `User`. Relay and GraphQL will provide helpful error messages if you get this wrong (and if they aren't helpful, let us know!).

### Passing Arguments to a Fragment

#### `@argumentDefinitions`

When defining a fragment, you can use the [`@argumentDefinitions`](Modern-GraphQLInRelay.md#argumentdefinitions) directive to specify any arguments, with potentially default values, that the fragment expects.

For example, let's redefine our `TodoList_list` fragment to take some arguments using `@argumentDefinitions`:

```graphql
fragment TodoList_list on TodoList @argumentDefinitions(
  count: {type: "Int", defaultValue: 10},  # Optional argument
  userID: {type: "ID"},                    # Required argument
) {
  title
  todoItems(userID: $userID, first: $count) {  # Use fragment arguments here as variables
    ...TodoItem_item
  }
}
```

Any arguments defined inside `@argumentDefinitions` will be local variables available inside the fragment's scope. However, a fragment can also reference global variables that were defined in the root query.

#### `@arguments`

In order to pass arguments to a fragment that has `@argumentDefinitions`, you need to use the [`@arguments`](Modern-GraphQLInRelay.md#arguments) directive.

Following our `TodoList_list` example, we would pass arguments to the fragment like so:

```graphql
query TodoListQuery($count: Int, $userID: ID) {
  ...TodoList_list @arguments(count: $count, userID: $userID) # Pass arguments here
}
```

## Rendering Containers

As we've learned, Relay fragment containers only declare data requirements as GraphQL fragments. In order to actually fetch and render the specified data, we need to use a `QueryRenderer` component to render a root query and any fragment containers included within. Please refer to our [`QueryRenderer`](Modern-QueryRenderer.md) docs for more details.


---
id: graphql-in-relay
title: GraphQL in Relay
original_id: graphql-in-relay
---
Table of Contents:

-   [`graphql`](#graphql)
-   [Directives](#directives)
-   [Relay Compiler](#relay-compiler)

## `graphql`

The `graphql` template tag provided by Relay serves as the mechanism to write queries, fragments, mutations or subscriptions in the [GraphQL](http://graphql.org/learn/) language. For example:

```javascript
import {graphql} from 'react-relay';

graphql`
  query MyQuery {
    viewer {
      id
    }
  }
`;
```

The result of using the `graphql` template tag is a `GraphQLTaggedNode`; a runtime representation of the GraphQL document which can be used to define [Query Renderers](Modern-QueryRenderer.md), [Fragment Containers](Modern-FragmentContainer.md), [Refetch Containers](Modern-RefetchContainer.md), [Pagination Containers](Modern-PaginationContainer.md), etc.

Note that `graphql` template tags are **never executed at runtime**. Instead, they are compiled ahead of time by the [Relay Compiler](#relay-compiler) into generated artifacts that live alongside your source code, and which Relay requires to operate at runtime. The [Relay Babel plugin](Introduction-InstallationAndSetup.md#setup-babel-plugin-relay) will then convert the `graphql` literals in your code into `require()` calls for the generated files.

## Directives

Relay uses directives to add additional information to GraphQL documents, which are used by the [Relay Compiler](#relay-compiler) to generate the appropriate runtime artifacts. These directives only appear in your application code and are removed from requests sent to your GraphQL server.

**Note:** The relay-compiler will maintain any directives supported by your server (such as `@include` or `@skip`) so they remain part of the request to the GraphQL server and won't alter generated runtime artifacts.

### `@arguments`

`@arguments` is a directive used to pass arguments to a fragment that was defined using [`@argumentDefinitions`](#argumentdefinitions). For example:

```graphql
query TodoListQuery($userID: ID) {
  ...TodoList_list @arguments(count: $count, userID: $userID) # Pass arguments here
}
```

See the [Fragment Container docs](Modern-FragmentContainer.md#passing-arguments-to-a-fragment) for more details.

### `@argumentDefinitions`

`@argumentDefinitions` is a directive used to specify arguments taken by a fragment. For example:

```graphql
fragment TodoList_list on TodoList @argumentDefinitions(
  count: {type: "Int", defaultValue: 10},  # Optional argument
  userID: {type: "ID"},                    # Required argument
) {
  title
  todoItems(userID: $userID, first: $count) {  # Use fragment arguments here as variables
    ...TodoItem_item
  }
}
```

See the [Fragment Container docs](Modern-FragmentContainer.md#passing-arguments-to-a-fragment) for more details.

### `@connection(key: String!, filters: [String])`

When using the [Pagination Container](Modern-PaginationContainer.md), Relay expects connection fields to be annotated with a `@connection` directive. For more detailed information and an example, check out the [docs on using `@connection` inside a Pagination Container](Modern-PaginationContainer.md#connection).

### `@relay(plural: Boolean)`

When defining a fragment for use with a Fragment container, you can use the `@relay(plural: true)` directive to indicate that container expects the prop for that fragment to be a list of items instead of a single item. A query or parent that spreads a `@relay(plural: true)` fragment should do so within a plural field (ie a field backed by a [GraphQL list](http://graphql.org/learn/schema/#lists-and-non-null). For example:

```javascript
// Plural fragment definition
graphql`
fragment TodoItems_items on TodoItem @relay(plural: true) {
  id
  text
}`;

// Plural fragment usage: note the parent type is a list of items (`TodoItem[]`)
fragment TodoApp_app on App {
  items {
    // parent type is a list here
    ...TodoItem_items
  }
}
```

### `@inline`

By default, Relay will only expose the data for fields explicitly requested by a [component's fragment](Modern-FragmentContainer.md#createfragmentcontainer), which is known as [data masking](PrinciplesAndArchitecture-ThinkingInRelay.md#data-masking). Fragment data is unmasked for use in React components by `createFragmentContainer`. However, you may want to use fragment data in non-React functions that are called from React.

Non-React functions can also take advantage of data masking. A fragment can be defined with the `@inline` directive and stored in a local variable. The non-React function can then "unmask" the data using the `readInlineData` function.

In the example below, the function `processItemData` is called from a React component. It requires an item object with a specific set of fields. All React components that use this function should spread the `processItemData_item` fragment to ensure all of the correct item data is loaded for this function.

```javascript
import {graphql, readInlineData} from 'react-relay';

// non-React function called from React
function processItemData(itemRef) {
  const item = readInlineData(graphql`
    fragment processItemData_item on Item @inline {
      title
      price
      creator {
        name
      }
    }
  `, itemRef);
  sendToThirdPartyApi({
    title: item.title,
    price: item.price,
    creatorName: item.creator.name
  });
}
```

```javascript
// React Component
function MyComponent({item}) {
  function handleClick() {
    processItemData(item);
  }

  return (
    <button onClick={handleClick}>Process {item.title}</button>
  );
}

export default createFragmentContainer(MyComponent, {
  item: graphql`
    fragment MyComponent_item on Item {
      ...processItemData_item
      title
    }
  `
});
```

### `@relay(mask: Boolean)`

 It is not recommended to use `@relay(mask: false)`. Please instead consider using the `@inline` fragment.

`@relay(mask: false)` can be used to prevent data masking; when including a fragment and annotating it with `@relay(mask: false)`, its data will be available directly to the parent instead of being masked for a different container.

Applied to a fragment definition, `@relay(mask: false)` changes the generated Flow types to be better usable when the fragment is included with the same directive. The Flow types will no longer be exact objects and no longer contain internal marker fields.

This may be helpful to reduce redundant fragments when dealing with nested or recursive data within a single Component.

Keep in mind that it is typically considered an **anti-pattern** to create a single fragment shared across many containers. Abusing this directive could result in over-fetching in your application.

In the example below, the `user` prop will include the data for `id` and `name` fields wherever `...Component_internUser` is included, instead of Relay's normal behavior to mask those fields:

```javascript
graphql`
  fragment Component_internUser on InternUser @relay(mask: false) {
    id
    name
  }
`;

export default createFragmentContainer(
  ({ user }) => /* ... */,
  graphql`
    fragment Component_user on User {
      internUser {
        manager {
          ...Component_internUser @relay(mask: false)
        }
        ... on Employee {
          admins {
            ...Component_internUser @relay(mask: false)
          }
          reports {
            ...Component_internUser @relay(mask: false)
          }
        }
      }
    }
  `,
);
```

## Relay Compiler

Relay uses the Relay Compiler to convert [`graphql`](#graphql) literals into generated files that live alongside your source files.

A query like the following:

```javascript
graphql`
  fragment MyComponent on Type {
    field
  }
`

```

Will cause a generated file to appear in `./__generated__/MyComponent.graphql`,
with both runtime artifacts (which help to read and write from the Relay Store)
and [Flow types](https://flow.org/) to help you write type-safe code.

The Relay Compiler is responsible for generating code as part of a build step which can then be referenced at runtime. By building the query ahead of time, the Relay's runtime is not responsible for generating a query string, and various optimizations can be performed on the query that could be too expensive at runtime (for example, fields that are duplicated in the query can be merged during the build step, to improve efficiency of processing the GraphQL response).

### Persisting queries

Relay Compiler supports the use of **persisted queries**, in which each version of a query is associated to a unique ID on the server and the runtime uploads only the persisted ID instead of the full query text. This has several benefits: it can significantly reduce the time to send a query (and the upload bytes) and enables _whitelisting_ of queries. For example, you may choose to disallow queries in text form and only allow queries that have been persisted (and that presumably have passed your internal code review process).

Persisted queries can be enabled by instructing Relay Compiler to emit metadata about each query, mutation, and subscription into a JSON file. The generated file will contain a mapping of query identifiers to query text, which you can then save to your server. To enable persisted queries, use the `--persist-output` flag to the compiler:

```javascript
"scripts": {
  "relay": "relay-compiler --src ./src --schema ./schema.graphql --persist-output ./path/to/persisted-queries.json"
}
```

Relay Compiler will then create the id =&gt; query text mapping in the path you specify. You can then use this complete
json file in your server side to map query ids to operation text.

For more details, refer to the [Persisted Queries section](Modern-PersistedQueries.md).

### Set up relay-compiler

See our relay-compiler section in our [Installation and Setup guide](Introduction-InstallationAndSetup.md#set-up-relay-compiler).

### GraphQL Schema

To use the Relay Compiler, you need either a .graphql or .json GraphQL schema file, describing your GraphQL server's API. Typically these files are local representations of a server source of truth and are not edited directly. For example, we might have a `schema.graphql` like:

```graphql
schema {
  query: Root
}

type Root {
  dictionary: [Word]
}

type Word {
  id: String!
  definition: WordDefinition
}

type WordDefinition {
  text: String
  image: String
}
```

### Source files

Additionally, you need a directory containing `.js` files that use the `graphql` tag to describe GraphQL queries and fragments. Let's call this `./src`.

Then run `yarn run relay` as set up before.

This will create a series of `__generated__` directories that are co-located with the corresponding files containing `graphql` tags.

For example, given the two files:

-   `src/Components/DictionaryComponent.js`

    ```javascript
    const DictionaryWordFragment = graphql`
      fragment DictionaryComponent_word on Word {
        id
        definition {
          ...DictionaryComponent_definition
        }
      }
    `

    const DictionaryDefinitionFragment = graphql`
      fragment DictionaryComponent_definition on WordDefinition {
        text
        image
      }
    `

    ```

-   `src/Queries/DictionaryQuery.js`

    ```javascript
    const DictionaryQuery = graphql`
      query DictionaryQuery {
        dictionary {
          ...DictionaryComponent_word
        }
      }
    `

    ```

This would produce three generated files, and two `__generated__` directories:

-   `src/Components/__generated__/DictionaryComponent_word.graphql.js`
-   `src/Components/__generated__/DictionaryComponent_definition.graphql.js`
-   `src/Queries/__generated__/DictionaryQuery.graphql.js`

### Importing generated definitions

Typically you will not need to import your generated definitions. The [Relay Babel plugin](Introduction-InstallationAndSetup.md#setup-babel-plugin-relay) will then convert the `graphql` literals in your code into `require()` calls for the generated files.

However the Relay Compiler also automatically generates [Flow](https://flow.org) types as [type comments](https://flow.org/en/docs/types/comments/). For example, you can import the generated Flow types like so:

```javascript
import type {DictionaryComponent_word} from './__generated__/DictionaryComponent_word.graphql';
```

### Client schema extensions

The Relay Compiler fully supports client-side schema extensions, which allows you to extend the server schema by defining additional GraphQL types and fields on the client. Relay expects the client schema to be located in your `--src` directory.

For example, assuming the server schema `./schema.graphql`:

```graphql
schema {
  query: Root
}

type Root {
  title: String!
}
```

We can create a `./src/clientSchema.graphql` and define a new type called `Setting`:

```graphql
type Setting {
  name: String!
  active: Boolean!
}
```

We can then extend existing server types in the client schema `./src/clientSchema.graphql` with our new `Setting` type, like so:

```graphql
extend type Root {
  settings: [Setting]
}
```

Any fields specified in the client schema, can be fetched from the [Relay Store](Modern-RelayStore.md), by selecting it in a query or fragment.

For more details, refer to the [Local state management section](Modern-LocalStateManagement.md).

### Advanced usage

In addition to the bin script, the `relay-compiler` package also [exports library code](https://github.com/facebook/relay/blob/main/packages/relay-compiler/index.js) which you may use to create more complex configurations for the compiler, or to extend the compiler with your own custom output.

If you find you need to do something unique (like generate types that conform to an older version of Flow, or to parse non-javascript source files), you can build your own version of the Compiler by swapping in your own `FileWriter` and `ASTCache`, or by adding on an additional `IRTransform`. Note, the internal APIs of the `RelayCompiler` are under constant iteration, so rolling your own version may lead to incompatibilities with future releases.


---
id: local-state-management
title: Local State Management
original_id: local-state-management
---
Relay can be used to read and write local data, and act as a single source of truth for _all_ data in your client application.
The Relay Compiler fully supports client-side extensions of the schema, which allows you to define local fields and types.

Table of Contents:

-   [Extending the server schema](#extending-the-server-schema)
-   [Querying local state](#querying-local-state)
-   [Mutating local state](#mutating-local-state)
-   [Initial local state](#initial-local-state)

## Extending the server schema

To extend the server schema, create a new `.graphql` file inside your `--src` directory.
Let's call it `./src/clientSchema.graphql`.

This schema describes what local data can be queried on the client.
It can even be used to extend an existing server schema.

For example, we can create a new type called `Note`:

```graphql
type Note {
  id: ID!
  title: String
  body: String
}
```

And then extend the server schema type `User`, with a list of `Note`, called `notes`.

```graphql
extend type User {
  notes: [Note]
}
```

## Querying local state

Accessing local data is no different from querying your GraphQL server, although you are required to include atleast one server field in the query.
The field can be from the server schema, or it can be schema agnostic, like an introspection field (i.e. `__typename`).

Here, we use a [QueryRenderer](Modern-QueryRenderer.md) to get the current `User` via the `viewer` field, along with their id, name and the local list of notes.

```javascript
// Example.js
import React from 'react';
import { QueryRenderer, graphql } from 'react-relay';

const renderQuery = ({error, props}) => {
  if (error) {
    return <div>{error.message}</div>;
  } else if (props) {
    return (
      <div>
        {props.viewer.notes.map(({id, title, body}) => (
          <div key={id}>
            {title}
          </div>
          <div key={id}>
            {body}
          </div>
        ))}
      </div>
    );
  }
  return <div>Loading</div>;
}

const Example = (props) => {
  return (
    <QueryRenderer
      render={renderQuery}
      environment={environment}
      query={graphql`
        query ExampleQuery {
          viewer {
            id
            name
            notes {
              id
              title
              body
            }
          }
        }
      `}
    />
  );
}
```

## Mutating local state

All local data lives in the [Relay Store](Modern-RelayStore.md).
Updating local state can be done with any `updater` function.
The `commitLocalUpdate` function is especially ideal for this, because writes to local state are usually executed outside of a mutation.

To build upon the previous example, let's try creating, updating and deleting a `Note` from the list of `notes` on `User`.

### Create

```javascript
import {commitLocalUpdate} from 'react-relay';

let tempID = 0;

function createUserNote() {
  commitLocalUpdate(environment, store => {
    const user = store.getRoot().getLinkedRecord('viewer');
    const userNoteRecords = user.getLinkedRecords('notes') || [];

    // Create a unique ID.
    const dataID = `client:Note:${tempID++}`;

    //Create a new note record.
    const newNoteRecord = store.create(dataID, 'Note');

    // Add the record to the user's list of notes.
    user.setLinkedRecords([...userNoteRecords, newNoteRecord], 'notes');
  });
}
```

Note that since this record will be rendered by the `ExampleQuery` in our `QueryRenderer`, the QueryRenderer will automatically retain this data so it isn't garbage collected.

If no component is rendering the local data and you want to manually retain it, you can do so by calling `environment.retain()`:

```javascript
import {createOperationDescriptor, getRequest} from 'relay-runtime';

// Create a query that references that record
const localDataQuery = graphql`
  query LocalDataQuery {
    viewer {
      notes {
        __typename
      }
    }
  }
`;

// Create an operation descriptor for the query
const request = getRequest(localDataQuery);
const operation = createOperationDescriptor(request, {} /* variables */);


// Tell Relay to retain this operation so any data referenced by it isn't garbage collected
// In this case, all the notes linked to the `viewer` will be retained
const disposable = environment.retain(operation);


// Whenever you don't need that data anymore and it's okay for Relay to garbage collect it,
// you can dispose of the retain
disposable.dispose();
```

### Update

```javascript
import {commitLocalUpdate} from 'react-relay';

function updateUserNote(dataID, body, title) {
  commitLocalUpdate(environment, store => {
    const note = store.get(dataID);

    note.setValue(body, 'body');
    note.setValue(title, 'title')
  });
}
```

### Delete

```javascript
import {commitLocalUpdate} from 'react-relay';

function deleteUserNote(dataID) {
  commitLocalUpdate(environment, store => {
    const user = store.getRoot().getLinkedRecord('viewer');
    const userNoteRecords = user.getLinkedRecords('notes');

    // Remove the note from the list of user notes.
    const newUserNoteRecords = userNoteRecords.filter(x => x.getDataID() !== dataID);

    // Delete the note from the store.
    store.delete(dataID);

    // Set the new list of notes.
    user.setLinkedRecords(newUserNoteRecords, 'notes');
  });
}
```

## Initial local state

All new client-side schema fields default to `undefined` value. Often however, you will want to set the initial state before querying local data.
You can use an updater function via `commitLocalUpdate` to prime local state.

```javascript
import {commitLocalUpdate} from 'react-relay';

commitLocalUpdate(environment, store => {
  const user = store.getRoot().getLinkedRecord('viewer');

  // initialize user notes to an empty array.
  user.setLinkedRecords([], 'notes');
});
```


---
id: migration-setup
title: Migration Setup
original_id: migration-setup
---
## Installation

Follow the installation instructions from the [Installation and Setup](Introduction-InstallationAndSetup.md) guide.

## Set up babel-plugin-relay for Relay Classic

With some additional configuration, the `"relay"` babel plugin can also translate
Relay Classic `Relay.QL` literals. Most importantly, include a reference to your GraphQL Schema as either a json file or graphql schema file.

```javascript
{
  "plugins": [
    ["relay", {"schema": "path/schema.graphql"}]
  ]
}
```

## Set up babel-plugin-relay for "[compatibility mode](Modern-RelayCompat.md)"

When incrementally converting a Relay Classic app to Relay Modern, `graphql`
literals can be translated to be usable by _both_ runtimes if configured to use
compatibility mode:

```javascript
{
  "plugins": [
    ["relay", {"compat": true, "schema": "path/schema.graphql"}]
  ]
}
```

## Additional Options

The Relay Classic and Relay Compat modes produce generated content inline and may
catch and log any detected GraphQL validation errors, leaving those errors to be
thrown at runtime.

When compiling code for production deployment, the plugin can be configured to immediately throw upon encountering a validation problem. The plugin can be further customized for different environments with the following options:

```javascript
{
  "plugins": [
    ["relay", {
      "compat": true,
      "schema": "path/schema.graphql",
    }]
  ]
}
```


---
id: mutations
title: Mutations
original_id: mutations
---
Table of Contents:

-   [`commitMutation`](#commitmutation)
-   [Simple Example](#simple-example)
-   [Optimistic Updates](#optimistic-updates)
-   [Updater Configs](#updater-configs)
-   [Using updater and optimisticUpdater](#using-updater-and-optimisticupdater)
-   [Committing Local Updates](#committing-local-updates)

## `commitMutation`

Use `commitMutation` to create and execute mutations. `commitMutation` has the following signature:

```javascript
commitMutation(
  environment: Environment,
  config: {
    mutation: GraphQLTaggedNode,
    variables: {[name: string]: mixed},
    onCompleted?: ?(response: ?Object, errors: ?Array<PayloadError>) => void,
    onError?: ?(error: Error) => void,
    optimisticResponse?: Object,
    optimisticUpdater?: ?(store: RecordSourceSelectorProxy) => void,
    updater?: ?(store: RecordSourceSelectorProxy, data: SelectorData) => void,
    configs?: Array<DeclarativeMutationConfig>,
    cacheConfig?: CacheConfig,
  },
);
```

### Arguments

-   `environment`: The [Relay Environment](Modern-RelayEnvironment.md). **Note:** To ensure the mutation is performed on the correct `environment`, it's recommended to use the environment available within components (from `this.props.relay.environment`), instead of referencing a global environment.
-   `config`:
    -   `mutation`: The `graphql` tagged mutation query.
    -   `variables`: Object containing the variables needed for the mutation. For example, if the mutation defines an `$input` variable, this object should contain an `input` key, whose shape must match the shape of the data expected by the mutation as defined by the GraphQL schema.
    -   `onCompleted`: Callback function executed when the request is completed and the in-memory Relay store is updated with the `updater` function. Takes a `response` object, which is the updated response from the store, and `errors`, an array containing any errors from the server.
    -   `onError`: Callback function executed if Relay encounters an error during the request.
    -   `optimisticResponse`: Object containing the data to optimistically update the local in-memory store, i.e. immediately, before the mutation request has completed. This object must have the same shape as the mutation's response type, as defined by the GraphQL schema. If provided, Relay will use the `optimisticResponse` data to update the fields on the relevant records in the local data store, _before_ `optimisticUpdater` is executed. If an error occurs during the mutation request, the optimistic update will be rolled back.
    -   `optimisticUpdater`: Function used to optimistically update the local in-memory store, i.e. immediately, before the mutation request has completed. If an error occurs during the mutation request, the optimistic update will be rolled back.
        This function takes a `store`, which is a proxy of the in-memory [Relay Store](Modern-RelayStore.md). In this function, the client defines 'how to' update the local data via the `store` instance. For details on how to use the `store`, please refer to our [Relay Store API Reference](Modern-RelayStore.md).
        **Please note:**
        -   It is usually preferable to just pass an `optimisticResponse` option instead of an `optimisticUpdater`, unless you need to perform updates on the local records that are more complicated than just updating fields (e.g. deleting records or adding items to collections).
        -   If you do decide to use an `optimisticUpdater`, often times it can be the same function as `updater`.
    -   `updater`: Function used to update the local in-memory store based on the **real** server response from the mutation. If `updater` is not provided, by default, Relay will know to automatically update the fields on the records referenced in the mutation response; however, you should pass an `updater` if you need to make more complicated updates than just updating fields (e.g. deleting records or adding items to collections).
        When the server response comes back, Relay first reverts any changes introduced by `optimisticUpdater` or `optimisticResponse` and will then execute `updater`.
        This function takes a `store`, which is a proxy of the in-memory [Relay Store](Modern-RelayStore.md). In this function, the client defines 'how to' update the local data based on the server response via the `store` instance. For details on how to use the `store`, please refer to our [Relay Store API Reference](Modern-RelayStore.md).
    -   `configs`:  Array containing objects describing `optimisticUpdater`/`updater` configurations. `configs` provides a convenient way to specify the `updater` behavior without having to write an `updater` function. See our section on [Updater Configs](#updater-configs) for more details.
    -   `cacheConfig?`: Optional object containing a set of cache configuration options

## Simple Example

Example of a simple mutation:

```javascript
import {commitMutation, graphql} from 'react-relay';

const mutation = graphql`
  mutation MarkReadNotificationMutation(
    $storyID: ID!
  ) {
    markReadNotification(id: $storyID) {
      notification {
        seenState
      }
    }
  }
`;

function markNotificationAsRead(environment, storyID) {
  const variables = {
    storyID,
  };

  commitMutation(
    environment,
    {
      mutation,
      variables,
      onCompleted: (response, errors) => {
        console.log('Response received from server.')
      },
      onError: err => console.error(err),
    },
  );
}
```

## Optimistic Updates

To improve perceived responsiveness, you may wish to perform an "optimistic update", in which the client immediately updates to reflect the anticipated new value even before the response from the server has come back. The simplest way to do this is by providing an `optimisticResponse` and adding it to the `config` that we pass into `commitMutation`:

```javascript
const mutation = graphql`
  mutation MarkReadNotificationMutation(
    $storyID: ID!
  ) {
    markReadNotification(id: $storyID) {
      notification {
        seenState
      }
    }
  }
`;

const optimisticResponse = {
  markReadNotification: {
    notification: {
      seenState: SEEN,
    },
  },
};

commitMutation(
  environment,
  {
    mutation,
    optimisticResponse,
    variables,
  },
);
```

Another way to enable optimistic updates is via the `optimisticUpdater`, which can be used for more complicated update scenarios. Using `optimisticUpdater` is covered in the section [below](#using-updater-and-optimisticupdater).

## Updater Configs

We can give Relay instructions in the form of a `configs` array on how to use the response from each mutation to update the client-side store. We do this by configuring the mutation with one or more of the following config types:

### NODE_DELETE

Given a `deletedIDFieldName`, Relay will remove the node(s) from the store.

**Note**: this will not remove it from any connection it might be in. If you want to remove a node from a connection, take a look at [RANGE_DELETE](#RANGE_DELETE).

#### Arguments

-   `deletedIDFieldName: string`: The field name in the response that contains the DataID or DataIDs of the deleted node or nodes

#### Example

```javascript
const mutation = graphql`
  mutation DestroyShipMutation($target: ID!) {
    destroyShip(target: $target) {
      destroyedShipId
      faction {
        ships {
          id
        }
      }
    }
  }
`;

const configs = [{
  type: 'NODE_DELETE',
  deletedIDFieldName: 'destroyedShipId',
}];
```

### RANGE_ADD

Given a parent, information about the connection, and the name of the newly created edge in the response payload Relay will add the node to the store and attach it to the connection according to the range behavior(s) specified in the connectionInfo.

#### Arguments

-   `parentID: string`: The DataID of the parent node that contains the
    connection.
-   `connectionInfo: Array<{key: string, filters?: Variables, rangeBehavior:
    string}>`: An array of objects containing a connection key, an object
    containing optional filters, and a range behavior depending on what behavior we expect (append, prepend, or ignore).
    -   `filters`: An object containing GraphQL calls e.g. `const filters = {'orderby': 'chronological'};`.
-   `edgeName: string`: The field name in the response that represents the newly created edge

#### Example

```javascript
const mutation = graphql`
  mutation AddShipMutation($factionID: ID!, $name: String!) {
    addShip(factionID: $factionID, name: $name) {
      shipEdge {
        node {
          name
        }
      }
    }
  }
`;

function commit(environment, factionID, name) {
  return commitMutation(environment, {
    mutation,
    variables: {
      factionID,
      name,
    },
    configs: [{
      type: 'RANGE_ADD',
      parentID: factionID,
      connectionInfo: [{
        key: 'AddShip_ships',
        rangeBehavior: 'append',
      }],
      edgeName: 'shipEdge',
    }],
  });
}
```

### RANGE_DELETE

Given a parent, `connectionKeys`, one or more DataIDs in the response payload, and
a path between the parent and the connection, Relay will remove the node(s)
from the connection but leave the associated record(s) in the store.

#### Arguments

-   `parentID: string`: The DataID of the parent node that contains the
    connection.
-   `connectionKeys: Array<{key: string, filters?: Variables}>`: An array of
    objects containing a connection key and optionally filters.
    -   `filters`: An object containing GraphQL calls e.g. `const filters = {'orderby': 'chronological'};`.
-   `pathToConnection: Array<string>`: An array containing the field names between the parent and the connection, including the parent and the connection.
-   `deletedIDFieldName: string | Array<string>`: The field name in the response that contains the DataID or DataIDs of the removed node or nodes, or the path to the node or nodes removed from the connection

#### Example

```javascript
const mutation = graphql`
  mutation RemoveTagMutation($todoID: ID!, $tagID: ID!) {
    removeTag(todo: $todoID, tag: $tagID) {
      removedTagID
    }
  }
`;

function commit(environment, todoID, tagID) {
  return commitMutation(environment, {
    mutation,
    variables: {
      todoID,
      tagID,
    },
    configs: [{
      type: 'RANGE_DELETE',
      parentID: todoID,
      connectionKeys: [{
        key: 'RemoveTags_tags',
      }],
      pathToConnection: ['todo', 'tags'],
      deletedIDFieldName: 'removedTagID',
    }],
  });
}
```

## Using updater and optimisticUpdater

`updater` and `optimisticUpdater` are functions that you can pass to a `commitMutation` call when you need full control over how to update the local data store, either optimistically, or based on a server response. Often times, both of these can be the same function.

When you provide these functions, this is roughly what happens during the mutation request:

-   If `optimisticResponse` is provided, Relay will use it to update the fields under the records as specified by the ids in the `optimisticResponse`.
-   If `optimisticUpdater` is provided, Relay will execute it and update the store accordingly.
-   After the network comes back, if any optimistic update was applied, it will be rolled back.
-   Relay will then automatically update the fields under the record corresponding to the ids in the response payload.
-   If an `updater` was provided, Relay will execute it and update the store accordingly. The server payload will be available to the `updater` as a root field in the store.

Here are a quick example of adding a todo item to a Todo list using this [example schema](https://github.com/relayjs/relay-examples/blob/main/todo/data/schema.graphql#L36):

```javascript
// AddTodoMutation.js
import {commitMutation, graphql} from 'react-relay';
import {ConnectionHandler} from 'relay-runtime';

const mutation = graphql`
  mutation AddTodoMutation($text: String!) {
    addTodo(text: $text) {
      todoEdge {
        cursor
        node {
          complete
          id
          text
        }
      }
      viewer {
        id
        totalCount
      }
    }
  }
`;

function sharedUpdater(store, user, newEdge) {
  // Get the current user record from the store
  const userProxy = store.get(user.id);

  // Get the user's Todo List using ConnectionHandler helper
  const conn = ConnectionHandler.getConnection(
    userProxy,
    'TodoList_todos', // This is the connection identifier, defined here
    // https://github.com/relayjs/relay-examples/blob/main/todo/js/components/TodoList.js#L76
  );

  // Insert the new todo into the Todo List connection
  ConnectionHandler.insertEdgeAfter(conn, newEdge);
}

let tempID = 0;

function commit(environment, text, user) {
  return commitMutation(environment, {
    mutation,
    variables: {
      text,
    },
    updater: (store) => {
      // Get the payload returned from the server
      const payload = store.getRootField('addTodo');

      // Get the edge of the newly created Todo record
      const newEdge = payload.getLinkedRecord('todoEdge');

      // Add it to the user's todo list
      sharedUpdater(store, user, newEdge);
    },
    optimisticUpdater: (store) => {
      // Create a Todo record in our store with a temporary ID
      const id = 'client:newTodo:' + tempID++;
      const node = store.create(id, 'Todo');
      node.setValue(text, 'text');
      node.setValue(id, 'id');

      // Create a new edge that contains the newly created Todo record
      const newEdge = store.create(
        'client:newEdge:' + tempID++,
        'TodoEdge',
      );
      newEdge.setLinkedRecord(node, 'node');

      // Add it to the user's todo list
      sharedUpdater(store, user, newEdge);

      // Given that we don't have a server response here,
      // we also need to update the todo item count on the user
      const userRecord = store.get(user.id);
      userRecord.setValue(
        userRecord.getValue('totalCount') + 1,
        'totalCount',
      );
    },
  });
}
```

For details on how to interact with the Relay Store, please refer to our Relay Store [docs](Modern-RelayStore.md).

## Committing Local Updates

Use `commitLocalUpdate` when you need to update the local store without necessarily executing a mutation (such as in the case of debounced operations). The function takes in a Relay `environment` and an `updater` function.


---
id: network-layer
title: Network Layer
original_id: network-layer
---
In order to know how to access your GraphQL server, Relay Modern requires developers to provide an object implementing the `NetworkLayer` interface when creating an instance of a [Relay Environment](Modern-RelayEnvironment.md). The environment uses this network layer to execute queries, mutations, and (if your server supports them) subscriptions. This allows developers to use whatever transport (HTTP, WebSockets, etc) and authentication is most appropriate for their application, decoupling the environment from the particulars of each application's network configuration.

Currently the easiest way to create a network layer is via a helper from the `relay-runtime` package:

```javascript
import {
  Environment,
  Network,
  RecordSource,
  Store,
} from 'relay-runtime';

// Define a function that fetches the results of an operation (query/mutation/etc)
// and returns its results as a Promise:
function fetchQuery(
  operation,
  variables,
  cacheConfig,
  uploadables,
) {
  return fetch('/graphql', {
    method: 'POST',
    headers: {
      // Add authentication and other headers here
      'content-type': 'application/json'
    },
    body: JSON.stringify({
      query: operation.text, // GraphQL text from input
      variables,
    }),
  }).then(response => {
    return response.json();
  });
}

// Create a network layer from the fetch function
const network = Network.create(fetchQuery);
const store = new Store(new RecordSource())

const environment = new Environment({
  network,
  store
  // ... other options
});

export default environment;
```

Note that this is a basic example to help you get started. This example could be extended with additional features such as request/response caching (enabled e.g. when `cacheConfig.force` is false) and uploading form data for mutations (the `uploadables` parameter).

## Caching

Relay modern makes no assumptions about what to cache and will garbage collect any data that is no longer referenced.

You have to implement your own cache strategy. A simple solution is to use `QueryResponseCache` (an in-memory cache):

```javascript
import {
  Environment,
  Network,
  QueryResponseCache,
  RecordSource,
  Store,
} from 'relay-runtime';

const oneMinute = 60 * 1000;
const cache = new QueryResponseCache({ size: 250, ttl: oneMinute });

function fetchQuery(
  operation,
  variables,
  cacheConfig,
) {
  const queryID = operation.text;
  const isMutation = operation.operationKind === 'mutation';
  const isQuery = operation.operationKind === 'query';
  const forceFetch = cacheConfig && cacheConfig.force;

  // Try to get data from cache on queries
  const fromCache = cache.get(queryID, variables);
  if (
    isQuery &&
    fromCache !== null &&
    !forceFetch
  ) {
    return fromCache;
  }

  // Otherwise, fetch data from server
  return fetch('/graphql', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      query: operation.text,
      variables,
    }),
  }).then(response => {
    return response.json();
  }).then(json => {
    // Update cache on queries
    if (isQuery && json) {
      cache.set(queryID, variables, json);
    }
    // Clear cache on mutations
    if (isMutation) {
      cache.clear();
    }

    return json;
  });
}

const environment = new Environment({
  network: Network.create(fetchQuery),
  store: new Store(new RecordSource()),
});

export default environment;
```

## Custom open-source implementations

**[react-relay-network-modern](https://github.com/relay-tools/react-relay-network-modern)** on [npm](https://www.npmjs.com/package/react-relay-network-modern) - is a Network Layer for Relay Modern which has built-in highly customizable middlewares for commonly used scenarios: batching query requests, caching, authentication, request retrying, logging. Moreover, you may write your own middlewares with custom logic.


---
id: new-in-relay-modern
title: New in Relay Modern
original_id: new-in-relay-modern
---
<blockquote>
A summary of the improvements and new features in Relay Modern.
</blockquote>

## Modern API

Compared to Relay Classic, the Relay Modern API has the following differentiating features:

-   A simpler, more predictable mutation API. The restrictions on mutation queries from Relay Classic are also removed: mutation queries are static, fields can be arbitrarily nested, and may use arbitrary arguments.
-   When using [`QueryRenderer`](Modern-QueryRenderer.md), the restrictions on queries from Relay Classic are removed: queries may contain multiple root fields that use arbitrary arguments and return singular or plural values. The `viewer` root field is now optional.
-   Routes are now optional: `QueryRenderer` can be used without defining a route. More in the [routing guide](Modern-Routing.md).
-   `QueryRenderer` supports rendering small amounts of data directly, instead of requiring a container to access data. [Containers](Modern-FragmentContainer.md) are optional and can be used as your application grows in size and complexity.
-   The API is overall simpler and more predictable.

You can use [Compat mode](Modern-RelayCompat.md) to incrementally adopt Relay Modern APIs in an existing Relay app.

## Modern Runtime

For new Relay apps or existing apps that have been fully converted to the Modern/Compat API, the Relay Modern runtime can be enabled to activate even more features. In addition to those described above, this includes:

### Performance

The new Relay Modern core is more light-weight and significantly faster than the previous version. It is redesigned to work with static queries, which allow us to push more work to build/compilation time. The Modern core is much smaller as a result of removing a lot of the complex features required for dynamic queries. The new core is also an order of magnitude faster in processing the response with an optimized parsing instruction set that is generated at build time. We no longer keep around tracking information needed for dynamic query generation, which drastically reduces the memory overhead of using Relay. This means more memory is left for making the UI feel responsive. Relay Modern also supports persisted queries, reducing the upload size of the request from the full query text to a simple id.

### Smaller Bundle Size

The Relay runtime bundle is roughly 20% of the size of Relay Classic.

### Garbage Collection

The runtime automatically removes cached data that is no longer referenced, helping to reduce memory usage.

### GraphQL Subscriptions & Live Queries

Relay Modern supports GraphQL Subscriptions, using the imperative update API to allow modifications to the store whenever a payload is received. It also features experimental support for GraphQL Live Queries via polling.

### Injectable Custom Field Handlers

Some fields - especially those for paginated data - can require post-processing on the client in order to merge previously fetched data with new information. Relay Modern supports custom field handlers that can be used to process these fields to work with various pagination patterns and other use cases.

### Simpler Mutation API

An area we've gotten a lot of questions on was mutations and their configs. Relay Modern introduces a new mutation API that allows records and fields to be updated in a more direct manner.

### Client Schema Extensions (Experimental)

The Relay Modern Core adds support for client schema extensions. These allow Relay to conveniently store some extra information with data fetched from the server and be rendered like any other field fetched from the server. This should be able to replace some use cases that previously required a Flux/Redux store on the side.

### Flow Type Generation

Relay Modern comes with automatic Flow type generation for the fragments used in Relay containers based on the GraphQL schema. Using these Flow types can help make an application less error-prone, by ensuring all possible `null` or `undefined` cases are considered even if they don't happen frequently.

## Fewer Requirements around Routing

Routes no longer need to know anything about the query root in Relay Modern. Relay components can be rendered anywhere wrapped in a `QueryRenderer`. This should bring more flexibility around picking routing frameworks.

## Extensible Core

Relay Modern's core is essentially an un-opinionated store for GraphQL data. It can be used independent of rendering views using React and can be extended to be used with other frameworks.


---
id: pagination-container
title: Pagination Container
original_id: pagination-container
---
Pagination Container is also a [higher-order component](https://reactjs.org/docs/higher-order-components.html), similar to a [Fragment Container](Modern-FragmentContainer.md), that is designed to simplify the workflow of loading more items in a list â€” in many cases, we don't want to fetch all the data at once but lazily load more data. It relies on a GraphQL server exposing connections in a standardized way. For a detailed spec, please check out [this page](https://relay.dev/graphql/connections.htm).

Table of Contents:

-   [`@connection`](#connection)
-   [`createPaginationContainer`](#createpaginationcontainer)
-   [`hasMore`](#hasmore)
-   [`isLoading`](#isloading)
-   [`loadMore`](#loadmore)
-   [`refetchConnection`](#refetchconnection)
-   [Pagination Example](#pagination-example)

## `@connection`

Pagination Container works in a very similar way to the [Fragment Container](Modern-FragmentContainer.md) in that you also specify the data requirements for a component via GraphQL fragments in the `fragmentSpec`.

However, when [specifying connection fragments](#createpaginationcontainer) for a Pagination Container, it is expected that at least one of the fragments contains a [GraphQL connection](https://relay.dev/graphql/connections.htm) to paginate over, and that the connection field is annotated with a `@connection` directive.

The purpose of the `@connection` directive is to allow Relay to uniquely identify different connections under a parent type. The `@connection` directive takes 2 arguments that help identify the connection:

```graphql
@connection(key: String!, filters: [String])

```

-   `key`: **Required** String that serves as a unique identifier for the connection under the parent field type. A good practice could be `<ComponentName>_<fieldName | fieldAlias>`.
-   `filters`: **Optional** Array of strings that belong to the set of argument variables defined for the connection field (e.g. `orderBy`, `searchTerm`, etc). The values for the variables specified in this array will be used alongside the user-supplied `key` to uniquely identify a connection. If `filters` is not provided, by default Relay will use the set of all of the arguments the connection field takes, excluding pagination specific arguments (i.e. `first`/`last`, `after`/`before`).

### Examples

Specifying just the `key`:

```javascript
fragment Feed_user on User {
  # This connection, under a specific User, will be uniquely identified by
  # the key "Feed_feed" and the value of `$orderBy` (given that no `filters` were provided)
  feed(
    first: $count
    after: $cursor
    orderby: $orderBy
  ) @connection(key: "Feed_feed") {
    edges {
      node {
        id,
        ...Story_story
      }
  }
}
```

Specifying `key` and `filters`:

```javascript
fragment Feed_user on User {
  # This connection, under a specific User, will be uniquely identified by
  # the key "Feed_feed" and /only/ the value of `$searchTerm`, i.e.
  # different values of `orderBy` will not distinguish connections.
  feed(
    first: $count
    after: $cursor
    orderby: $orderBy
    search_term: $searchTerm
  ) @connection(key: "Feed_feed", filters: ["searchTerm"]) {
    edges {
      node {
        id,
        ...Story_story
      }
  }
}
```

## `createPaginationContainer`

`createPaginationContainer` has the following signature:

```javascript
createPaginationContainer(
  component: ReactComponentClass,
  fragmentSpec: {[string]: GraphQLTaggedNode},
  connectionConfig: ConnectionConfig,
): ReactComponentClass;

type ConnectionConfig = {
  direction?: 'backward' | 'forward',
  getConnectionFromProps?: (props: Object) => ?ConnectionData,
  getFragmentVariables?: (previousVariables: Object, totalCount: number) => Object,
  getVariables: (
    props: Object,
    paginationInfo: {count: number, cursor: ?string},
    fragmentVariables: Object,
  ) => Object,
  query: GraphQLTaggedNode,
};

type ConnectionData = {
  edges?: ?Array<any>,
  pageInfo?: ?{
    endCursor: ?string,
    hasNextPage: boolean,
    hasPreviousPage: boolean,
    startCursor: ?string,
  },
};
```

### Arguments

-   `component`: The React Component _class_ of the component requiring the fragment data.
-   `fragmentSpec`: Specifies the data requirements for the Component via a GraphQL fragment. It is expected that one of the fragments specified here will contain a [`@connection`](#connection) for pagination. The required data will be available on the component as props that match the shape of the provided fragment. `fragmentSpec` should be an object whose keys are prop names and values are `graphql` tagged fragments. Each key specified in this object will correspond to a prop available to the resulting Component.
    -   **Note:** `relay-compiler` enforces fragments to be named as `<FileName>_<propName>`.
-   `connectionConfig`:
    -   `direction`: Either "forward" to indicate forward pagination using after/first, or "backward" to indicate backwards pagination using before/last. If not provided, Relay will infer the direction based on the provided `@connection` directive.
    -   `getConnectionFromProps`: Function that should indicate which connection to paginate over, given the fragment props (i.e. the props corresponding to the `fragmentSpec`). This is necessary in most cases because the Relay can't automatically tell which connection you mean to paginate over (a container might fetch multiple fragments and connections, but can only paginate one of them). If not provided, Relay will try infer the correct connection to paginate over based on the provided `@connection` directive. See our [example](#pagination-example) for more details.
    -   `getFragmentVariables`: Function that should return the bag of variables  to use for reading out the data from the store when re-rendering the component. This function takes the previous set of variables passed to the pagination `query`, and the number of elements that have been fetched in total so far. Specifically, this indicates which variables to use when reading out the data from the
        local data store _after_ the new pagination `query` has been fetched. If not specified, Relay will default to using all of the previous variables and using the total count for the `count` variable. This option is analogous to [`renderVariables`](Modern-RefetchContainer.md#refetch) in the Refetch Container. See our [example](#pagination-example) for more details.
    -   `getVariables`: Function that should return the variables to pass to the pagination `query` when fetching it from the server, given the current `props`, `count` and `cursor`. You may set whatever variables here, as well as modify the defaults to use for after/first/before/last arguments. See our [example](#pagination-example) for more details.
    -   `query`: A `graphql` tagged query to be used as the pagination query to fetch more data upon calling [`loadMore`](#loadmore).

### Available Props

The Component resulting from `createPaginationContainer` will receive the following `props`:

```javascript
type Props = {
  relay: {
    environment: Environment,
    hasMore(), // See #hasMore section
    isLoading(), // See #isLoading section
    loadMore(), // See #loadMore section
    refetchConnection(), // See #refetchConnection section
  },
  // Additional props as specified by the fragmentSpec
}
```

-   `relay`:
    -   `environment`: The current [Relay Environment](Modern-RelayEnvironment.md)
    -   `hasMore`: See `hasMore` [docs](#hasmore)
    -   `isLoading`: See `isLoading` [docs](#isloading)
    -   `loadMore`: See `loadMore` [docs](#loadmore)
    -   `refetchConnection `: See `refetchConnection` [docs](#refetchconnection)

## `hasMore`

`hasMore` is a function available on the `relay` [prop](#available-props). This function indicates whether there are more pages to fetch from the server or not.

```javascript
hasMore: () => boolean,

```

## `isLoading`

`isLoading` is a function available on the `relay` [prop](#available-props). This function indicates if a previous call to [`loadMore()`](#loadmore) is still pending. This is convenient for avoiding duplicate load calls.

```javascript
isLoading: () => boolean,

```

## `loadMore`

`loadMore` is a function available on the `relay` [prop](#available-props). You can call `loadMore()` to fetch more items from the server based on the `connectionConfig` provided to the container. This will return null if there are no more items to fetch, otherwise it will fetch more items and return a Disposable that can be used to cancel the fetch.

```javascript
loadMore(
  pageSize: number,
  callback: ?(error: ?Error) => void,
  options?: RefetchOptions
): ?Disposable

```

### Arguments:

-   `pageSize`: The number of **additional** items to fetch (not the total).
-   `callback`: Function called when the new page has been fetched. If an error occurred during refetch, this function will receive that error as an argument.
-   `options`: Optional object containing set of options.
    -   `force`: If the [Network Layer](Modern-NetworkLayer.md) has been configured with a cache, this option forces a refetch even if the data for this query and variables is already available in the cache.

## `refetchConnection`

`refetchConnection` is a function available on the `relay` [prop](#available-props). You can call `refetchConnection` to restart pagination on a connection from scratch, with optionally a completely new set of variables to pass to the pagination `query`. This is useful for example if you are paginating over a collection based on a userID and the userID changes, you'd want to start paginating over the new collection for the new user.

```javascript
refetchConnection:(
  totalCount: number,
  callback: (error: ?Error) => void,
  refetchVariables: ?Variables,
) => ?Disposable,

```

### Arguments:

-   `totalCount`: The total number of elements to fetch
-   `callback`: Function called when the new page has been fetched. If an error occurred during refetch, this function will receive that error as an argument.
-   `refetchVariables`: A potentially new bag of variables to pass to the pagination `query` when fetching it from the server.

## Pagination Example

```javascript
// Feed.js
import {createPaginationContainer, graphql} from 'react-relay';

class Feed extends React.Component {
  render() {
    return (
      <div>
        {this.props.user.feed.edges.map(
          edge => <Story story={edge.node} key={edge.node.id} />
        )}
        <button
          onPress={() => this._loadMore()}
          title="Load More"
        />
      </div>
    );
  }

  _loadMore() {
    if (!this.props.relay.hasMore() || this.props.relay.isLoading()) {
      return;
    }

    this.props.relay.loadMore(
      10,  // Fetch the next 10 feed items
      error => {
        console.log(error);
      },
    );
  }
}

module.exports = createPaginationContainer(
  Feed,
  {
    user: graphql`
      fragment Feed_user on User
      @argumentDefinitions(
        count: {type: "Int", defaultValue: 10}
        cursor: {type: "ID"}
        orderby: {type: "[FriendsOrdering]", defaultValue: [DATE_ADDED]}
      ) {
        feed(
          first: $count
          after: $cursor
          orderby: $orderBy # Non-pagination variables
        ) @connection(key: "Feed_feed") {
          edges {
            node {
              id
              ...Story_story
            }
          }
        }
      }
    `,
  },
  {
    direction: 'forward',
    getConnectionFromProps(props) {
      return props.user && props.user.feed;
    },
    // This is also the default implementation of `getFragmentVariables` if it isn't provided.
    getFragmentVariables(prevVars, totalCount) {
      return {
        ...prevVars,
        count: totalCount,
      };
    },
    getVariables(props, {count, cursor}, fragmentVariables) {
      return {
        count,
        cursor,
        orderBy: fragmentVariables.orderBy,
        // userID isn't specified as an @argument for the fragment, but it should be a variable available for the fragment under the query root.
        userID: fragmentVariables.userID,
      };
    },
    query: graphql`
      # Pagination query to be fetched upon calling 'loadMore'.
      # Notice that we re-use our fragment, and the shape of this query matches our fragment spec.
      query FeedPaginationQuery(
        $count: Int!
        $cursor: ID
        $orderBy: [FriendsOrdering]!
        $userID: ID!
      ) {
        user: node(id: $userID) {
          ...Feed_user @arguments(count: $count, cursor: $cursor, orderBy: $orderBy)
        }
      }
    `
  }
);
```


---
id: persisted-queries
title: Persisted Queries
original_id: persisted-queries
---
The relay compiler supports persisted queries which is useful because:

-   the client operation text becomes just an md5 hash which is usually shorter than the real
    query string. This saves upload bytes from the client to the server.

-   the server can now whitelist queries which improves security by restricting the operations
    that can be executed by a client.

## Usage on the client

### The `--persist-output` flag

In your `npm` script in `package.json`, run the relay compiler using the `--persist-output` flag:

```javascript
"scripts": {
  "relay": "relay-compiler --src ./src --schema ./schema.graphql --persist-output ./path/to/persisted-queries.json"
}
```

The `--persist-ouput` flag does 3 things:

1.  It converts all query and mutation operation texts to md5 hashes.

    For example without `--persist-output`, a generated `ConcreteRequest` might look like below:

    ```javascript
    const node/*: ConcreteRequest*/ = (function(){
    //... excluded for brevity
    return {
      "kind": "Request",
      "operationKind": "query",
      "name": "TodoItemRefetchQuery",
      "id": null, // NOTE: id is null
      "text": "query TodoItemRefetchQuery(\n  $itemID: ID!\n) {\n  node(id: $itemID) {\n    ...TodoItem_item_2FOrhs\n  }\n}\n\nfragment TodoItem_item_2FOrhs on Todo {\n    text\n    isComplete\n}\n",
      //... excluded for brevity
    };
    })();

    ```

    With `--persist-output <path>` this becomes:

    ```javascript
    const node/*: ConcreteRequest*/ = (function(){
    //... excluded for brevity
    return {
      "kind": "Request",
      "operationKind": "query",
      "name": "TodoItemRefetchQuery",
      "id": "3be4abb81fa595e25eb725b2c6a87508", // NOTE: id is now an md5 hash of the query text
      "text": null, // NOTE: text is null now
      //... excluded for brevity
    };
    })();

    ```

2.  It generates a JSON file at the `<path>` you specify containing a mapping from query ids
    to the corresponding operation texts.

```javascript
"scripts": {
  "relay": "relay-compiler --src ./src --schema ./schema.graphql --persist-output ./src/queryMaps/queryMap.json"
}
```

The example above writes the complete query map file to `./src/queryMaps/queryMap.json`. You need to ensure all the directories
leading to the `queryMap.json` file exist.

### Network layer changes

You'll need to modify your network layer fetch implementation to pass a documentId parameter in the POST body instead of a query parameter:

```javascript
function fetchQuery(operation, variables,) {
  return fetch('/graphql', {
    method: 'POST',
    headers: {
      'content-type': 'application/json'
    },
    body: JSON.stringify({
      documentId: operation.id, // NOTE: pass md5 hash to the server
      // query: operation.text, // this is now obsolete because text is null
      variables,
    }),
  }).then(response => {
    return response.json();
  });
}
```

## Executing Persisted Queries on the Server

To execute client requests that send persisted queries instead of query text, your server will need to be able
to lookup the query text corresponding to each id. Typically this will involve saving the output of the `--persist-output <path>` JSON file to a database or some other storage mechanism, and retrieving the corresponding text for the ID specified by a client.

For universal applications where the client and server code are in one project, this is not an issue since you can place
the query map file in a common location accessible to both the client and the server.

### Compile time push

For applications where the client and server projects are separate, one option is to have an additional npm run script
to push the query map at compile time to a location accessible by your server:

```javascript
"scripts": {
  "push-queries": "node ./pushQueries.js",
  "relay": "relay-compiler --src ./src --schema ./schema.graphql --persist-ouput <path> && npm run push-queries"
}
```

Some possibilities of what you can do in `./pushQueries.js`:

-   `git push` to your server repo

-   save the query maps to a database

### Run time push

A second more complex option is to push your query maps to the server at runtime, without the server knowing the query ids at the start.
The client optimistically sends a query id to the server, which does not have the query map. The server then in turn requests
for the full query text from the client so it can cache the query map for subsequent requests. This is a more complex approach
requiring the client and server to interact to exchange the query maps.

### Simple server example

Once your server has access to the query map, you can perform the mapping. The solution varies depending on the server and
database technologies you use, so we'll just cover the most common and basic example here.

If you use `express-graphql` and have access to the query map file, you can import the `--persist-output` JSON file directly and
perform the matching using the `matchQueryMiddleware` from [relay-compiler-plus](https://github.com/yusinto/relay-compiler-plus).

```javascript
import Express from 'express';
import expressGraphql from 'express-graphql';
import {matchQueryMiddleware} from 'relay-compiler-plus';
import queryMapJson from './path/to/persisted-queries.json';

const app = Express();

app.use('/graphql',
  matchQueryMiddleware(queryMapJson),
  expressGraphql({schema}));
```

## Using `--persist-output` and `--watch`

It is possible to continuously generate the query map files by using the `--persist-output` and `--watch` options simultaneously.
This only makes sense for universal applications i.e. if your client and server code are in a single project
and you run them both together on localhost during development. Furthermore, in order for the server to pick up changes
to the `queryMap.json`, you'll need to have server side hot-reloading set up. The details on how to set this up
is out of the scope of this document.


---
id: query-renderer
title: QueryRenderer
original_id: query-renderer
---
A `QueryRenderer` is a React Component at the root of a Relay component tree. It takes a query, fetches the given query, and uses the `render` prop to render the resulting data.

As React components, `QueryRenderer`s can be rendered anywhere that a React component can be rendered, i.e. not just at the top level but _within_ other components or containers; for example, to lazily fetch additional data for a popover.

However, a `QueryRenderer` will not start loading its data until it is mounted, so nested `QueryRenderer` components can lead to request waterfalls if used unnecessarily.

## Props

-   `environment`: The [Relay Environment](Modern-RelayEnvironment.md)
-   `query`: The `graphql` tagged query. **Note:** `relay-compiler` enforces the query to be named as `<FileName>Query`. Optional, if not provided, an empty `props` object is passed to the `render` callback.
-   `cacheConfig?`: Optional object containing a set of cache configuration options, i.e. `force: true` requires the fetch to be issued regardless of the state of any configured response cache.
-   `fetchPolicy?`: Optional prop to indicate if data already present in the store should be used to render immediately and updated from the network afterwards using the `store-and-network` key. Using the `network-only` key, which is the default behavior, ignores data already present in the store and waits for the network results to come back.
-   `variables`: Object containing set of variables to pass to the GraphQL query, i.e. a mapping from variable name to value. **Note:** If a new set of variables is passed, the `QueryRenderer` will re-fetch the query.
-   `render`: Function of type `({error, props, retry}) => React.Node`. The output of this function will be rendered by the `QueryRenderer`.
    -   `props`: Object containing data obtained from the query; the shape of this object will match the shape of the query. If this object is not defined, it means that the data is still being fetched.
    -   `error`: Error will be defined if an error has occurred while fetching the query.
    -   `retry`: Reload the data. It is null if `query` was not provided.

## Example

```javascript
// Example.js
import React from 'react';
import { QueryRenderer, graphql } from 'react-relay';

const renderQuery = ({error, props}) => {
  if (error) {
    return <div>{error.message}</div>;
  } else if (props) {
    return <div>{props.page.name} is great!</div>;
  }
  return <div>Loading</div>;
}

const Example = (props) => {
  return (
    <QueryRenderer
      environment={environment}
      query={graphql`
        query ExampleQuery($pageID: ID!) {
          page(id: $pageID) {
            name
          }
        }
      `}
      variables={{
        pageID: '110798995619330',
      }}
      render={renderQuery}
    />
  );
}
```


---
id: refetch-container
title: Refetch Container
original_id: refetch-container
---
A Refetch Container is also a [higher-order component](https://reactjs.org/docs/higher-order-components.html) that works like a regular [Fragment Container](Modern-FragmentContainer.md), but provides the additional ability to fetch a new GraphQL query with different variables and re-render the component with the new result.

Table of Contents:

-   [`createRefetchContainer`](#createrefetchcontainer)
-   [`refetch`](#refetch)
-   [Examples](#examples)

## `createRefetchContainer`

`createRefetchContainer` has the following signature:

```javascript
createRefetchContainer(
  component: ReactComponentClass,
  fragmentSpec: {[string]: GraphQLTaggedNode},
  refetchQuery: GraphQLTaggedNode,
): ReactComponentClass;
```

### Arguments

-   `component`: The React Component _class_ of the component requiring the fragment data.
-   `fragmentSpec`: Specifies the data requirements for the Component via a GraphQL fragment. The required data will be available on the component as props that match the shape of the provided fragment. `fragmentSpec` should be an object whose keys are prop names and values are `graphql` tagged fragments. Each key specified in this object will correspond to a prop available to the resulting Component.
    -   **Note:** `relay-compiler` enforces fragments to be named as `<FileName>_<propName>`.
-   `refetchQuery`: A `graphql` tagged query to be fetched upon calling [`props.relay.refetch`](#refetch). As with any query, upon fetching this query, its result will be normalized into the store, any relevant subscriptions associated with the changed records will be fired, and subscribed components will re-render.

### Available Props

The Component resulting from `createRefetchContainer` will receive the following `props`:

```javascript
type Props = {
  relay: {
    environment: Environment,
    refetch(), // See #refetch section
  },
  // Additional props as specified by the fragmentSpec
}
```

-   `relay`:
    -   `environment`: The current [Relay Environment](Modern-RelayEnvironment.md)
    -   `refetch`: See `refetch` [docs](#refetch)

## `refetch`

`refetch` is a function available on the `relay` [prop](#available-props) which can be used to execute the `refetchQuery` and potentially re-render the component with the newly fetched data. Specifically, upon fetching the `refetchQuery`, its result will be normalized into the store, and any relevant subscriptions associated with the changed records will be fired, causing relevant components to re-render.

**Note:** `refetch` is meant to be used for changing variables in the component's fragment. Specifically, in order for _this_ component to re-render, it must be subscribed to changes in the records affected by this query. If the fragment for the component doesn't use variables, the component won't be subscribed to changes to new records that might be fetched by this query. A common example of this is using `refetch` to fetch a new node and re-render the component with the data for the new node; in this case the fragment needs to use a variable for the node's id, otherwise the component won't pick up the changes for the new node.

`refetch` has the following signature:

```javascript
type RefetchOptions = {
  force?: boolean,
};

type Disposable = {
  dispose(): void,
};

refetch(
  refetchVariables: Object | (fragmentVariables: Object) => Object,
  renderVariables: ?Object,
  callback: ?(error: ?Error) => void,
  options?: RefetchOptions,
): Disposable,

```

### Arguments

-   `refetchVariables`:
    -   A bag of variables to pass to the `refetchQuery` when fetching it from the server.
    -   Or, a function that receives the previous set of variables used to query the data, and returns a new set of variables to pass to the `refetchQuery` when fetching it from the server.
-   `renderVariables`: Optional bag of variables that indicate which variables to use for reading out the data from the store when re-rendering the component. Specifically, this indicates which variables to use when querying the data from the
    local data store _after_ the new query has been fetched. If not specified, the `refetchVariables` will be used. This is useful when the data you need to render in your component doesn't necessarily match the data you queried the server for. For example, to implement pagination, you would fetch a page with variables like `{first: 5, after: '<cursor>'}`, but you might want to render the full collection with `{first: 10}`.
-   `callback`: Function to be called after the refetch has completed. If an error occurred during refetch, this function will receive that error as an argument.
-   `options`: Optional object containing set of options.
    -   `force`: If the [Network Layer](Modern-NetworkLayer.md) has been configured with a cache, this option forces a refetch even if the data for this query and variables is already available in the cache.
    -   `fetchPolicy`: If the data is already present in the store, using the `'store-or-network'` option will use that data without making an additional network request. Using the `'network-only'` option, which is the default behavior, will ignore any data present in the store and make a network request.

### Return Value

Returns a `Disposable` on which you could call `dispose()` to cancel the refetch.

## Examples

### Refetching latest data

In this simple example, let's assume we want to fetch the latest data for a `TodoItem` from the server:

```javascript
// TodoItem.js
import {createRefetchContainer, graphql} from 'react-relay';

class TodoItem extends React.Component {
  render() {
    const item = this.props.item;
    return (
      <View>
        <Checkbox checked={item.isComplete} />
        <Text>{item.text}</Text>
        <button onPress={this._refetch} title="Refresh" />
      </View>
    );
  }

  _refetch = () => {
    this.props.relay.refetch(
      {itemID: this.props.item.id},  // Our refetchQuery needs to know the `itemID`
      null,  // We can use the refetchVariables as renderVariables
      () => { console.log('Refetch done') },
      {force: true},  // Assuming we've configured a network layer cache, we want to ensure we fetch the latest data.
    );
  }
}

export default createRefetchContainer(
  TodoItem,
  {
    item: graphql`
      fragment TodoItem_item on Todo {
        text
        isComplete
      }
    `
  },
  graphql`
    # Refetch query to be fetched upon calling `refetch`.
    # Notice that we re-use our fragment and the shape of this query matches our fragment spec.
    query TodoItemRefetchQuery($itemID: ID!) {
      item: node(id: $itemID) {
        ...TodoItem_item
      }
    }
  `
);
```

### Loading more data

In this example we are using a Refetch Container to fetch more stories in a story feed component.

```javascript
import {createRefetchContainer, graphql} from 'react-relay';

class FeedStories extends React.Component {
  render() {
    return (
      <div>
        {this.props.feed.stories.edges.map(
          edge => <Story story={edge.node} key={edge.node.id} />
        )}
        <button
          onPress={this._loadMore}
          title="Load More"
        />
      </div>
    );
  }

  _loadMore() {
    // Increments the number of stories being rendered by 10.
    const refetchVariables = fragmentVariables => ({
      count: fragmentVariables.count + 10,
    });
    this.props.relay.refetch(refetchVariables);
  }
}

export default createRefetchContainer(
  FeedStories,
  {
    feed: graphql`
      fragment FeedStories_feed on Feed
      @argumentDefinitions(
        count: {type: "Int", defaultValue: 10}
      ) {
        stories(first: $count) {
          edges {
            node {
              id
              ...Story_story
            }
          }
        }
      }
    `
  },
  graphql`
    # Refetch query to be fetched upon calling `refetch`.
    # Notice that we re-use our fragment and the shape of this query matches our fragment spec.
    query FeedStoriesRefetchQuery($count: Int) {
      feed {
        ...FeedStories_feed @arguments(count: $count)
      }
    }
  `,
);
```


---
id: relay-compat
title: Compatibility Mode
original_id: relay-compat
---
Migrating a Relay Classic app to Relay Modern doesn't require rewriting from
scratch. Instead, convert one component at a time to the Relay Modern API while
continuing to have a working app. Once all components have been converted, the
smaller and faster Relay Modern runtime can be used.

During this migration, use the [Relay Compat](Modern-RelayCompat.md) tools and APIs to work with both Relay Classic and Relay Modern.

## API and Runtime

Relay can be thought of as two parts which work together: an API for building
data-driven components and a runtime which fetches and stores data from GraphQL
to populate your app. Relay Modern brings both a new API and a new runtime.

In order to incrementally convert an existing codebase, we will need to use the
Relay Modern API while continuing to use the Relay Classic runtime until all
components are converted.

Relay Compat is part of `'react-relay'` which allows you to do exactly this,
providing an identical API to Relay Modern, while allowing interoperability with
both runtimes.

## Getting started

Require the Relay Compat API from `'react-relay/compat'` and use it as you would
Relay Modern. The components using Relay Compat can be referred to by both other
Relay Modern and Relay Classic components.

```javascript
const {createFragmentContainer, graphql} = require('react-relay/compat');

class TodoItem extends React.Component {
  render() {
    const item = this.props.item;
    // ...
  }
}

module.exports = createFragmentContainer(TodoItem, graphql`
  fragment TodoItem_item on Todo {
    text
    isComplete
  }
`);
```


---
id: relay-environment
title: Relay Environment
original_id: relay-environment
---
The Relay "Environment" bundles together the configuration, cache storage, and network-handling that Relay needs in order to operate.

Most applications will create a single Environment instance and use it throughout. In specific situations, however, you may want to create multiple environments for different purposes. For example, you may create a new environment instance whenever the user logs in or out in order to prevent data for different users being cached together. Similarly, a server rendered application may create a new environment instance per request, so that each request gets its own cache and user data does not overlap. Alternatively, you might have multiple products or features within a larger application, and you want each one to have product-specific network-handling or caching.

## A simple example

To create an environment instance in Relay Modern, use the `RelayModernEnvironment` class:

```javascript
const {
  Environment,
  Network,
  RecordSource,
  Store,
} = require('relay-runtime');

const source = new RecordSource();
const store = new Store(source);
const network = Network.create(/*...*/); // see note below
const handlerProvider = null;

const environment = new Environment({
  handlerProvider, // Can omit.
  network,
  store,
});
```

For more details on creating a Network, see the [NetworkLayer guide](Modern-NetworkLayer.md).

Once you have an environment, you can pass it in to your [`QueryRenderer`](Modern-QueryRenderer.md) instance, or into mutations via the `commitUpdate` function (see "[Mutations](Modern-Mutations.md)").

## Adding a `handlerProvider`

The example above did not configure a `handlerProvider`, which means that a default one will be provided. Relay Modern comes with a built-in handler that augment the core with special functionality for handling connections (which is not a standard GraphQL feature, but a set of pagination conventions used at Facebook, specified in detail in the [Relay Cursor Connections Specification](https://relay.dev/graphql/connections.htm), and well-supported by Relay itself).

If you wish to provide your own `handlerProvider`, you can do so:

```javascript
const {
  ConnectionHandler,
} = require('relay-runtime');

function handlerProvider(handle) {
  switch (handle) {
    // Augment (or remove from) this list:
    case 'connection': return ConnectionHandler;
  }
  throw new Error(
    `handlerProvider: No handler provided for ${handle}`
  );
}
```


---
id: relay-store
title: Relay Store
original_id: relay-store
---
The Relay Store can be used to programmatically update client-side data inside [`updater` functions](Modern-Mutations.md#using-updater-and-optimisticupdater). The following is a reference of the Relay Store interface.

Table of Contents:

-   [RecordSourceSelectorProxy](#recordsourceselectorproxy)
-   [RecordProxy](#recordproxy)
-   [ConnectionHandler](#connectionhandler)

## RecordSourceSelectorProxy

The `RecordSourceSelectorProxy` is the type of the `store` that [`updater` functions](Modern-Mutations.md#using-updater-and-optimisticupdater) receive as an argument. The following is the `RecordSourceSelectorProxy` interface:

```javascript
interface RecordSourceSelectorProxy {
  create(dataID: string, typeName: string): RecordProxy;
  delete(dataID: string): void;
  get(dataID: string): ?RecordProxy;
  getRoot(): RecordProxy;
  getRootField(fieldName: string): ?RecordProxy;
  getPluralRootField(fieldName: string): ?Array<?RecordProxy>;
  invalidateStore(): void;
}
```

### `create(dataID: string, typeName: string): RecordProxy`

Creates a new record in the store given a `dataID` and the `typeName` as defined by the GraphQL schema. Returns a [`RecordProxy`](#recordproxy) which serves as an interface to mutate the newly created record.

#### Example

```javascript
const record = store.create(dataID, 'Todo');
```

### `delete(dataID: string): void`

Deletes a record from the store given its `dataID`.

#### Example

```javascript
store.delete(dataID);
```

### `get(dataID: string): ?RecordProxy`

Retrieves a record from the store given its `dataID`. Returns a [`RecordProxy`](#recordproxy) which serves as an interface to mutate the record.

#### Example

```javascript
const record = store.get(dataID);
```

### `getRoot(): RecordProxy`

Returns the [`RecordProxy`](#recordproxy) representing the root of the GraphQL document.

#### Example

Given the GraphQL document:

```graphql
viewer {
  id
}
```

Usage:

```javascript
// Represents root query
const root = store.getRoot();
```

### `getRootField(fieldName: string): ?RecordProxy`

Retrieves a root field from the store given the `fieldName`, as defined by the GraphQL document. Returns a [`RecordProxy`](#recordproxy) which serves as an interface to mutate the record.

#### Example

Given the GraphQL document:

```graphql
viewer {
  id
}
```

Usage:

```javascript
const viewer = store.getRootField('viewer');
```

### `getPluralRootField(fieldName: string): ?Array<?RecordProxy>`

Retrieves a root field that represents a collection from the store given the `fieldName`, as defined by the GraphQL document. Returns an array of [`RecordProxies`](#recordproxy).

#### Example

Given the GraphQL document:

```graphql
nodes(first: 10) {
  # ...
}
```

Usage:

```javascript
const nodes = store.getPluralRootField('nodes');
```

### `invalidateStore(): void`

Globally invalidates the Relay store. This will cause any data that was written to the store before invalidation occurred to be considered stale, and will be considered to require refetch the next time a query is checked with `environment.check()`.

#### Example

```javascript
store.invalidateStore();
```

After global invalidation, any query that is checked before refetching it will be considered stale:

```javascript
environment.check(query) === 'stale'

```

## RecordProxy

The `RecordProxy` serves as an interface to mutate records:

```javascript
interface RecordProxy {
  copyFieldsFrom(sourceRecord: RecordProxy): void;
  getDataID(): string;
  getLinkedRecord(name: string, arguments?: ?Object): ?RecordProxy;
  getLinkedRecords(name: string, arguments?: ?Object): ?Array<?RecordProxy>;
  getOrCreateLinkedRecord(
    name: string,
    typeName: string,
    arguments?: ?Object,
  ): RecordProxy;
  getType(): string;
  getValue(name: string, arguments?: ?Object): mixed;
  setLinkedRecord(
    record: RecordProxy,
    name: string,
    arguments?: ?Object,
  ): RecordProxy;
  setLinkedRecords(
    records: Array<?RecordProxy>,
    name: string,
    arguments?: ?Object,
  ): RecordProxy;
  setValue(value: mixed, name: string, arguments?: ?Object): RecordProxy;
  invalidateRecord(): void;
}
```

### `getDataID(): string`

Returns the dataID of the current record.

#### Example

```javascript
const id = record.getDataID();
```

### `getType(): string`

Gets the type of the current record, as defined by the GraphQL schema.

#### Example

```javascript
const type = user.getType();  // User

```

### `getValue(name: string, arguments?: ?Object): mixed`

Gets the value of a field in the current record given the field name.

#### Example

Given the GraphQL document:

```graphql
viewer {
  id
  name
}
```

Usage:

```javascript
const name = viewer.getValue('name');
```

Optionally, if the field takes arguments, you can pass a bag of `variables`.

#### Example

Given the GraphQL document:

```graphql
viewer {
  id
  name(arg: $arg)
}
```

Usage:

```javascript
const name = viewer.getValue('name', {arg: 'value'});
```

### `getLinkedRecord(name: string, arguments?: ?Object): ?RecordProxy`

Retrieves a record associated with the current record given the field name, as defined by the GraphQL document. Returns a `RecordProxy`.

#### Example

Given the GraphQL document:

```graphql
rootField {
  viewer {
    id
    name
  }
}
```

Usage:

```javascript
const rootField = store.getRootField('rootField');
const viewer = rootField.getLinkedRecord('viewer');
```

Optionally, if the linked record takes arguments, you can pass a bag of `variables` as well.

#### Example

Given the GraphQL document:

```graphql
rootField {
  viewer(arg: $arg) {
    id
  }
}
```

Usage:

```javascript
const rootField = store.getRootField('rootField');
const viewer = rootField.getLinkedRecord('viewer', {arg: 'value'});
```

### `getLinkedRecords(name: string, arguments?: ?Object): ?Array<?RecordProxy>`

Retrieves the set of records associated with the current record given the field name, as defined by the GraphQL document. Returns an array of `RecordProxies`.

#### Example

Given the GraphQL document:

```graphql
rootField {
  nodes {
    # ...
  }
}
```

Usage:

```javascript
const rootField = store.getRootField('rootField');
const nodes = rootField.getLinkedRecords('nodes');
```

Optionally, if the linked record takes arguments, you can pass a bag of `variables` as well.

#### Example

Given the GraphQL document:

```graphql
rootField {
  nodes(first: $count) {
    # ...
  }
}
```

Usage:

```javascript
const rootField = store.getRootField('rootField');
const viewer = rootField.getLinkedRecord('viewer', {count: 10});
```

### `getOrCreateLinkedRecord(name: string, typeName: string, arguments?: ?Object)`

Retrieves the a record associated with the current record given the field name, as defined by the GraphQL document. If the linked record does not exist, it will be created given the type name. Returns a `RecordProxy`.

#### Example

Given the GraphQL document:

```graphql
rootField {
  viewer {
    id
  }
}
```

Usage:

```javascript
const rootField = store.getRootField('rootField');
const newViewer = rootField.getOrCreateLinkedRecord('viewer', 'User'); // Will create if it doesn't exist

```

Optionally, if the linked record takes arguments, you can pass a bag of `variables` as well.

### `setValue(value: mixed, name: string, arguments?: ?Object): RecordProxy`

Mutates the current record by setting a new value on the specified field. Returns the mutated record.

Given the GraphQL document:

```graphql
viewer {
  id
  name
}
```

Usage:

```javascript
viewer.setValue('New Name', 'name');
```

Optionally, if the field takes arguments, you can pass a bag of `variables`.

```javascript
viewer.setValue('New Name', 'name', {arg: 'value'});
```

### `copyFieldsFrom(sourceRecord: RecordProxy): void`

Mutates the current record by copying the fields over from the passed in record `sourceRecord`.

#### Example

```javascript
const record = store.get(id1);
const otherRecord = store.get(id2);
record.copyFieldsFrom(otherRecord); // Mutates `record`

```

### `setLinkedRecord(record: RecordProxy, name: string, arguments?: ?Object)`

Mutates the current record by setting a new linked record on the given the field name.

#### Example

Given the GraphQL document:

```graphql
rootField {
  viewer {
    id
  }
}
```

Usage:

```javascript
const rootField = store.getRootField('rootField');
const newViewer = store.create(/* ... */)''
rootField.setLinkedRecord(newViewer, 'viewer'); //

```

Optionally, if the linked record takes arguments, you can pass a bag of `variables` as well.

### `setLinkedRecords(records: Array<RecordProxy>, name: string, variables?: ?Object)`

Mutates the current record by setting a new set of linked records on the given the field name.

#### Example

Given the GraphQL document:

```graphql
rootField {
  nodes {
    # ...
  }
}
```

Usage:

```javascript
const rootField = store.getRootField('rootField');
const newNode = store.create(/* ... */);
const newNodes = [...rootField.getLinkedRecords('nodes'), newNode];
rootField.setLinkedRecords(newNodes, 'nodes'); //

```

Optionally, if the linked record takes arguments, you can pass a bag of `variables` as well.

### `invalidateRecord(): void`

Invalidates the record. This will cause any query that references this record to be considered stale until the next time it is refetched, and will be considered to require a refetch the next time such a query is checked with `environment.check()`.

#### Example

```javascript
const record = store.get('4');
record.invalidateRecord();
```

After invalidating a record, any query that references the invalidated record and that is checked before refetching it will be considered stale:

```javascript
environment.check(query) === 'stale'

```

## ConnectionHandler

`ConnectionHandler` is a utility module exposed by `relay-runtime` that aids in the manipulation of connections. `ConnectionHandler` exposes the following interface:

```javascript
interface ConnectionHandler {
  getConnection(
    record: RecordProxy,
    key: string,
    filters?: ?Object,
  ): ?RecordProxy,
  createEdge(
    store: RecordSourceProxy,
    connection: RecordProxy,
    node: RecordProxy,
    edgeType: string,
  ): RecordProxy,
  insertEdgeBefore(
    connection: RecordProxy,
    newEdge: RecordProxy,
    cursor?: ?string,
  ): void,
  insertEdgeAfter(
    connection: RecordProxy,
    newEdge: RecordProxy,
    cursor?: ?string,
  ): void,
  deleteNode(connection: RecordProxy, nodeID: string): void
}
```

### `getConnection(record: RecordProxy, key: string, filters?: ?Object)`

Given a record and a connection key, and optionally a set of filters, `getConnection` retrieves a [`RecordProxy`](#recordproxy) that represents a connection that was annotated with a `@connection` directive.

First, let's take a look at a plain connection:

```graphql
fragment FriendsFragment on User {
  friends(first: 10) {
    edges {
      node {
        id
      }
    }
  }
}
```

Accessing a plain connection field like this is the same as other regular field:

```javascript
// The `friends` connection record can be accessed with:
const user = store.get(userID);
const friends = user && user.getLinkedRecord('friends');

// Access fields on the connection:
const edges = friends && friends.getLinkedRecords('edges');
```

In a [pagination container](Modern-PaginationContainer.md), we usually annotate the actual connection field with `@connection` to tell Relay which part needs to be paginated:

```graphql
fragment FriendsFragment on User {
  friends(first: 10, orderby: "firstname") @connection(
    key: "FriendsFragment_friends",
  ) {
    edges {
      node {
        id
      }
    }
  }
}
```

For connections like the above, `ConnectionHandler` helps us find the record:

```

import {ConnectionHandler} from 'relay-runtime';

// The `friends` connection record can be accessed with:
const user = store.get(userID);
const friends = ConnectionHandler.getConnection(
 user,                        // parent record
 'FriendsFragment_friends'    // connection key
 {orderby: 'firstname'}       // 'filters' that is used to identify the connection
);
// Access fields on the connection:
const edges = friends.getLinkedRecords('edges');
```

### Edge creation and insertion

#### `createEdge(store: RecordSourceProxy, connection: RecordProxy, node: RecordProxy, edgeType: string)`

Creates an edge given a [`store`](#recordsourceselectorproxy), a connection, the edge type, and a record that holds that connection.

#### `insertEdgeBefore(connection: RecordProxy, newEdge: RecordProxy, cursor?: ?string)`

Given a connection, inserts the edge at the beginning of the connection, or before the specified `cursor`.

#### `insertEdgeAfter(connection: RecordProxy, newEdge: RecordProxy, cursor?: ?string)`

Given a connection, inserts the edge at the end of the connection, or after the specified `cursor`.

#### Example

```

const user = store.get(userID);
const friends = ConnectionHandler.getConnection(user, 'friends');
const edge = ConnectionHandler.createEdge(store, friends, user, 'UserEdge');

// No cursor provided, append the edge at the end.
ConnectionHandler.insertEdgeAfter(friends, edge);

// No cursor provided, Insert the edge at the front:
ConnectionHandler.insertEdgeBefore(friends, edge);
```

### `deleteNode(connection: RecordProxy, nodeID: string): void`

Given a connection, deletes any edges whose id matches the given id.

#### Example

```

const user = store.get(userID);
const friends = ConnectionHandler.getConnection(user, 'friends');
ConnectionHandler.deleteNode(friends, idToDelete);
```


---
id: routing
title: Routing
original_id: routing
---
Historically, Relay started out internally at Facebook as a routing framework. However, Relay no longer makes any assumptions about routing, and works with a variety of routing options.

## No Routing

If the Relay part of an application is some widget or single view as part of a larger application, you don't need any routing. You can just render a `QueryRenderer` somewhere on the page to fetch and render the data you need there. This option is simple and should be used when sufficient.

## Flat Routes

When not nesting routes with Relay data dependencies, such as when using flat routes, it is sufficient to just render a `QueryRenderer` for the parts of your application that require Relay data. You can also use the options below that integrate your routes with their data dependencies.

## Nested Routes

Nested routes with Relay data dependencies introduce an additional complication. While it's possible to render a `QueryRenderer` per route, doing so will lead to request waterfalls in the general case where parent routes do not render their child routes until the data for those parent routes are available. This generally leads to an unnecessary additional delay in loading the data for the page, but may be acceptable for small applications or for applications with shallow route trees.

Integration options are available for open-source routing libraries that can instead fetch data for nested routes in parallel. In many of these cases, using a batching network layer can bring additional benefits in avoiding sending multiple HTTP requests.

### [React Router](https://reacttraining.com/react-router/)

Integration with Relay Classic for React Router v2 or v3 is available via [`react-router-relay`](https://github.com/relay-tools/react-router-relay), which will aggregate the queries for matched routes, and request data for all routes in parallel.

The component-based approach of React Router v4 does not readily allow for aggregating the data requirements for nested routes, and as such does not readily permit an approach that will avoid request waterfalls from nesting `QueryRenderer` components.

### [Found](https://github.com/4Catalyzer/found)

Found offers integration with Relay Modern and Relay Classic via [Found Relay](https://github.com/4Catalyzer/found-relay). Found Relay runs queries for matched routes in parallel, and supports fetching Relay data in parallel with downloading async bundles from code splitting when using Relay Modern.

## Custom Routing and More

The options listed above are not exhaustive. If you are aware of other routing solutions that work well with Relay Modern, [please let us know](https://github.com/facebook/relay/issues/new).


---
id: subscriptions
title: Subscriptions
original_id: subscriptions
---
Relay exposes the following APIs to create subscriptions.

```javascript
import { requestSubscription } from 'react-relay';

type Variables = {[name: string]: any};

type Disposable = {
  dispose(): void,
};

requestSubscription(
  environment: Environment,
  config: {
    subscription: GraphQLTaggedNode,
    variables: Variables,
    onCompleted?: ?() => void,
    onError?: ?(error: Error) => void,
    onNext?: ?(response: ?Object) => void,
    updater?: ?(store: RecordSourceSelectorProxy, data: SelectorData) => void,
    configs?: Array<DeclarativeMutationConfig>,
    cacheConfig?: CacheConfig,
  },
) => Disposable;
```

The function returns a `Disposable` on which you could call `dispose()` to cancel the refetch.

Now let's take a closer look at the `config`:

-   `subscription`: the `graphql` tagged subscription query.
-   `variables`: an object that contains the variables needed for the subscription.
-   `onCompleted`: a callback function executed when the subscription is closed by
    the peer without error.
-   `onError`: a callback function executed when Relay or the server encounters an
    error processing the subscription.
-   `onNext`: a callback function executed each time a response is received from
    the server, with the raw GraphQL response payload.
-   `updater`: an optional function that can supply custom logic for updating the
    in-memory Relay store based on the server response.
-   `configs`: an array containing the updater configurations. It is the same as [`configs`](Modern-Mutations.md#updater-configs) in `commitMutation`.
-   `cacheConfig?`: Optional object containing a set of cache configuration options

## Example

In a simple subscription, you only need `subscription` and `variables`. This is
appropriate when you are only changing the properties of existing records that
can be identified by their `id`:

```javascript
import {
  requestSubscription,
  graphql,
} from 'react-relay';

const subscription = graphql`
  subscription MarkReadNotificationSubscription(
    $storyID: ID!
  ) {
    markReadNotification(storyID: $storyID) {
      notification {
        seenState
      }
    }
  }
`;

const variables = {
  storyID,
};

requestSubscription(
  yourEnvironment, // see Environment docs
  {
    subscription,
    variables,
    // optional but recommended:
    onCompleted: () => {
      // server closed the subscription
    },
    onError: error => console.error(error),
  }
);
```

# Configure Network

You will need to Configure your Network layer to handle subscriptions.

Usually GraphQL subscriptions are communicated over [WebSockets](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API), here's an example using [graphql-ws](https://github.com/enisdenjo/graphql-ws):

```javascript
import {
    ...
    Network,
    Observable
} from 'relay-runtime';
import { createClient } from 'graphql-ws';

const wsClient = createClient({
  url:'ws://localhost:3000',
});

const subscribe = (operation, variables) => {
  return Observable.create((sink) => {
    return wsClient.subscribe(
      {
        operationName: operation.name,
        query: operation.text,
        variables,
      },
      sink,
    );
  });
}

const network = Network.create(fetchQuery, subscribe);
```

Alternatively, the legacy [subscriptions-transport-ws](https://github.com/apollographql/subscriptions-transport-ws) library can be used too:

```javascript
import {
    ...
    Network,
    Observable
} from 'relay-runtime';
import { SubscriptionClient } from 'subscriptions-transport-ws';

...

const subscriptionClient = new SubscriptionClient('ws://localhost:3000', {
    reconnect: true,
});

const subscribe = (request, variables) => {
    const subscribeObservable = subscriptionClient.request({
        query: request.text,
        operationName: request.name,
        variables,
    });
    // Important: Convert subscriptions-transport-ws observable type to Relay's
    return Observable.from(subscribeObservable);
};

const network = Network.create(fetchQuery, subscribe);

...

```

# Updating the client on each response

For more complex use-cases, you may wish to perform custom logic to update
Relay's in-memory cache when each subscription response is received. To do so,
pass an `updater` function:

```javascript
import { ConnectionHandler } from 'relay-runtime';

requestSubscription(
  environment,
  {
    subscription,
    variables,
    updater: store => {
      // Get the notification
      const rootField = store.getRootField('markReadNotification');
      const notification = rootField.getLinkedRecord('notification');
      // Add it to a connection
      const viewer = store.getRoot().getLinkedRecord('viewer');
      const notifications =
        ConnectionHandler.getConnection(viewer, 'notifications');
      const edge = ConnectionHandler.createEdge(
        store,
        notifications,
        notification,
        '<TypeOfNotificationsEdge>',
      );
      ConnectionHandler.insertEdgeAfter(notifications, edge);
    },
  },
);
```


---
id: testing-relay-components
title: Testing Relay Components
original_id: testing-relay-components
---
The purpose of this document is to cover the Relay APIs for testing Relay components.

The content is focused mostly on jest unit-tests (testing individual components) and integration tests (testing a combination of components).  But these testing tools may be applied in different cases: screenshot-tests, production smoke-tests, fuzz-tests, e2e test, etc.

What are the benefits of writing jest tests:

-   In general, it improves the stability of the system. Flow really helps with catching a various set of javascript errors, but it is still possible to introduce regressions to the components. Unit-tests may help to find, reproduce, and fix those regressions, and prevent them in the future.
-   It simplifies the refactoring process: when properly written (testing public interface, not implementation) - tests really help with changing the internal implementation of the components.
-   It may speed up and improve the development workflow. Some people may call it Test Driven Development (TM). But essentially it's just writing tests for public interfaces of your components, and then writing the components that are implementing those interfaces. Jest â€”watch mode is really shining in this case.
-   It will simplify the onboarding process for new developers, having tests really help to ramp up on the new code base, fixing bugs, and delivering features.

One thing to notice: while jest unit and integration tests will help improve the stability of the system, they should be considered as a part of a bigger stability infrastructure with multiple layers of automated testing: flow, e2e, screenshot, performance tests.

## Testing with Relay

Testing applications that are using Relay may be challenging, because of the additional data fetching layer that is wrapping the actual product code.

And it's not always easy to understand the mechanics of all processes that are happening behind Relay, and how to properly handle interactions with the framework.

Fortunately, we have tools that aim to simplify the process of writing tests for Relay components, by providing imperative APIs for controlling the request/response flow and additional API for mock data generation.

There are two main modules that you may use in your tests:

-   createMockEnvironment(options): RelayMockEnvironment
-   MockPayloadGenerator and @relay_test_operation directive

With `createMockEnvironment,` you will be able to create an instance of `RelayMockEnvironment`, a Relay environment specifically for your tests. The instance created by `createMockEnvironment` is implementing the Relay Environment Interface and it also has an additional Mock layer, with methods that allow to resolve/reject and control the flow of operations (queries/mutations/subscriptions).

The main purpose of `MockPayloadGenerator` is to improve the process of creating and maintaining the mock data for tested components.

One of the patterns you may see in the tests for Relay components: 95% of the test code, is the test preparation: the gigantic mock object with dummy data, manually created, or just a copy of a sample server response that needs to be passed as the network response. And rest 5% is actual test. As a result, people don't test much. It's hard to create and manage all these dummy payloads for different cases. Hence, writing tests are time-consuming and painful to maintain.

With the MockPayloadGenerator and @relay_test_operation, we want to get rid of this pattern and switch the developer's focus from the preparation of the test to the actual testing.

## RelayMockEnvironment API Overview

RelayMockEnvironment is a special version of Relay Environment with an additional API methods for controlling the operation flow: resolving and rejection operations, providing incremental payloads for subscriptions, working with cache.

-   Methods for finding operations executed on the environment
    -   `getAllOperations()` - get all operation executed during the test by the current time
    -   `findOperation(findFn => boolean) `- find particular operation in the list of all executed operations, this method will throw, if operation is not available. Maybe useful to find a particular operation when multiple operations executed at the same time
    -   `getMostRecentOperation() -` return the most recent operation, this method will throw if no operations were executed prior this call.
-   Methods for resolving or rejecting operations
    -   `nextValue(request | operation, data)` - provide payload for operation(request), but not complete request. Practically useful when testing incremental updates and subscriptions
    -   `complete(request | operation)`  - complete the operation, no more payloads are expected for this operation, when it's completed.
    -   `resolve(request | operation, data)` - resolve the request with provided GraphQL response. Essentially, it's nextValue(...) and complete(...)
    -   `reject(request | operation, error)` - reject the request with particular error
    -   `resolveMostRecentOperation(data | operation => data)` - resolve and getMostRecentOperation work together
    -   `rejectMostRecentOperation(error | operation => error)`  - reject and getMostRecentOperation work together
    -   `queueOperationResolver(operation => data | error)` - adds an OperationResolver function to the queue, those methods will be used to resolve/reject operations as they appear
-   Additional utility methods
    -   `isLoading(request | operation)` - will return `true` if operations have not been completed, yet.
    -   `cachePayload(request | operation, variables, payload)` - will add payload to QueryResponse cache
    -   `clearCache() `- will clear QueryResponse cache

## Mock Payload Generator and @relay_test_operation Directive

MockPayloadGenerator may drastically simplify the process of creating and maintaining mock data for your tests. MockPayloadGenerator is the module that can generate dummy data for the selection that you have in your operation. There is an API to modify the generated data - Mock Resolvers. With Mock Resolvers, you may adjust the data for your needs. Collection of Mock Resolvers it's an object where keys are names of GraphQL types (ID, String, User, Feedback, Comment, etc), and values are functions that will return the default data for the type.

Example of a simple Mock Resolver:

```javascript
{
  ID() {
    // Return mock value for a scalar filed with type ID
    return 'my-id';
  },
  String() {
    // Every scalar field with type String will have this default value
    return "Lorem Ipsum"
  }
}
```

It is possible to define more resolvers for Object types

```javascript
{
  // This will be the default values for User object in the query response
  User() {
    return {
      id: 1000,
      name: "Alice",
      profile_picture: {
        uri: "http://my-image...",
      },
    };
  },
}
```

### Mock Resolver Context

The first argument of the MockResolver is the object that contains Mock Resolver Context. It is possible to return dynamic values from mock resolvers based on the context - for instance, name or alias of the field, a path in the selection, arguments, or parent type.

```javascript
{
  String(context) {
    if (context.name === 'zip') {
      return '94025';
    }
    if (context.path != null && context.path.join('.') === 'node.actor.name') {
      return 'Current Actor Name';
    }
    if (context.parentType === 'Image' && context.name === 'uri') {
       return 'http://my-image.url';
    }
  }
}
```

### ID Generation

The second argument of the Mock Resolver its a function that will generate a sequence of integers, useful to generate unique ids in the tests

```javascript
{
  // will generate strings "my-id-1", "my-id-2", etc.
  ID(_, generateId) {
     return `my-id-${generateId()}`;
  },
}
```

### @relay_test_operation

Most of GraphQL type information for a specific field in the selection is not available during Relay runtime. By default, Relay, cannot get type information for a scalar field in the selection, or an interface type of the object.

Operation with the @relay_test_operation directive will have additional metadata that will contain GraphQL type info for fields in the operation's selection. And it will improve the quality of the generated data. You also will be able to define Mock resolvers for Scalar (not only ID and String) and Abstract types:

```javascript
{
  Float() {
    return 123.456;
  },
  Boolean(context) {
    if (context.name === 'can_edit') {
      return true;
    }
    return false;
  },
  Node() {
    return {
      __typename: 'User',
      id: 'my-user-id',
    };
  }
}
```

## Examples

### Relay Component Test

Using `createMockEnvironment` and `MockPayloadGenerator` allows writing concise tests for components that are using Relay Containers and Renderers. Both those modules can be imported from `relay-test-utils`

```javascript
// Say you have a component with the QueryRenderer
const MyAwesomeViewRoot = require('MyAwesomeViewRoot');
const {
  createMockEnvironment,
  MockPayloadGenerator,
} = require('relay-test-utils');

// Relay may trigger 3 different states
// for this component: Loading, Error, Data Loaded
// Here is examples of tests for those states.
test('Loading State', () => {
  const environment = createMockEnvironment();
  const renderer = ReactTestRenderer.create(
    <MyAwesomeViewRoot environment={environment} />,
  );

  // Here we just verify that the spinner is rendered
  expect(
    renderer.root.find(node => node.props['data-testid'] === 'spinner'),
  ).toBeDefined();
});

test('Data Render', () => {
  const environment = createMockEnvironment();
  const renderer = ReactTestRenderer.create(
    <MyAwesomeViewRoot environment={environment} />,
  );

  environment.mock.resolveMostRecentOperation(operation =>
    MockPayloadGenerator.generate(operation),
  );

  // At this point operation will be resolved
  // and the data for a query will be available in the store
  expect(
    renderer.root.find(node => node.props['data-testid'] === 'myButton'),
  ).toBeDefined();
});

test('Error State', () => {
  const environment = createMockEnvironment();
  const renderer = ReactTestRenderer.create(
    <MyAwesomeViewRoot environment={environment} />,
  );

  // Error can be simulated with `rejectMostRecentOperation`
  environment.mock.rejectMostRecentOperation(new Error('Uh-oh'));

  expect(
    renderer.root.find(item => (item.props.testID = 'errorMessage')),
  ).toBeDefined();
});
```

### Fragment Container Tests

Essentially, in the example above will `resolveMostRecentOperation` will generate data for all child fragment containers (pagination, refetch). But, usually the Root Components container may have many child fragment components and you may want to exercise a specific Fragment Container. The solution for that would be to wrap your fragment container with the QueryRenderer that renders a Query that's spreads fragments from your fragment container.

```javascript
test('Fragment Container', () => {
  const environment = createMockEnvironment();
  const TestRenderer = () => (
    <QueryRenderer
      environment={environment}
      query={graphql`
        query TestQuery @relay_test_operation {
          myData: node(id: "test-id") {
            ...MyFragment
          }
        }
      `}
      variables={{}}
      render={({error, props}) => {
        if (props) {
          return <MyFragmentContainer myData={props.myData} />;
        } else if (error) {
          return error.message;
        }
        return 'Loading...';
      }}
    />
  );
  const renderer = ReactTestRenderer.create(<TestRenderer />);
  environment.mock.resolveMostRecentOperation(operation =>
    MockPayloadGenerator.generate(operation),
  );

  expect(renderer).toMatchSnapshot();
});
```

### Pagination Container Test

Essentially, tests for Pagination container are not different from Fragment Container tests. But we can do more here, we can actually see how the pagination works - we can assert the behavior of our components when performing pagination (load more, refetch).

```javascript
// Pagination Example
test('Pagination Container', () => {
  const environment = createMockEnvironment();
  const TestRenderer = () => (
    <QueryRenderer
      environment={environment}
      query={graphql`
        query TestQuery @relay_test_operation {
          myConnection: node(id: "test-id") {
            connection {
              ...MyConnectionFragment
            }
          }
        }
      `}
      variables={{}}
      render={({error, props}) => {
        if (props) {
          return <MyPaginationContainer connection={props.myConnection.connection} />;
        } else if (error) {
          return error.message;
        }
        return 'Loading...';
      }}
    />
  );
  const renderer = ReactTestRenderer.create(<TestRenderer />);
  environment.mock.resolveMostRecentOperation(operation =>
    MockPayloadGenerator.generate(operation, {
      ID(_, generateId) {
        // Why we're doing this?
        // To make sure that we will generate a different set of ID
        // for elements on first page and the second page.
        return `first-page-id-${generateId()}`;
      },
      PageInfo() {
        return {
          has_next_page: true,
        };
      },
    }),
  );

  // Let's find a `loadMore` button and click on it to initiate pagination request, for example
  const loadMore = renderer.root.find(node => node.props['data-testid'] === 'loadMore')
  expect(loadMore.props.disabled).toBe(false);
  loadMore.props.onClick();

  environment.mock.resolveMostRecentOperation(operation =>
    MockPayloadGenerator.generate(operation, {
      ID(_, generateId) {
        // See, the second page IDs will be different
        return `second-page-id-${generateId()}`;
      },
      PageInfo() {
        return {
          // And the button should be disabled, now. Probably.
          has_next_page: false,
        };
      },
    }),
  );
  expect(loadMore.props.disabled).toBe(true);
});


```

### Refetch Container

We can use similar approach here with wrapping container with Query Renderer. And for the sake of completeness, we will add example here:

```javascript
test('Refetch Container', () => {
  const environment = createMockEnvironment();
  const TestRenderer = () => (
    <QueryRenderer
      environment={environment}
      query={graphql`
        query TestQuery @relay_test_operation {
          myData: node(id: "test-id") {
            ...MyRefetchableFragment
          }
        }
      `}
      variables={{}}
      render={({error, props}) => {
        if (props) {
          return <MyRefetchContainer myData={props.myData} />;
        } else if (error) {
          return error.message;
        }
        return 'Loading...';
      }}
    />
  );

  const renderer = ReactTestRenderer.create(<TestRenderer />);
  environment.mock.resolveMostRecentOperation(operation =>
    MockPayloadGenerator.generate(operation),
  );
  // Assuming we have refetch button in the Container
  const refetchButton = renderer.root.find(node => node.props['data-testid'] === 'refetch');

  // This should trigger the `refetch`
  refetchButton.props.onClick();

  environment.mock.resolveMostRecentOperation(operation =>
    MockPayloadGenerator.generate(operation, {
      // We can customize mock resolvers, to change the output of the refetch query
    }),
  );
  // expect(renderer).toMatchSnapshot();
});
```

### Mutations

Mutations itself are operations so we can test them independently (unit-test) for specific mutation, or in combination with the view from which this mutation is called.

```javascript
// Say, you have a mutation function
function sendMutation(environment, onCompleted, onError, variables)
  commitMutation(environment, {
    mutation: graphql`...`,
    onCompleted,
    onError,
    variables,
  });
}

// Example test may be written like so
test('it should send mutation', () => {
  const environment = createMockEnvironment();
  const onCompleted = jest.fn();
  sendMutation(environment, onCompleted, jest.fn(), {});
  const operation = environment.mock.getMostRecentOperation();
  environment.mock.resolve(
    operation,
    MockPayloadGenerator.generate(operation)
  );
  expect(onCompleted).toBeCalled();
});
```

### Subscription

We can test subscription in a similar way we test mutations

```javascript
// Example subscribe function
function subscribe(environment, onNext, onError, variables)
  requestSubscription(environment, {
    subscription: graphql`...`,
    onNext,
    onError,
    variables,
  });
}

// Example test may be written like so
test('it should subscribe', () => {
  const environment = createMockEnvironment();
  const onNext = jest.fn();
  subscribe(environment, onNext, jest.fn(), {});
  const operation = environment.mock.getMostRecentOperation();
  environment.mock.nextValue(
    operation,
    MockPayloadGenerator.generate(operation)
  );
  expect(onNext).toBeCalled();
});
```

### Example with `queueOperationResolver`

With `queueOpeararionResolver` it possible to define responses for operations that will be executed on the environment

```javascript
// Say you have a component with the QueryRenderer
const MyAwesomeViewRoot = require('MyAwesomeViewRoot');
const {
  createMockEnvironment,
  MockPayloadGenerator,
} = require('relay-test-utils');

test('Data Render', () => {
  const environment = createMockEnvironment();
  environment.mock.queueOperationResolver(operation =>
    MockPayloadGenerator.generate(operation),
  );

  const renderer = ReactTestRenderer.create(
    <MyAwesomeViewRoot environment={environment} />,
  );

  // At this point operation will be resolved
  // and the data for a query will be available in the store
  expect(
    renderer.root.find(node => node.props['data-testid'] === 'myButton'),
  ).toBeDefined();
});

test('Error State', () => {
  const environment = createMockEnvironment();
  environment.mock.queueOperationResolver(() =>
    new Error('Uh-oh'),
  );
  const renderer = ReactTestRenderer.create(
    <MyAwesomeViewRoot environment={environment} />,
  );

  expect(
    renderer.root.find(item => (item.props.testID = 'errorMessage')),
  ).toBeDefined();
});


```


---
id: type-emission
title: Type Emission
original_id: type-emission
---
As part of its normal work, `relay-compiler` will emit type information for your language of choice that helps you write type-safe application code. These types are included in the artifacts that `relay-compiler` generates to describe your operations and fragments.

Regardless of your choice of language, all language plugins will emit roughly the same sort of type-information, but be sure to read the documentation for other [language plugins](#language-plugins) to learn about their specifics.

### Operation input data

The shape of the variables object used for query, mutation, or subscription operations.

In this example the emitted type-information would require the variables object to contain a `page` key with a non-null string.

#### Flow

```javascript
/**
 * export type ExampleQueryVariables = {|
 *   +artistID: string
 * |}
 */
import type { ExampleQueryVariables } from "__generated__/ExampleQuery.graphql"

const variables: ExampleQueryVariables = {
  artistID: 'banksy',
}

<QueryRenderer
  query={graphql`
    query ExampleQuery($artistID: ID!) {
      artist(id: $artistID) {
        name
      }
    }
  `}
  variables={variables}
/>

```

#### TypeScript

```javascript
/**
 * export type ExampleQueryVariables = {
 *   readonly artistID: string
 * }
 * export type ExampleQuery = {
 *   readonly variables: ExampleQueryVariables
 * }
 */
import { ExampleQuery } from "__generated__/ExampleQuery.graphql"

<QueryRenderer<ExampleQuery>
  query={graphql`
    query ExampleQuery($artistID: ID!) {
      artist(id: $artistID) {
        name
      }
    }
  `}
  variables={{
    artistID: 'banksy',
  }}
/>

```

### Operation/Fragment selection-set data

The shape of the data selected in a operation or fragment, following the [data-masking] rules. That is, excluding any data selected by fragment spreads, unless the `@relay(mask: false)` directive is used.

In this example the emitted type-information describes the response data available to the operationâ€™s render function.

#### Flow

```javascript
/**
 * export type ExampleQueryResponse = {|
 *   +artist: ?{|
 *     +name: string
 *   |}
 * |}
 */
import type { ExampleQueryResponse } from "__generated__/ExampleQuery.graphql"

<QueryRenderer
  query={graphql`
    query ExampleQuery {
      artist(id: "banksy") {
        name
      }
    }
  `}
  render={({ props }: { props?: ExampleQueryResponse }) => {
    if (props) {
      return props.artist && <div>{props.artist.name} is great!</div>
    }
    return <div>Loading</div>
  }}
/>

```

#### TypeScript

```javascript
/**
 * export type ExampleQueryResponse = {
 *   readonly artist?: {
 *     readonly name: string
 *   }
 * }
 * export type ExampleQuery = {
 *   readonly response: ExampleQueryResponse
 * }
 */
import { ExampleQuery } from "__generated__/ExampleQuery.graphql"

<QueryRenderer<ExampleQuery>
  query={graphql`
    query ExampleQuery {
      artist(id: "banksy") {
        name
      }
    }
  `}
  render={({ props }) => {
    if (props) {
      return props.artist && <div>{props.artist.name} is great!</div>
    }
    return <div>Loading</div>
  }}
/>

```

Similarly, in this example the emitted type-information describes the prop data that the container expects to receive.

#### Flow

```javascript
/**
 * export type ExampleFragment_artist = {|
 *   +name: string
 * |}
 */
import type { ExampleFragment_artist } from "__generated__/ExampleFragment_artist.graphql"

export const ExampleFragment = createFragmentContainer(
  (props: { artist: ExampleFragment_artist }) => (
    <div>About the artist: {props.artist.biography}</div>
  ),
  {
    artist: graphql`
      fragment ExampleFragment_artist on Artist {
        biography
      }
    `
  }
)

```

#### TypeScript

```javascript
/**
 * export type ExampleFragment_artist = {
 *   readonly name: string
 * }
 */
import { ExampleFragment_artist } from "__generated__/ExampleFragment_artist.graphql"

export const ExampleFragment = createFragmentContainer(
  (props: { artist: ExampleFragment_artist }) => (
    <div>About the artist: {props.artist.biography}</div>
  ),
  {
    artist: graphql`
      fragment ExampleFragment_artist on Artist {
        biography
      }
    `,
  }
)

```

### Fragment references

The opaque identifier described in [data-masking] that a child container expects to receive from its parent, which represents the child containerâ€™s fragment spread inside the parentâ€™s fragment.

_Please read [this important caveat](#single-artifact-directory) about actually enabling type-safe fragment reference checking._

Consider a component that composes the above fragment container example. In this example, the emitted type-information of the child container receives a unique opaque identifier type, called a fragment reference, which the type-information emitted for the parentâ€™s fragment references in the location where the childâ€™s fragment is spread. Thus ensuring that the childâ€™s fragment is spread into the parentâ€™s fragment _and_ the correct fragment reference is passed to the child container at runtime.

#### Flow

```javascript
/**
 * import type { FragmentReference } from "relay-runtime";
 * declare export opaque type ExampleFragment_artist$ref: FragmentReference;
 * export type ExampleFragment_artist = {|
 *   +name: string,
 *   +$refType: ExampleFragment_artist$ref,
 * |};
 */
import { ExampleFragment } from "./ExampleFragment"

/**
 * import type { ExampleFragment_artist$ref } from "ExampleFragment_artist.graphql";
 * export type ExampleQueryResponse = {|
 *   +artist: ?{|
 *     +$fragmentRefs: ExampleFragment_artist$ref,
 *   |}
 * |};
 */
import type { ExampleQueryResponse } from "__generated__/ExampleQuery.graphql"

<QueryRenderer
  query={graphql`
    query ExampleQuery {
      artist(id: "banksy") {
        ...ExampleFragment_artist
      }
    }
  `}
  render={({ props }: { props?: ExampleQueryResponse }) => {
    if (props) {
      // Here only `props.artist` is an object typed as the appropriate prop
      // for the `artist` prop of the `ExampleFragment` container.
      return <ExampleFragment artist={props.artist} />
    }
    return <div>Loading</div>
  }}
/>

```

#### TypeScript

```javascript
/**
 * declare const _ExampleFragment_artist$ref: unique symbol;
 * export type ExampleFragment_artist$ref = typeof _ExampleFragment_artist$ref;
 * export type ExampleFragment_artist = {
 *   readonly name: string
 *   readonly " $refType": ExampleFragment_artist$ref
 * }
 */
import { ExampleFragment } from "./ExampleFragment"

/**
 * import { ExampleFragment_artist$ref } from "ExampleFragment_artist.graphql";
 * export type ExampleQueryResponse = {
 *   readonly artist?: {
 *     readonly " $fragmentRefs": ExampleFragment_artist$ref
 *   }
 * }
 * export type ExampleQuery = {
 *   readonly response: ExampleQueryResponse
 * }
 */
import { ExampleQuery } from "__generated__/ExampleQuery.graphql"

<QueryRenderer<ExampleQuery>
  query={graphql`
    query ExampleQuery {
      artist(id: "banksy") {
        ...ExampleFragment_artist
      }
    }
  `}
  render={({ props }) => {
    if (props) {
      // Here only `props.artist` is an object typed as the appropriate prop
      // for the `artist` prop of the `ExampleFragment` container.
      return props.artist && <ExampleFragment artist={props.artist} />
    }
    return <div>Loading</div>
  }}
/>

```

## Single artifact directory

An important caveat to note is that by default strict fragment reference type-information will _not_ be emitted, instead they will be typed as `any` and would allow you to pass in any data to the child container.

To enable this feature, you will have to tell the compiler to store all the artifacts in a single directory, like so:

```shell

$ relay-compiler --artifactDirectory ./src/__generated__ [â€¦]

```

â€¦and additionally inform the babel plugin in your `.babelrc` config where to look for the artifacts:

```json

{
  "plugins": [
    ["relay", { "artifactDirectory": "./src/__generated__" }]
  ]
}
```

It is recommended to alias this directory in your module resolution configuration such that you donâ€™t need to specify relative paths in your source files. This is what is also done in the above examples, where artifacts are imported from a `__generated__` alias, rather than relative paths like `../../../../__generated__`.

### Background information

The reason is that `relay-compiler` and its artifact emission is stateless. Meaning that it does not keep track of locations of original source files and where the compiler previously saved the accompanying artifact on disk. Thus, if the compiler were to emit artifacts that try to import fragment reference types from _other_ artifacts, the compiler would:

-   first need to know where on disk that other artifact exists;
-   and update imports when the other artifact changes location on disk.

Facebook uses a module system called [Haste], in which all source files are considered in a flat namespace. This means that an import declaration does not need to specify the path to another module and thus there is no need for the compiler to ever consider the above issues. I.e. an import only needs to specify the basename of the module filename and Haste takes care of actually finding the right module at import time. Outside of Facebook, however, usage of the Haste module system is non-existent nor encouraged, thus the decision to not import fragment reference types but instead type them as `any`.

At its simplest, we can consider Haste as a single directory that contains all module files, thus all module imports always being safe to import using relative sibling paths. This is what is achieved by the single artifact directory feature. Rather than co-locating artifacts with their source files, all artifacts are stored in a single directory, allowing the compiler to emit imports of fragment reference types.

## Language plugins

-   Flow: This is the default and builtin language plugin. You can explicitly enable it like so:

    ```shell

    $ relay-compiler --language javascript [â€¦]

    ```

By default, Flow types are emitted inside of comments to avoid forcing your project to use Flow. Flow types inside of comments is perfectly valid Flow, however, some editors and IDEs (like WebStorm/IDEA) do not understand Flow unless it's in plain source code. In order to solve that, there's a language plugin maintained by the community that replicates the functionality of the default builtin plugin, but emits the Flow types as plain source and not inside comments. Installation and usage:

```shell

  $ yarn add --dev relay-compiler-language-js-flow-uncommented
  $ relay-compiler --language js-flow-uncommented [â€¦]

```

-   [TypeScript](https://github.com/relay-tools/relay-compiler-language-typescript): This is a language plugin for the TypeScript language maintained by the community. Install and enable it like so:

    ```shell

    $ yarn add --dev relay-compiler-language-typescript @types/react-relay @types/relay-runtime
    $ relay-compiler --language typescript [â€¦]

    ```

If you are looking to create your own language plugin, refer to the `relay-compiler` [language plugin interface][plugin-interface].

[data-masking]: ./PrinciplesAndArchitecture-ThinkingInRelay.md#data-masking

[Haste]: https://twitter.com/dan_abramov/status/758655309212704768

[plugin-interface]: https://github.com/facebook/relay/blob/main/packages/relay-compiler/language/RelayLanguagePluginInterface.js


---
id: upgrading-setvariables
title: Upgrading setVariables
original_id: upgrading-setvariables
---
<blockquote>
Examples on how to migrate <code>this.props.setVariables</code> calls from the old API.
</blockquote>

`this.props.setVariables` from the old API does not have a direct equivalent in the new API. A big reason for this change is that the new core no longer tracks how to refetch any specific sub-tree from the query. This makes the new core a lot faster, but requires explicit queries for how to fetch new data. Check out these four different scenarios:

## `initialVariables`

If the component doesn't actually use `setVariables()`, and just uses `initialVariables` to share values between JS and GraphQL, there are two alternative approaches:

-   Inline the value in the GraphQL query, potentially annotating with a GraphQL comment (i.e. `# PAGE_SIZE`).
-   Add the variable to the queries that use the fragment and pass it in when fetching the query. For this it can be useful to have a module with a collection of variables for your product.

## Pagination

Typical Relay Classic code:

```

// counterexample
this.props.relay.setVariables({
  count: count + 10,
});

initialVariables: {
  count: 10,
},

fragment on User {
  friends(first: $count) {
    # ...
  }
}
```

This should be upgraded to use a [`PaginationContainer`](Modern-PaginationContainer.md).

## Changing Arguments

Typical old code:

```

// counterexample
this.props.relay.setVariables({
  search: newSearchTerm,
});

initialVariables: {
  search: '',
}

fragment on User {
  friends(named: $search, first: 10) {
    # ...
  }
}
```

This can be upgraded by using a [`RefetchContainer`](Modern-RefetchContainer.md) which allows you to specify the exact query to use to fetch the new data.

## Show More

Typical old code:

```

// counterexample
this.props.relay.setVariables({
  showComments: true,
});

initialVariables: {
  showComments: false,
}

fragment on FeedbackTarget {
  comments(first: 10) @include(if: $showComments) {
    # ...
  }
}
```

This can be upgraded by conditionally rendering a [`QueryRenderer`](Modern-QueryRenderer.md) which will load the data once it is rendered. The code overhead of doing this is dramatically reduced with the new API.

Alternatively a [`RefetchContainer`](Modern-RefetchContainer.md) can also be used.


---
id: fetch-query
title: fetchQuery
original_id: fetch-query
---
You can use the `fetchQuery` function to imperatively make GraphQL Requests. This is useful for cases where you want to make requests outside of React but still utilize the Relay store and network layer.

```javascript
import {fetchQuery, graphql} from 'relay-runtime';

const query = graphql`
  query ExampleQuery($pageID: ID!) {
    page(id: $pageID) {
      name
    }
  }
`;

const variables = {
  pageID: '110798995619330',
};

fetchQuery(environment, query, variables)
  .then(data => {
    // access the graphql response
  });
```

## Arguments

-   `environment`: The [Relay Environment](Modern-RelayEnvironment.md)
-   `query`: The `graphql` tagged query. **Note:** `relay-compiler` enforces the query to be named as `<FileName>Query`.
-   `variables`: Object containing set of variables to pass to the GraphQL query, i.e. a mapping from variable name to value.
-   `cacheConfig?`: Optional object containing a set of cache configuration options, i.e. `force: true` requires the fetch to be issued regardless of the state of any configured response cache. See [the types](https://github.com/DefinitelyTyped/DefinitelyTyped/blob/master/types/relay-runtime/lib/util/RelayRuntimeTypes.d.ts#L22-L35) for more `cacheConfig` options.

## Return Value

The function returns a `Promise` that resolves with an object containing data obtained from the query.


---
id: compiler-architecture
title: Compiler Architecture
original_id: compiler-architecture
---
The compiler is a set of modules designed to extract GraphQL documents from across a codebase, transform/optimize them, and generate build artifacts. Examples of common types of artifacts include optimized GraphQL to persist to your server, runtime representations of the queries for use with GraphQL clients such as the Relay runtime, or generated source code for use with GraphQL frameworks for compiled languages (Java/Swift/etc).

## Data Flow

The high-level flow of data through the compiler is represented in the following diagram:

```

                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   GraphQL   â”‚â”‚   Schema    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚              â”‚              parse
                          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                  â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚      CompilerContext       â”‚
                   â”‚                            â”‚
                   â”‚   â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”  â”‚â”€â”€â”
                   â”‚   â”‚ IR  â”‚ â”‚ IR  â”‚ â”‚ ... â”‚  â”‚  â”‚
                   â”‚   â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  transform/
                          â”‚    â”‚      â–²            â”‚   optimize
                          â”‚    â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚    â”‚
                          â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  print        â”‚  codegen
                          â–¼               â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   GraphQL   â”‚ â”‚  Artifacts  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

1.  GraphQL text is extracted from source files and "parsed" into an intermediate representation (IR) using information from the schema.
2.  The set of IR documents forms a CompilerContext, which is then transformed and optimized.
3.  Finally, GraphQL is printed (e.g. to files, saved to a database, etc) and any artifacts are generated.

## Data Types & Modules

The compiler module is composed of a set of core building blocks as well as a helper that packages them together in an easy to use API. Some of the main data types and modules in the compiler are as follows:

-   `IR` (Intermediate Representation): an (effectively immutable) representation of a GraphQL document (query, fragment, field, etc) as a tree structure, including type information from a schema. Compared to the standard GraphQL AST (produced by e.g. `graphql-js`) the main difference is that it encodes more of the semantics of GraphQL. For example, conditional branches (`@include` and `@skip`) are represented directly, making it easier to target optimizations for these directives (One such optimization is to merge sibling fields with the same condition, potentially reducing the number of conditionals that must be evaluated at runtime).
-   `CompilerContext`: an immutable representation of a corpus of GraphQL documents. It contains the schema and a mapping of document names to document representations (as IR, see above).
-   `Transform`: a "map"-like function that accepts a `CompilerContext` as input and returns a new, modified context as output. Examples below.
-   `Parser`: Converts a GraphQL schema and raw GraphQL text into typed IR objects.
-   `Printer`: a function that accepts IR and converts it to a GraphQL string.

The `RelayCompiler` module is a helper class that demonstrates one way of combining these primitives. It takes IR transforms, and given IR definitions, constructs a CompilerContext from them, transforming them, and generating output artifacts intended for use with Relay runtime.

## Transforms

One of the main goals of the compiler is to provide a consistent platform for writing tools that transform or optimize GraphQL. This includes the ability to experiment with new directives by transforming them away at compile time. Transform functions should typically perform a single type of modification - it's expected that an app will have multiple transforms configured in the compiler instance.

Here are a few examples of some of the included transforms:

-   `FlattenTransform`: Reduces extraneous levels of indirection in a query, inlining fields from anonymous fragments wherever they match the parent type. This can be beneficial when generating code to read the results of a query or process query results, as it reduces duplicate field processing. For example:

```

# before: `id` is processed twice
foo { # type FooType
   id
   ... on FooType { # matches the parent type, so this is extraneous
     id
   }
 }

 # after: `id` is processed once
 foo {
   id
 }
```

-   `SkipRedundantNodeTransform`: A more advanced version of flattening, this eliminates more complex cases of field duplication such as when a field is fetched both unconditionally and conditionally, or is fetched by two different sub-fragments. For example:

```

# before: `id` processed up to 2x
foo {
  bar {
    id
  }
  ... on FooType @include(if: $cond) { # can't be flattened due to conditional
    id # but this field is guaranteed to be fetched regardless
  }
}

# after: `id` processed at most once
foo {
  bar {
    id
  }
}
```

-   `GenerateRequisiteFieldTransform`: This optional, Relay-specific transform inserts `id` fields for globally identifiable objects and `__typename` fields wherever the type cannot be statically determined (e.g. for unions).


---
id: architecture-overview
title: Architecture Overview
original_id: architecture-overview
---
This document, together with [Runtime Architecture](./PrinciplesAndArchitecture-Runtime.md) and [Compiler Architecture](./PrinciplesAndArchitecture-Compiler.md), describes the high-level architecture of Relay "Modern". The intended audience includes developers interested in contributing to Relay, developers hoping to utilize the building blocks of Relay to create higher-level APIs, and anyone interested in understanding more about Relay internals. For developers wanting to learn more about _using_ Relay to build products, the other sections might be more helpful.

## Core Modules

Relay Modern is composed of three core modules:

-   **Relay Compiler:** A GraphQL to GraphQL optimizing _compiler_, providing general utilities for transforming and optimizing queries as well as generating build artifacts. A novel feature of the compiler is that it facilitates experimentation with new GraphQL features - in the form of custom directives - by making it easy to translate code using these directives into standard, spec-compliant GraphQL.
-   **Relay Runtime:** A full-featured, high-performance GraphQL _runtime_ that can be used to build higher-level client APIs. The runtime features a normalized object cache, optimized "write" and "read" operations, a generic abstraction for incrementally fetching field data (such as for pagination), garbage collection for removing unreferenced cache entries, optimistic mutations with arbitrary logic,  support for building subscriptions and live queries, and more.
-   **React/Relay:** A high-level _product API_ that integrates the Relay Runtime with React. This is the primary public interface to Relay for most product developers, featuring APIs to fetch the data for a query or define data dependencies for reusable components (aka containers).

Note that these modules are _loosely coupled_. For example, the compiler emits representations of queries in a well-defined format that the runtime consumes (the "Concrete" node interfaces in `RelayConcreteNode`), such that the compiler implementation can be swapped out if desired. React/Relay relies only on the well-documented public interface of the runtime, such that the actual implementation can be swapped out (in fact, we've upgraded the classic Relay core to also implement this same API). We hope that this loose coupling will allow the community to explore new use-cases such as the development of specialized product APIs using the Relay runtime or integrations of the runtime with view libraries other than React.


---
id: runtime-architecture
title: Runtime Architecture
original_id: runtime-architecture
---
The Relay runtime is a full-featured GraphQL client that is designed for high performance even on low-end mobile devices and is capable of scaling to large, complex apps. The runtime API is not intended to be used directly in product code, but rather to provide a foundation for building higher-level product APIs such as React/Relay. This foundation includes:

-   A normalized, in-memory object graph/cache.
-   An optimized "write" operation for updating the cache with the results of queries/mutations/subscriptions.
-   A mechanism for reading data from the cache and subscribing for updates when these results change due to a mutation, subscription update, etc.
-   Garbage collection to evict entries from the cache when they can no longer be referenced by any view.
-   A generic mechanism for intercepting data prior to publishing it to the cache and either synthesizing new data or merging new and existing data together (which among other things enables the creation of a variety of pagination schemes).
-   Mutations with optimistic updates and the ability to update the cache with arbitrary logic.
-   Support for live queries where supported by the network/server.
-   Core primitives to enable subscriptions.
-   Core primitives for building offline/persisted caching.

## Comparison to Classic Relay

For users of classic Relay, note that the runtime makes as few assumptions as possible about GraphQL. Compared to earlier versions of Relay there is no concept of routes, there are no limitations on mutation input arguments or side-effects, arbitrary root fields just work, etc. At present, the main restriction from classic Relay that remains is the use of the `Node` interface and `id` field for object identification. However there is no fundamental reason that this restriction can't be relaxed (there is a single place in the codebase where object identity is determined), and we welcome feedback from the community about ways to support customizable object identity without negatively impacting performance.

## Data Types

 (subsequent sections explain how these types are used in practice):

-   `DataID` (type): A globally unique or client-generated identifier for a record, stored as a string.
-   `Record` (type): A representation of a distinct data entity with an identity, type, and fields. Note that the actual runtime representation is opaque to the system: all accesses to `Record` objects (including record creation) is mediated through the `RelayModernRecord` module. This allows the representation itself to be changed in a single place (e.g. to use `Map`s or a custom class). It is important that other code does not assume that `Record`s will always be plain objects.
-   `RecordSource` (type): A collection of records keyed by their data ID, used both to represent the cache and updates to it. For example the store's record cache is a `RecordSource` and the results of queries/mutations/subscriptions are normalized into `RecordSource`s that are published to a store. Sources also define methods for asynchronously loading records in order to (eventually) support offline use-cases. Currently the only implementation of this interface is `RelayInMemoryRecordSource`; future implementations may add support for loading records from disk.
-   `Store` (type): The source of truth for an instance of `RelayRuntime`, holding the canonical set of records in the form of a `RecordSource` (though this is not required). Currently the only implementation is `RelayModernStore`.
-   `Network` (type): Provides methods for fetching query data from and executing mutations against an external data source.
-   `Environment` (type): Represents an encapsulated environment combining a `Store` and `Network`, providing a high-level API for interacting with both. This is the main public API of `RelayRuntime`.

Types for working with queries and their results include:

-   `Selector` (type): A selector defines the starting point for a traversal into the graph for the purposes of targeting a subgraph, combining a GraphQL fragment, variables, and the Data ID for the root object from which traversal should progress. Intuitively, this "selects" a portion of the object graph.
-   `Snapshot` (type): The (immutable) results of executing a `Selector` at a given point in time. This includes the selector itself, the results of executing it, and a list of the Data IDs from which data was retrieved (useful in determining when these results might change).

## Data Model

Relay Runtime is designed for use with GraphQL schemas that describe **object graphs** in which objects have a type, an identity, and a set of fields with values. Objects may reference each other, which is represented by fields whose values are one or more other objects in the graph [1]. To distinguish from JavaScript `Object`s, these units of data are referred to as `Record`s. Relay represents both its internal cache as well as query/mutation/etc results as a mapping of **data ID**s to **records**. The data ID is the unique (with respect to the cache) identifier for a record - it may be the value of an actual `id` field or based on the path to the record from the nearest object with an `id` (such path-based ids are called **client ids**). Each `Record` stores its data ID, type, and any fields that have been fetched. Multiple records are stored together as a `RecordSource`: a mapping of data IDs to `Record` instances.

For example, a user and their address might be represented as follows:

```

// GraphQL Fragment
fragment on User {
  id
  name
  address {
    city
  }
}

// Response
{
  id: '842472',
  name: 'Joe',
  address: {
    city: 'Seattle',
  }
}

// Normalized Representation
RecordSource {
  '842472': Record {
    __id: '842472',
    __typename: 'User', // the type is known statically from the fragment
    id: '842472',
    name: 'Joe',
    address: {__ref: 'client:842472:address'}, // link to another record
  },
  'client:842472:address': Record {
    // A client ID, derived from the path from parent & parent's ID
    __id: 'client:842472:address',
    __typename: 'Address',
    city: 'Seattle',
  }
}
```

[1] Note that GraphQL itself does not impose this constraint, and Relay Runtime may also be used for schemas that do not conform to it. For example, both systems can be used to query a single denormalized table. However, many of the features that Relay Runtime provides, such as caching and normalization, work best when the data is represented as a normalized graph with stable identities for discrete pieces of information.

### Store Operations

The `Store` is the source of truth for application data and provides the following core operations.

-   `lookup(selector: Selector): Snapshot`: Reads the results of a selector from the store, returning the value given the data currently in the store.

-   `subscribe(snapshot: Snapshot, callback: (snapshot: Snapshot) => void): Disposable`: Subscribe to changes to the results of a selector. The callback is called when data has been published to the store that would cause the results of the snapshot's selector to change.

-   `publish(source: RecordSource): void`: Update the store with new information. All updates to the store are expressed in this form, including the results of queries/mutation/subscriptions as well as optimistic mutation updates. All of those operations internally create a new `RecordSource` instance and ultimately publish it to the store. Note that `publish()` does _not_ immediately update any `subscribe()`-ers. Internally, the store compares the new `RecordSource` with its internal source, updating it as necessary:
    -   Records that exist only in the published source are added to the store.
    -   Records that exist in both are merged into a new record (inputs unchanged), with the result added to the store.
    -   Records that are null in the published source are deleted (set to null) in the store.
    -   Records with a special sentinel value are removed from the store. This supports un-publishing optimistically created records.

-   `notify(): void`: Calls any `subscribe()`-ers whose results have changed due to intervening `publish()`-es. Separating `publish()` and `notify()` allows for multiple payloads to be published before performing any downstream update logic (such as rendering).

-   `retain(selector: Selector): Disposable`: Ensure that all the records necessary to fulfill the given selector are retained in-memory. The records will not be eligible for garbage collection until the returned reference is disposed.

### Example Data Flow: Fetching Query Data

```

               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚         Query         â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                                             â”Œ â”€ â”€ â”€ â”
                         fetch â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Server
                                             â”” â”€ â”€ â”€ â”˜
                           â”‚
                     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                     â–¼             â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  Query   â”‚  â”‚ Response â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚             â”‚
                     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                       normalize
                           â”‚
                           â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚     RecordSource      â”‚
               â”‚                       â”‚
               â”‚â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”â”‚
               â”‚â”‚Recordâ”‚â”‚Recordâ”‚â”‚ ... â”‚â”‚
               â”‚â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

1.  The query is fetched from the network.
2.  The query and response are traversed together, extracting the results into `Record` objects which are added to a fresh `RecordSource`.

This fresh `RecordSource` would then be published to the store:

```

                        publish
                           â”‚
                           â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚           Store           â”‚
             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
             â”‚ â”‚     RecordSource      â”‚ â”‚
             â”‚ â”‚                       â”‚ â”‚
             â”‚ â”‚â”Œ â”€ â”€ â”€ â”Œ â”€ â”€ â”€ â”Œ â”€ â”€ â”â”‚ â”‚
             â”‚ â”‚ Recordâ”‚ Recordâ”‚  ...  â”‚ â”‚  <--- records are updated
             â”‚ â”‚â”” â”€ â”€ â”€ â”” â”€ â”€ â”€ â”” â”€ â”€ â”˜â”‚ â”‚
             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
             â”‚ â”‚     Subscriptions     â”‚ â”‚
             â”‚ â”‚                       â”‚ â”‚
             â”‚ â”‚â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”â”‚ â”‚
             â”‚ â”‚â”‚ Sub. â”‚â”‚ Sub. â”‚â”‚ ... â”‚â”‚ â”‚ <--- subscriptions do not fire yet
             â”‚ â”‚â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜â”‚ â”‚
             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

Publishing the results updates the store but does _not_ immediately notify any subscribers. This is accomplished by calling `notify()`...

```

                        notify
                           â”‚
                           â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚           Store           â”‚
             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
             â”‚ â”‚     RecordSource      â”‚ â”‚
             â”‚ â”‚                       â”‚ â”‚
             â”‚ â”‚â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”â”‚ â”‚
             â”‚ â”‚â”‚Recordâ”‚â”‚Recordâ”‚â”‚ ... â”‚â”‚ â”‚
             â”‚ â”‚â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜â”‚ â”‚
             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
             â”‚ â”‚     Subscriptions     â”‚ â”‚
             â”‚ â”‚                       â”‚ â”‚
             â”‚ â”‚â”Œ â”€ â”€ â”€ â”Œ â”€ â”€ â”€ â”Œ â”€ â”€ â”â”‚ â”‚
             â”‚ â”‚  Sub. â”‚  Sub. â”‚  ...  â”‚ â”‚ <--- affected subscriptions fire
             â”‚ â”‚â”” â”€â”‚â”€ â”€ â”” â”€â”‚â”€ â”€ â”” â”€â”‚â”€ â”˜â”‚ â”‚
             â”‚ â””â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”˜ â”‚
             â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”˜
                   â”‚       â”‚       â”‚
                   â–¼       â”‚       â”‚
               callback    â”‚       â”‚
                           â–¼       â”‚
                       callback    â”‚
                                   â–¼
                               callback

```

...which calls the callbacks for any `subscribe()`-ers whose results have changed. Each subscription is checked as follows:

1.  First, the list of data IDs that have changed since the last `notify()` is compared against data IDs listed in the subscription's latest `Snapshot`. If there is no overlap, the subscription's results cannot possibly have changed (if you imagine the graph visually, there is no overlap between the part of the graph that changed and the part that is selected). In this case the subscription is ignored, otherwise processing continues.
2.  Second, any subscriptions that do have overlapping data IDs are re-read, and the new/previous results are compared. If the result has not changed, the subscription is ignored (this can occur if a field of a record changed that is not relevant to the subscription's selector), otherwise processing continues.
3.  Finally, subscriptions whose data actually changed are notified via their callback.

### Example Data Flow: Reading and Observing the Store

Products access the store primarily via `lookup()` and `subscribe()`. Lookup reads the initial results of a fragment, and subscribe observes that result for any changes. Note that the output of `lookup()` - a `Snapshot` - is the input to `subscribe()`. This is important because the snapshot contains important information that can be used to optimize the subscription - if `subscribe()` accepted only a `Selector`, it would have to re-read the results in order to know what to subscribe to, which is less efficient.

Therefore a typical data flow is as follows - note that this flow is managed automatically by higher-level APIs such as React/Relay. First a component will lookup the results of a selector against a record source (e.g. the store's canonical source):

```

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     RecordSource      â”‚       â”‚              â”‚
    â”‚                       â”‚       â”‚              â”‚
    â”‚â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”â”‚       â”‚   Selector   â”‚
    â”‚â”‚Recordâ”‚â”‚Recordâ”‚â”‚ ... â”‚â”‚       â”‚              â”‚
    â”‚â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜â”‚       â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                           â”‚
                â”‚                           â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â”‚  lookup
                               â”‚  (read)
                               â”‚
                               â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚             â”‚
                        â”‚  Snapshot   â”‚
                        â”‚             â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â”‚  render, etc
                               â”‚
                               â–¼

```

Next, it will `subscribe()` using this snapshot in order to be notified of any changes - see the above diagram for `publish()` and `notify()`.


---
id: thinking-in-graphql
title: Thinking in GraphQL
original_id: thinking-in-graphql
---
GraphQL presents new ways for clients to fetch data by focusing on the needs of product developers and client applications. It provides a way for developers to specify the precise data needed for a view and enables a client to fetch that data in a single network request. Compared to traditional approaches such as REST, GraphQL helps applications to fetch data more efficiently (compared to resource-oriented REST approaches) and avoid duplication of server logic (which can occur with custom endpoints). Furthermore, GraphQL helps developers to decouple product code and server logic. For example, a product can fetch more or less information without requiring a change to every relevant server endpoint. It's a great way to fetch data.

In this article we'll explore what it means to build a GraphQL client framework and how this compares to clients for more traditional REST systems. Along the way we'll look at the design decisions behind Relay and see that it's not just a GraphQL client but also a framework for _declarative data-fetching_. Let's start at the beginning and fetch some data!

## Fetching Data

Imagine we have a simple application that fetches a list of stories, and some details about each one. Here's how that might look in resource-oriented REST:

```javascript
// Fetch the list of story IDs but not their details:
rest.get('/stories').then(stories =>
  // This resolves to a list of items with linked resources:
  // `[ { href: "http://.../story/1" }, ... ]`
  Promise.all(stories.map(story =>
    rest.get(story.href) // Follow the links
  ))
).then(stories => {
  // This resolves to a list of story items:
  // `[ { id: "...", text: "..." } ]`
  console.log(stories);
});
```

Note that this approach requires _n+1_ requests to the server: 1 to fetch the list, and _n_ to fetch each item. With GraphQL we can fetch the same data in a single network request to the server (without creating a custom endpoint that we'd then have to maintain):

```javascript
graphql.get(`query { stories { id, text } }`).then(
  stories => {
    // A list of story items:
    // `[ { id: "...", text: "..." } ]`
    console.log(stories);
  }
);
```

So far we're just using GraphQL as a more efficient version of typical REST approaches. Note two important benefits in the GraphQL version:

-   All data is fetched in a single round trip.
-   The client and server are decoupled: the client specifies the data needed instead of _relying on_ the server endpoint to return the correct data.

For a simple application that's already a nice improvement.

## Client Caching

Repeatedly refetching information from the server can get quite slow. For example, navigating from the list of stories, to a list item, and back to the list of stories means we have to refetch the whole list. We'll solve this with the standard solution: _caching_.

In a resource-oriented REST system, we can maintain a **response cache** based on URIs:

```javascript
var _cache = new Map();
rest.get = uri => {
  if (!_cache.has(uri)) {
    _cache.set(uri, fetch(uri));
  }
  return _cache.get(uri);
};
```

Response-caching can also be applied to GraphQL. A basic approach would work similarly to the REST version. The text of the query itself can be used as a cache key:

```javascript
var _cache = new Map();
graphql.get = queryText => {
  if (!_cache.has(queryText)) {
    _cache.set(queryText, fetchGraphQL(queryText));
  }
  return _cache.get(queryText);
};
```

Now, requests for previously cached data can be answered immediately without making a network request. This is a practical approach to improving the perceived performance of an application. However, this method of caching can cause problems with data consistency.

## Cache Consistency

With GraphQL it is very common for the results of multiple queries to overlap. However, our response cache from the previous section doesn't account for this overlap â€” it caches based on distinct queries. For example, if we issue a query to fetch stories:

```

query { stories { id, text, likeCount } }
```

and then later refetch one of the stories whose `likeCount` has since been incremented:

```

query { story(id: "123") { id, text, likeCount } }
```

We'll now see different `likeCount`s depending on how the story is accessed. A view that uses the first query will see an outdated count, while a view using the second query will see the updated count.

### Caching A Graph

The solution to caching GraphQL is to normalize the hierarchical response into a flat collection of **records**. Relay implements this cache as a map from IDs to records. Each record is a map from field names to field values. Records may also link to other records (allowing it to describe a cyclic graph), and these links are stored as a special value type that references back into the top-level map. With this approach each server record is stored _once_ regardless of how it is fetched.

Here's an example query that fetches a story's text and its author's name:

```

query {
  story(id: "1") {
    text,
    author {
      name
    }
  }
}
```

And here's a possible response:

```

query: {
  story: {
     text: "Relay is open-source!",
     author: {
       name: "Jan"
     }
  }
}
```

Although the response is hierarchical, we'll cache it by flattening all the records. Here is an example of how Relay would cache this query response:

```javascript
Map {
  // `story(id: "1")`
  1: Map {
    text: 'Relay is open-source!',
    author: Link(2),
  },
  // `story.author`
  2: Map {
    name: 'Jan',
  },
};
```

This is only a simple example: in reality the cache must handle one-to-many associations and pagination (among other things).

### Using The Cache

So how do we use this cache? Let's look at two operations: writing to the cache when a response is received, and reading from the cache to determine if a query can be fulfilled locally (the equivalent to `_cache.has(key)` above, but for a graph).

### Populating The Cache

Populating the cache involves walking a hierarchical GraphQL response and creating or updating normalized cache records. At first it may seem that the response alone is sufficient to process the response, but in fact this is only true for very simple queries. Consider `user(id: "456") { photo(size: 32) { uri } }` â€” how should we store `photo`? Using `photo` as the field name in the cache won't work because a different query might fetch the same field but with different argument values (e.g. `photo(size: 64) {...}`). A similar issue occurs with pagination. If we fetch the 11th to 20th stories with `stories(first: 10, offset: 10)`, these new results should be _appended_ to the existing list.

Therefore, a normalized response cache for GraphQL requires processing payloads and queries in parallel. For example, the `photo` field from above might be cached with a generated field name such as `photo_size(32)` in order to uniquely identify the field and its argument values.

### Reading From Cache

To read from the cache we can walk a query and resolve each field. But wait: that sounds _exactly_ like what a GraphQL server does when it processes a query. And it is! Reading from the cache is a special case of an executor where a) there's no need for user-defined field functions because all results come from a fixed data structure and b) results are always synchronous â€” we either have the data cached or we don't.

Relay implements several variations of **query traversal**: operations that walk a query alongside some other data such as the cache or a response payload. For example, when a query is fetched Relay performs a "diff" traversal to determine what fields are missing (much like React diffs virtual DOM trees). This can reduce the amount of data fetched in many common cases and even allow Relay to avoid network requests at all when queries are fully cached.

### Cache Updates

Note that this normalized cache structure allows overlapping results to be cached without duplication. Each record is stored once regardless of how it is fetched. Let's return to the earlier example of inconsistent data and see how this cache helps in that scenario.

The first query was for a list of stories:

```

query { stories { id, text, likeCount } }
```

With a normalized response cache, a record would be created for each story in the list. The `stories` field would store links to each of these records.

The second query refetched the information for one of those stories:

```

query { story(id: "123") { id, text, likeCount } }
```

When this response is normalized, Relay can detect that this result overlaps with existing data based on its `id`. Rather than create a new record, Relay will update the existing `123` record. The new `likeCount` is therefore available to _both_ queries, as well as any other query that might reference this story.

## Data/View Consistency

A normalized cache ensures that the _cache_ is consistent. But what about our views? Ideally, our React views would always reflect the current information from the cache.

Consider rendering the text and comments of a story along with the corresponding author names and photos. Here's the GraphQL query:

```

query {
  story(id: "1") {
    text,
    author { name, photo },
    comments {
      text,
      author { name, photo }
    }
  }
}
```

After initially fetching this story our cache might be as follows. Note that the story and comment both link to the same record as `author`:

```

// Note: This is pseudo-code for `Map` initialization to make the structure
// more obvious.
Map {
  // `story(id: "1")`
  1: Map {
    text: 'got GraphQL?',
    author: Link(2),
    comments: [Link(3)],
  },
  // `story.author`
  2: Map {
    name: 'Yuzhi',
    photo: 'http://.../photo1.jpg',
  },
  // `story.comments[0]`
  3: Map {
    text: 'Here\'s how to get one!',
    author: Link(2),
  },
}
```

The author of this story also commented on it â€” quite common. Now imagine that some other view fetches new information about the author, and her profile photo has changed to a new URI. Here's the _only_ part of our cached data that changes:

```

Map {
  ...
  2: Map {
    ...
    photo: 'http://.../photo2.jpg',
  },
}
```

The value of the `photo` field has changed; and therefore the record `2` has also changed. And that's it. Nothing else in the _cache_ is affected. But clearly our _view_ needs to reflect the update: both instances of the author in the UI (as story author and comment author) need to show the new photo.

A standard response is to "just use immutable data structures" â€” but let's see what would happen if we did:

```

ImmutableMap {
  1: ImmutableMap // same as before
  2: ImmutableMap {
    ... // other fields unchanged
    photo: 'http://.../photo2.jpg',
  },
  3: ImmutableMap // same as before
}
```

If we replace `2` with a new immutable record, we'll also get a new immutable instance of the cache object. However, records `1` and `3` are untouched. Because the data is normalized, we can't tell that `story`'s contents have changed just by looking at the `story` record alone.

### Achieving View Consistency

There are a variety of solutions for keeping views up to date with a flattened cache. The approach that Relay takes is to maintain a mapping from each UI view to the set of IDs it references. In this case, the story view would subscribe to updates on the story (`1`), the author (`2`), and the comments (`3` and any others). When writing data into the cache, Relay tracks which IDs are affected and notifies _only_ the views that are subscribed to those IDs. The affected views re-render, and unaffected views opt-out of re-rendering for better performance (Relay provides a safe but effective default `shouldComponentUpdate`). Without this strategy, every view would re-render for even the tiniest change.

Note that this solution will also work for _writes_: any update to the cache will notify the affected views, and writes are just another thing that updates the cache.

## Mutations

So far we've looked at the process of querying data and keeping views up to date, but we haven't looked at writes. In GraphQL, writes are called **mutations**. We can think of them as queries with side effects. Here's an example of calling a mutation that might mark a given story as being liked by the current user:

```

// Give a human-readable name and define the types of the inputs,
// in this case the id of the story to mark as liked.
mutation StoryLike($storyID: String) {
   // Call the mutation field and trigger its side effects
   storyLike(storyID: $storyID) {
     // Define fields to re-fetch after the mutation completes
     likeCount
   }
}
```

Notice that we're querying for data that _may_ have changed as a result of the mutation. An obvious question is: why can't the server just tell us what changed? The answer is: it's complicated. GraphQL abstracts over _any_ data storage layer (or an aggregation of multiple sources), and works with any programming language. Furthermore, the goal of GraphQL is to provide data in a form that is useful to product developers building a view.

We've found that it's common for the GraphQL schema to differ slightly or even substantially from the form in which data is stored on disk. Put simply: there isn't always a 1:1 correspondence between data changes in your underlying _data storage_ (disk) and data changes in your _product-visible schema_ (GraphQL). The perfect example of this is privacy: returning a user-facing field such as `age` might require accessing numerous records in our data-storage layer to determine if the active user is even allowed to _see_ that `age` (Are we friends? Is my age shared? Did I block you? etc.).

Given these real-world constraints, the approach in GraphQL is for clients to query for things that may change after a mutation. But what exactly do we put in that query? During the development of Relay we explored several ideas â€” let's look at them briefly in order to understand why Relay uses the approach that it does:

-   Option 1: Re-fetch everything that the app has ever queried. Even though only a small subset of this data will actually change, we'll still have to wait for the server to execute the _entire_ query, wait to download the results, and wait to process them again. This is very inefficient.

-   Option 2: Re-fetch only the queries required by actively rendered views. This is a slight improvement over option 1. However, cached data that _isn't_ currently being viewed won't be updated. Unless this data is somehow marked as stale or evicted from the cache subsequent queries will read outdated information.

-   Option 3: Re-fetch a fixed list of fields that _may_ change after the mutation. We'll call this list a **fat query**. We found this to also be inefficient because typical applications only render a subset of the fat query, but this approach would require fetching all of those fields.

-   Option 4 (Relay): Re-fetch the intersection of what may change (the fat query) and the data in the cache. In addition to the cache of data Relay also remembers the queries used to fetch each item. These are called **tracked queries**. By intersecting the tracked and fat queries, Relay can query exactly the set of information the application needs to update and nothing more.

## Data-Fetching APIs

So far we looked at the lower-level aspects of data-fetching and saw how various familiar concepts translate to GraphQL. Next, let's step back and look at some higher-level concerns that product developers often face around data-fetching:

-   Fetching all the data for a view hierarchy.
-   Managing asynchronous state transitions and coordinating concurrent requests.
-   Managing errors.
-   Retrying failed requests.
-   Updating the local cache after receiving query/mutation responses.
-   Queuing mutations to avoid race conditions.
-   Optimistically updating the UI while waiting for the server to respond to mutations.

We've found that typical approaches to data-fetching â€” with imperative APIs â€” force developers to deal with too much of this non-essential complexity. For example, consider _optimistic UI updates_. This is a way of giving the user feedback while waiting for a server response. The logic of _what_ to do can be quite clear: when the user clicks "like", mark the story as being liked and send the request to the server. But the implementation is often much more complex. Imperative approaches require us to implement all of those steps: reach into the UI and toggle the button, initiate a network request, retry it if necessary, show an error if it fails (and untoggle the button), etc. The same goes for data-fetching: specifying _what_ data we need often dictates _how_ and _when_ it is fetched. Next, we'll explore our approach to solving these concerns with **Relay**.


---
id: thinking-in-relay
title: Thinking In Relay
original_id: thinking-in-relay
---
Relay's approach to data-fetching is heavily inspired by our experience with React. In particular, React breaks complex interfaces into reusable **components**, allowing developers to reason about discrete units of an application in isolation, and reducing the coupling between disparate parts of an application. Even more important is that these components are **declarative**: they allow developers to specify _what_ the UI should look like for a given state, and not have to worry about _how_ to show that UI. Unlike previous approaches that used imperative commands to manipulate native views (e.g. the DOM), React uses a UI description to automatically determine the necessary commands.

Let's look at some product use-cases to understand how we incorporated these ideas into Relay. We'll assume a basic familiarity with React.

## Fetching Data For a View

In our experience, the overwhelming majority of products want one specific behavior: fetch _all_ the data for a view hierarchy while displaying a loading indicator, and then render the _entire_ view once the data is ready.

One solution is to have a root component fetch the data for all its children. However, this would introduce coupling: every change to a component would require changing _any_ root component that might render it, and often some components between it and the root. This coupling could mean a greater chance for bugs and slow the pace of development. Ultimately, this approach doesn't take advantage of React's component model. The natural place for specifying data-dependencies was in _components_.

The next logical approach is to use `render()` as the means of initiating data-fetching. We could simply render the application once, see what data it needed, fetch that data, and render again. This sounds great, but the problem is that _components use data to figure out what to render!_ In other words, this would force data-fetching to be staged: first render the root and see what data it needs, then render its children and see what they need, all the way down the tree. If each stage incurs network request, rendering would require slow, serial roundtrips. We needed a way to determine all the data needs up-front or _statically_.

This is where GraphQL comes into play. Components specify one or multiple GraphQL fragments for some of their props describing their data requirements. Each GraphQL fragment has a unique name within an application which allows us to determine the query needed to fetch the full query tree in a build step and load all the required data in a single network request efficiently at runtime.

## Data Components aka Containers

Relay allows developers to annotate their React components with data dependencies by creating **containers**. These are regular React components that wrap the originals. A key design constraint is that React components are meant to be reusable, so Relay containers must be too. For example, a `<Story />` component might implement a view for rendering any `Story` item. The actual story to render would be determined by the data passed to the component: `<Story story={ ... } />`. The equivalent in GraphQL are **fragments**: named query snippets that specify what data to fetch _for an object of a given type_. We might describe the data needed by `<Story>` as follows:

```

fragment Story_story on Story {
  text
  author {
    name
    photo
  }
}
```

And this fragment can then be used to define the Story container:

```javascript
const {createFragmentContainer, graphql} = require('react-relay');

// Plain React component.
// Usage: `<Story story={ ... } />`
class Story extends React.Component { ... }

// Higher-order component that wraps `<Story />`
const StoryContainer = createFragmentContainer(Story, {
  // Define a fragment with a name matching the `story` prop expected above
  story: graphql`
    fragment Story_story on Story {
      text
      author {
        name
        photo
      }
    }
  `
})

```

## Rendering

In React, rendering a view requires two inputs: the _component_ to render, and a _root_ DOM (UI) node to render into. Rendering Relay containers is similar: we need a _container_ to render, and a _root_ in the graph from which to start our query. We also must ensure that the queries for the container are executed and may want to show a loading indicator while data is being fetched. Similar to `ReactDOM.render(component, domNode)`, Relay provides `<QueryRenderer query={...} variables={...} render={...}>` for this purpose. The `query` and `variables` define what data to fetch and `render` defines what to render. Here's how we might render `<StoryContainer>`:

```javascript
ReactDOM.render(
  <QueryRenderer
    environment={
      // defined or imported above...
    }
    query={graphql`
      query StoryQuery($storyID: ID!) {
        node(id: $storyID) {
          ...Story_story
        }
      }
    `}
    variables={{
      storyID: '123',
    }}
    render={(props, error) => {
      if (error) {
        return <ErrorView />;
      } else if (props) {
        return <StoryContainer story={props.story} />;
      } else {
        return <LoadingIndicator />;
      }
    }}
  />,
  rootElement
)

```

`QueryRenderer` will then fetch the data and render `StoryContainer` once the data is available. Just as React allows developers to render views without directly manipulating the underlying view, Relay removes the need to directly communicate with the network.

## Data Masking

With typical approaches to data-fetching we found that it was common for two components to have _implicit dependencies_. For example `<StoryHeader />` might use some data without directly ensuring that the data was fetched. This data would often be fetched by some other part of the system, such as `<Story />`. Then when we changed `<Story />` and removed that data-fetching logic, `<StoryHeader />` would suddenly and inexplicably break. These types of bugs are not always immediately apparent, especially in larger applications developed by larger teams. Manual and automated testing can only help so much: this is exactly the type of systematic problem that is better solved by a framework.

We've seen that Relay containers ensure that GraphQL fragments are fetched _before_ the component is rendered. But containers also provide another benefit that isn't immediately obvious: **data masking**. Relay only allows components to access data they specifically ask for in GraphQL fragments â€” nothing more. So if one component queries for a Story's `text`, and another for its `author`, each can see _only_ the field that they asked for. In fact, components can't even see the data requested by their _children_: that would also break encapsulation.

Relay also goes further: it uses opaque identifiers on `props` to validate that we've explicitly fetched the data for a component before rendering it. If `<Story />` renders `<StoryHeader />` but forgets to include its fragment, Relay will warn that the data for `<StoryHeader />` is missing. In fact, Relay will warn _even if_ some other component happened to fetch the same data required by `<StoryHeader />`. This warning tells us that although things _might_ work now they're highly likely to break later.

# Conclusion

GraphQL provides a powerful tool for building efficient, decoupled client applications. Relay builds on this functionality to provide a framework for **declarative data-fetching**. By separating _what_ data to fetch from _how_ it is fetched, Relay helps developers build applications that are robust, transparent, and performant by default. It's a great complement to the component-centric way of thinking championed by React. While each of these technologies â€” React, Relay, and GraphQL â€” are powerful on their own, the combination is a **UI platform** that allows us to _move fast_ and _ship high-quality apps at scale_.


---
id: videos
title: Videos
original_id: videos
---
## [Facebook F8 2017](https://www.f8.com/)

### The Evolution of React and GraphQL at Facebook and Beyond

<iframe src="https://www.facebook.com/plugins/video.php?href=https%3A%2F%2Fwww.facebook.com%2FFacebookforDevelopers%2Fvideos%2F10154614710193553%2F&show_text=0&width=640" width={640} height={360} frameBorder="0" allowFullScreen={true} />

## [Silicon Valley ReactJS Meetup](http://www.meetup.com/Silicon-Valley-ReactJS-Meetup/)

### Relay Modern: simpler, faster, more predictable ([slides](https://speakerdeck.com/wincent/relay-2-simpler-faster-more-predictable))

<iframe width={640} height={360} src="https://www.youtube-nocookie.com/embed/OEfUBN9dAI8" frameBorder="0" allowFullScreen={true} />

### Zero to GraphQL in 30 minutes

<iframe width={640} height={360} src="https://www.youtube-nocookie.com/embed/UBGzsb2UkeY" frameBorder="0" allowFullScreen={true} />

## [GraphQL Europe 2018](https://www.graphql-europe.org/)

### Data Masking in GraphQL Clients

<iframe width={640} height={360} src="https://www.youtube-nocookie.com/embed/ww5UQ50oHok" frameBorder="0" allowFullScreen={true} />


</relay-docs>